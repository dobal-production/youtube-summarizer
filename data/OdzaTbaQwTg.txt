dr. Vogel's are some people in your dressing room they claim to be from your agency agency I mean every agency nice to meet you pleasure so my name is Channing on the creative director for crack work agency it's gonna kill you Birds no cool dive right into it okay so we synched up with our research division and we discovered something really interesting every time you wear a new t-shirt 80 boost likability ratings skyrocket up three percent our strategy team has identified a unique opportunity where we can leverage your new t-shirt at the keynote and if we help you find the right t-shirt we think that a WS likability can scale up to like five to six percent year-over-year maybe eight to nine percent of our Twitter game is Solek come to I pick my own t-shirt oh oh no I burner that is like so last year so last year yeah okay show me what you have okay so nihilism is like huge on tick-tock right now no we don't even know what this means but it's like super bad I think our customers are smarter than that hmm yeah yeah yeah right I mean like oh I don't think so I know that would be insulting to our customers last one better now check this out oh wow yes well I'll wear that face all the time I would look good on someone else why don't you let me pick my own t-shirt so thank you for your help Zoe's public that's it that's a yes right now oh okay madam please welcome chief technology officer of amazon.com dr. Verner Vogel's [Music] nice t-shirt shifty look a lot welcome everyone to the first day event I hope you had a really good revent until now as always it's a learning it's an educational experience and I hope that you guys learned a lot in the past days I I thought I'll do something different this year and really focus on a bit more behind the scenes of AWS and Amazon then on sort of new features and services so the one thing that we've been very fortunate at AWS is that they've been doing this for was it 13 years now and we've gotten a lot of experience in that and then the experience has allowed us to innovate in ways behind the covers that maybe if you've seen all the new services and features that have been launched in the past days but you sort of forget that there's a lot of things that we're doing behind the scenes and this listen there's a quote from from Jeff Bezos he says that sometimes innovation if you want to focus on innovation you have to focus on the things that will never change for your customers because if you do that you create flywheels that will benefit them forever and it's easy to see how that works in retail yeah a larger catalogue means that you have a higher likelihood that you can find what you're looking for well we're playing better guarantees on delivery but then how does that work for AWS what are the things that never change for our customers security performance scale reliability cost efficiency operational excellence all those things never change then anything we do over those parameters will benefit you forever amongst yourself things are not things where we put out a press release about it's really things sort of innovation that we do behind the covers do for example always make sure that we improve performance of of all the components in the system that we have and so I thought that today we look at some of those things that we've done at a Ramirez behind the scenes and do a little bit of a deep dive on them and see what kind of lessons we learned from those and then maybe you'd like those lessons as well and maybe you could take them home and do something with them so the first thing where I would like to talk about its routinization fertilization has been sort of the bread and butter of the computer parts of of any cloud environment from day one now and it's one of those major technical in the pinnings that have really allowed cloud computing to become as big as it is and if you look at classical virtualization yeah it's been actually went from quite a long time in the 60s the major mainframes would already went virtualization but the way we see virtualization today basically the x86 virtualization this really came to life by major research at Stanford a language they won a Stanford resulted in VMware and they made use of some binary rewriting to trap the privileged instructions into the hypervisor then took a different approach and then [Music] actually modify to operating system to make sure that it trapped into the hypervisor to execute these previous instructions so if you look at sort of at least the basis of virtualization you know we really pushed the boundaries of virtualization over time there is something in virtualization called the root I of virtualization tax that's basically if you have all these guest services they are all fighting for the same IO resources and especially you see that in the in the network if you look at sort of when this visualization really scaled up you would see that most of the customers or most of the guest OS s which is significant jitter a very and latency and on their on the network mostly because they were all fighting for the same network device so if that we started to think about how can we radically change this and think about sort of rethinking virtualization since that we can actually create a base for innovation for our customers they also had to deal with the fact that the newer kind of architectures really were being hampered by the old style virtualization basically we really wanted to give our customers performance at almost bare metal if if that will be possible and we saw that with traditional virtualization there was significant overhead in all of that so we really wanted to build a modular system at least that's the things we do at Amazon we're really thinking about sort of taking some of the lessons that we've learned in software and actually apply them to the hardware world in the virtualization world as well basically you should see the tradition of virtualization world as the monolith you have where all the hardware components actually are managed by the same hypervisor and so well if we actually take the lessons from microservices where you have small building blocks we if we can really quickly innovate on and if we can endeavor supplying those to the hardware world as well maybe we can chase the world of virtualization as well so just think about sort of can we create a world where we have all these devices and they have an API the API may be Hardware API like the PCI bus but it's still a hardware hardware it's still an API to which our hardware so let's take a look at sort of all the different steps that we've taken in sort of the evolution of the nitro system now we started off with really traditional virtualization I'm really thinking the first problem we try to solve for side of the network but was basically just transferred let's say eight gigabit file from s3 would result in literally hundreds of thousands of kernel traps and so we really wanted to see whether we could actually solve that particular problem so what we did we actually moved the network component onto a separate cart and so that was really the first version and that was actually what you saw in the c3 instance that we launched in 2013 and that's we really learned a lot from actually offloading the i/o onto a separate cart and they took us actually another two years to really become much more familiar before that would take to actually upload processing onto separate cards that sit on the same server step two was actually in the c4 architecture when we started working with Annapoorna labs to actually move EBS processing or into a separate card so no longer is the sort of the volume processing and the network they're happening on the main CPU that was such a success of the the Nitro carts in the c-4 that an opponent laps actually joined AWS and we started working on the c5 which was a major jump because we could also do all I owe that we were doing on the servers you do sell out all the i/o on two separate cars and the next step will stand to really start thinking about can we actually remove all the other pieces of the hypervisor and move all of those into the control plane on separate cars and that became the complete nitro system so there's a nitro controller that doesn't management and then we also built a new hypervisor that is absolutely really minimized so you can do all of this and so the first ones where the X ones and they actually really became first much more faster which by the performance and this would secure them people could ever have done before so let's take a look at sort of how these words how you interact with it and basically she would create a volume EBS volume you would do a volume attached that would actually talk to the to the EBS control plane who talks to the the EBS cart on the Metro in the light system who then actually makes that as an nvme device notifies two PCI bus and then the the hypervisor traps that and actually mounts that volume them in the in the guest arrests and we've been quite successful with this if you look at sort of the pre nitro hypervisor and this is sort of typical jitter that you would be seeing if you interact with in india's device this is after with a florida on tonight up basically all Jetta has disappeared this has allowed us to double the i ops to EBS increase the throughput tremendously and as you see here that earlier in the event that the the EBS optimized bandwidth has actually increased from 40 gigabytes a second to 19 gigabits a second now this is networking and EBS which is really important to actually all of our customers but if you look at processing what has happened to their processors and if you're David Brown living in the week talked to by the customer who had a requirement of a heaviness of 50 microseconds processing time if you look at this e4 which is before the night to a hypervisor was introduced then you can see that the customers had towable actually meeting meeting the processing your capabilities let me ask the customer to actually try the same thing on a c5 and as you can see the c5 has performance and is almost close to bare metal this is purely because the hypervisor is so thin that it is no longer in the way of guess who has to get the performance that they want the same goes for for story agency yeah the ice these were already beasts instead of storage but you can see that after the introducing or the introduction of nitrile both at the p50 as well as at the end of the performance spectrum there's a rock-solid performance and it increased almost as much itself 4x the same see the sameness if you look at the network optimized instances that we've created the ones with the the N at the back of the year instance name and if he went to repeat in the santoses talk on Monday night you saw the the additional boards that they've created to give you a hundred gig Network and again performance increased 4x and it's not just that we were looking for improving performance if actually offloading all of this onto separate cards you also could improve security just no one killed on 0 yeah we have to remember that Don zero in the old style fertilization is a complete Linux instance basically you could log into it and do a memory dump that is a very big security risk yeah and as such you know by actually removing dom0 you also remove any SSH or other access to the devices and they suit you create a much more secure environment oh thank you I'll do this deform and actually I like this is a very important part of the whole nitro security design basically you have to control the communication flow what can happen is that the night of controller will talk to the hypervisor that's allowed communication the hypervisor is not allowed to communicate back if the hype of take actions to control to actually access the microcontroller you know that the system is compromised it can isolate it you can start investigating it the same goes the external control planes ability the zz2 or abs they are allowed to communicate it in matter controller like we just saw earlier on in the EBS example the NATO controller however is not allowed to take any other actions if the 90 controller XE starts actively going out on the network you again know that the system is compromised you can isolate it this is a unique communication design that allows us to build extremely secure systems now so you really need to be able to do a Myers just with computing in an interested world and as such we created two trusted parts you had just a nice dual system but the nitrous system also sits on the complete trusted Network by itself she said all company all the components can actually talk to each other another thing that we were able to do is actually at encryption to it and you know that I've been almost a big fan of action here so encrypt everything and with nitro we are able to encrypt everything we encrypt your communication out of the nitro cards by default everything is encrypted by default in nitro and not just the things that go out of the network also your local disks are encrypted by default with no performance implications at all and as you can see in that way we've actually improved security significantly and we can't even trust the hosts or the guests yeah we have to make sure that the guests can no longer at no moment actually do anything to the hardware of the machine that we do not allow them to do and one thing for example that we absolutely do not allow them to do is to modify any of the non-volatile memory in the machine and what we also do when the machine boots up to actually create a graphically check all the components of the machine to ensure that they are never compromised in any sense and otherwise we will isolate the machine and actually start investigating the coughing loss that nitro now became a base for innovation now we could do all these other things that we could never do before for example we could do a life updates we could start patching the operating system we could start patching the hypervisor from the Nitro cart without any thing taking down we could add new hypervisors to it we could also start winning bare-metal and we could also create outposts all of these things has been enabled by the fact that we've created this platform called nitro that controls our compute environments but also another innovation that we had been asked came the actually protect more sensitive data we have a number of customers and of course easy to is used for a lot of highly sensitive processing the customer has asked us can you do something more for us that can be are there any innovations that you can do and given that we now at nitro we could do is very unique things and earlier this week we announced tonight for enclaves which allows you to cordon off a little piece of the memory and that memory is in the coulomb enclaves and in that enclaves you can bring your code and the code is continuously checked to be cryptographically correct making sure that that code is never compromised the enclaves also has no access to network or to disk and you as the as the parent instance you can actually communicate it over free Sox with a communicable a secure channel this allowed with quite a few of our customers to have even higher control over sensitive data now if you look at sort of night or related innovation can you figure out where that started yeah we've been able to increase the release of for X number of instances and after that we induced nitro and it really has been a game changer it has really changed the way that we think about our compute environment and the control of our computer climate it also allows us go up the stack and think about sort of can we find support for not just for VMs but can we find support for containers and for and for surface if that we introduced a micro film called firecracker and here to tell us more about firecracker and Fargate is clearly going principle software engineer at the AWS container team well [Music] [Music] hi I'm Claire Liguori and I'm so excited to be here today to take you under the hood on far gate far gate is serverless compute for your containers on far gate we run tens of millions of containers for our customers every week and security is our number one priority for those serverless container workloads virtualization provides a strong isolation boundary between workloads and in Fargo we use virtualization to isolate customers from each other and even to isolate each copy of an application an application and Fargate is made up of one or more containers and each copy of that application runs in its own virtual machine under the hood on Fargate isolating it from all other containers running in Fargate inside that virtual machine is a dedicated kernel network interface data volume and credentials so we ensure application isolation at multiple levels I'd like to show you an example of what a typical application looks like running under the hood running in these isolated virtual machines this is reinvent trivia an online trivia game about reinvent and it's running on Fargate on Tuesday we announce that you can now use Fargate with the elastic community service eks and i'm running this application using eks and Fargate so I'm going to show you what happens under the hood on Fargate when a large traffic spike comes in to this website say for example I showed it in a Rhema keynote to thousands of people so let's first look at what happens when I run this application with eks without Fargate running on my own ec2 instances to handle changes in traffic I've configured kubernetes to auto scale both the number of containers called pods and kubernetes and the number of ec2 instances so with normal traffic like we're seeing here where I'm running a few pods on a few easy to instances now I've just shown the game in the keynote so of course the traffic is gonna flood in with people trying out the game but it takes a little while for kubernetes to spin up enough ec2 instances to run all the pods needed to handle that traffic so while we're waiting for those instances to start up we're under provisioned causing that big latency spike then after a while the traffic is going to start to drop off kubernetes is going to spin down pods and eventually terminate those ec2 instances but that instant scale down tends to lag behind the pods scale down so during this time we're actually over provisioned let's now look at what happens in the same situation but wanting on the under the hood on far gate with Fargate I don't have to worry about having enough ec2 instances to run all of these pods it's serverless compute far gate takes care of isolating each pod in a virtual machine and allocating the right amount of compute per pod so now that traffic spike comes in again new pods are spinning up and far gate is quickly allocating a new virtual machine per pod under the hood there's a small latency spike there as pods start starting up but it's quickly resolved once they're up and running so using far gate the number of pods can react really quickly to changes in traffic to the site kubernetes spins down these pods as traffic is dropping off and I don't have to worry about being over provisioned because I'm using far gate server lists compute side by side here we can really see the difference between running on my own ec2 instances and running on Fargate with easy to we saw both under and over provisioning but with four gate I was able to quickly react to changes in traffic far gate isolated each of my pods with a virtual machine and it allocated the right amount of compute per pod so now that we've seen how far get scaled out and isolates the containers for the serverless compute let's now look at the virtualization technology we use to provide that strong isolation boundary between applications since faregates launch we've used ec2 instances to isolate applications in virtual machines in this model each application is allocated a fresh easy - instance running the Fargate data plane but traditional virtual machines are pretty heavyweight to use for isolating containers traditional virtual machines tend to present a lot of interfaces and devices that containers simply don't care about as a small example a traditional VM will typically present a video card and reserve at least 4 megabytes of memory for graphics but containers almost never have a graphical environment and it can be really small as small as 256 megabytes on Fargate so these are wasted resources when using traditional VMs to isolate containers Fargate provides better efficiency for isolating containers Fargate is purpose-built for isolating containers and functions in virtual machines called micro VMS micro VMs provide the same level of isolation as a traditional vm but they're fast and lightweight they don't have any of the devices they don't need the device model only implements the devices that are actually needed by containers and functions so there is no video card inside of a micro via reserving 4 megabytes of memory like in a traditional VM in fact a micro VM requires less than 5 megabytes of overhead total so it's highly efficient to use for isolating containers and we've been really excited to see open source projects like weave works at night and Kotik containers leveraging firecracker to provide fast efficient isolation in their projects so with firecracker base based us isolation each target application can be allocated a fresh and firecracker micro VM instead of a fresh ec2 instance these micro vias look pretty similar to the ec2 instance I showed you already they look the same on the inside there's no difference to the application container running inside them and they have all the same components like the Fargate data plane but with firecracker were able to achieve better efficiency compared to traditional VMs we can pack many micro VMs onto a single nitro bare metal instance with each micro VM running its own isolated Fargate application as we run more and more afar gate on firecracker that high-density means better efficiency in Fargate I want to share a bit about what we're working on now under the hood on Fargate we're optimizing how we fit firecracker into Fargate we originally ran the same target data plane inside each micro VM just like we did on each easy to instance but that's no longer optimal at our high scale and high-density on nitro bare metal so we've redesigned the Fargate data plane from the ground up for the unique needs of service container compute this new data plane that's under development now is designed to run directly on the Nitro bare metal instance where it manages all of the micro VMs and their container workloads inside them the containers running inside the micro VMs can actually start up faster in this model because they don't have to wait for any other components to start up in the micro via like that far get data plane we're developing a core component of this new Fargate data plane in the open on github the fire cracker container D project fire cracker container D makes it simpler to use fire cracker to isolate containers it enables using the open-source project container d to manage my fire cracker micro VMS it minimizes the overhead required for isolating containers in micro VMS and it exposes container images as block devices to the micro vm so check out can't a fire cracker container d on github for a little sneak peek at the future of part of Fargate under the hood thank you so much [Music] prick clear so it's we of course fortunate that the micro films also allow us to run lumber yeah and I think if you looked at the warts so if you seen the alumni improve over the past years you know what we've done in the in the past was a weeks months and releasing we did some really cool stuff I think give it a many of you rely on FePc boundaries were able to actually really reduce the startup latency in in the fee PC bandwidth in CPC boundaries and if you look at sort of the new concurrency scaling that we've released and all the other components very efficient compare concurrency you can get really good control of your startup times and quite a few other pieces the thing is that we've little under as well as we forget we we also thought that the surface technologies will be first adopted by the say young technology companies and it turns out that's not the case the rapid adoption of service is happening in the enterprise mostly because you really only have to pay for your execution times and the management is so much simpler and as such enterprises are adopting service at tremendous speed and we want to introduce to you Jeff we down the IT executive forefingers to share about how they are making use of these technologies to completely revamp Vanguard Jeffrey [Music] good morning I am thrilled to represent Vanguard today and I'm excited to share with you Vanguard journey to the cloud at Vanguard our core purpose is to take a stand for all investors to treat them fairly and to give them the best chance of investment success let me introduce you to our firm we're a global asset manager we have 30 million investors they entrust us with five point seven trillion dollars of their assets we offer four hundred and fifty investment products we have 17,000 crew that's how we refer to our employees we have no physical branches we're a digital firm 90% of our client interactions come through digital channels we have 40 years of lowering the cost to invest most importantly we have industry best clients satisfaction results from an IT perspective we're big and we're complicated we have global data centers mainframes thousands of servers lots of storage thousands of apps 50,000 endpoints 5,000 technical staff and in our business downtime is not tolerable 60 years ago Vanguard senior IT leaders set out on a transformation we knew that if Vanguard was going to stay competitive in the digital age we needed to be better at the business of IT we wanted to accelerate the pace of innovation we wanted to deliver business value at startup speed continuous delivery DevOps micro services cloud new ways of working CI CD all of these concepts were in play but we knew cloud was the cornerstone to go to go any fast we knew is the linchpin to our success so we set out on a private cloud journey since we had some concerns about public cloud security one year into our journey back in 2015 we sent three of our cloud architects to reinvent upon their return we knew we could not compete with the cloud-based services being delivered by AWS we also knew that building a private cloud was going to take too long and be too expensive a quick huddle with our seaso and other senior leaders we pivoted to public cloud and we selected AWS as our cloud provider with public cloud as our destination we quickly formed the cloud construction team many of whom are in the audience today thanks guys they are full stack in their structure they are outcome oriented in their mission most importantly they have aligned goals so how does a big firm like Vanguard with big data centers get to the cloud what was our starting point we had a traditional tech stack heavily virtualized we had big data platforms monolithic applications I'm not talking about monoliths that are a million lines of code we had monoliths that were 30 40 50 million lines of code and we had an ape as running on Prem for our emerging portfolio of micro services following a design guideline of security first commensurate with a heavily regulated asset manager we build out our accounts be pcs and a security apparatus that entailed over a hundred and fifty security controls with security in place we wanted to start moving some of our workloads to the cloud we started with some of our Web Apps or services we moved our ape as we thought this was the fastest way to start getting some workloads into the cloud at the same time we established secure internet connectivity using route 53 for DNS AWS is Web Application Firewall and cloud front for CDN we also migrated from VPN access to Direct Connect for improved resiliency and bandwidth between our facilities then we won the shut down a rapidly growing on-prem Big Data platforms we became heavy users of s3 and EMR other machine learning capabilities such as comprehend Lex sage maker transcribed and Glu introduced more AWS security services were implemented we use secret managers for authentication credentials we use Macy for discovering and protecting sensitive information and we use shield for DDoS protection we knew we had to get our data closer to the micro services they were still reaching back to our one Prem data center for their data using CDC technology along with Aurora it allowed us to move our data in a similar to schema from our own Prem relational databases some of our micro services solution delivery teams wanted access to data in more of a key value structure so we introduced dynamo using Kinesis for data streaming and lambda for event-driven data transformation we get began moving to dynamo DB and this put us in a position to eliminate our cloud-based data cache our next huge design decision focused on our APIs we pivoted to ECS on Fargate as mentioned earlier in learners remarks we got stronger container isolation we got security out of the box we got integration with other key services especially Identity and Access Management most importantly to me the guy that was paying the AWS bill we got into a pure consumption model and we hooked ECS on Fargate up to dynamo and aurora we are now starting to drain our micro services from our ape as we are accelerating the pace of our monolith decomposition and this should allow us to retire our ape as in the near future finally we started to move the gold copy of bounded context of function and data to the cloud recently we have strategically decided to host our emerging advisory platform on ECS on Fargate this platform supports our advice services that are increasingly in demand from our clients so here's our end state just about a 100% cloud native architecture so what does Vanguard get out of this we know we can reduce the cost of compute by at least 30% we know we can build software 30% faster we know we can deploy our capabilities 20 times faster and all this leads to a better ability to innovate and along the way we get improved resiliency since 1973 Vanguard has been disrupting how investors pursue financial security today marks the 17th time Vanguard has been on stage somewhere it reinvent I'd like to thank AWS for these opportunities I'd like to thank the Vanguard cloud construction team for making all this possible and I'd like to thank our investors who entrust us with their assets so that they can enjoy financial security thank you [Applause] thank you [Music] so it's really cool to hear from from customers as faithful that fans enjoy it especially seeing all the benefits they're getting out at the platform one thing if I think back about when we just talked about nitro I think about the sort of a more general concept it's the fact that that AWS and Amazon as well but AWS especially we always think about evolvable architectures and what what do I mean by that is that you're often you start building an architecture you have to be keeping in mind that that might not be the same software you will be running a year or two years from now and especially when you have to scale up like we have to have to do with in AWS you have to make sure that for example with each order of magnitude you can almost revisit the architecture that you have built and I think probably there's no better example for that and SV the sort of the first real service that we delivered to everyone and I remember that when we were designing s3 we had a number of objects on the board that we thought we would be storing in the first six months and just for the heck of it we had a two orders of magnitude to it we blew through that in the first month and that meant certainly meant that we had to keep a good eye on our architecture now last year my man was on stage to talk about sort of how SV evolved over time and it started off with eight micro services and last year my mom was on stage they were holding a fifty-three microservices in s3 now they're 262 yeah but for example all the new capabilities that you've heard about for example s3 access point which was launched and this keynote that's a new micro service se replication time control is 8 micro services the access analyzed for s3 is another 4 to 5 micro services what it shows is that we are able to evolve the system because we've taken really good care in thinking about that this would be an evolve of all architecture but one of the things that I'm always fired off with s3 and it's one of the core principle industry is reliability mostly because as I always like to say everything fails all the time yeah and mostly if you think about hardware if you think about discs they really have high failure rates but network controllers do it things you have bit flips in memory there's all these things that will happen to you at scale that you need to be able to be prepared for it and as all and that's even the heart we're not even thinking about sort of like Black Swan events like a big cat hit in in one of the components so we're always thinking about how can we reduce the impact if things fail how can we reduce the impact on our customers and we call that blast radius so we're always thinking about how to reduce the blast radius and I've talked last year and last year also people gave a great talk on cell based architectures and so let me just quickly revisit that now if you would have a regional architecture something that spent multiple AZ's a cell-base version of that would sort of this big the smaller components into that such that the blast radius of a potential failure is just limited to the cell itself but also if you have a zonal architecture something that just lives in one zone at the time or a different zones you can also actually make use of cell based architectures for the same approach it is always the case that we want to reduce the blast radius how exactly to pick the size of the cells if you have smaller cells and you can really reduce the blast radius it's easy to test and easy to operate but if you have larger cells the more cost efficient and reduce splits and so you can also see the hole system is easier to operate and the question is always how to really nicely partition your system such that you can actually make use or sell based architectures now if you think about its own oil based service in AWS probably EBS is a really good example so let's take a look at the kind of things that we've done in ABS to really reduce the blast radius in that world yeah so you have to think bank EBS as a block store service but don't think about it as something that has just disks attached it is really the case that there are multiple shirts that actually make up the volume and of course we replicate that yeah so addresses another set of shards that actually is the replication for all of this now to control any type of failures of any of these shards we have a configuration master and the configuration masters it's actually on the second network the second network is a sort of an overflow network is not as big provisioned as as the firm 10 network between ec2 and an EBS but the configuration master sits there and the configuration master does nothing actually the only thing it does is when any of these shards would fail when if the node should fail it's sort of restarts triggers to view application so it's actually pretty simple one yeah so something fails it fails it over to the back up and then start to be replicating to a new set of shards and so the configuration master doesn't have to do that terribly much but if multiple things fail at the same time this thing can get easily overloaded and especially because we're not talking about one disk we're not talking about one volume we are talking about millions and millions and millions of volumes and so if you're only have one configuration master that configuration master actually becomes a single point of failure because it can easy to get overwhelmed so thinking about selves what can we do to improve that now as always there is always this tension between consistency and availability where the cap theorem says that in in the world where you have partitions yeah you cannot have any consistency and availability but consistency in EBS is non-negotiable so we need to make sure that we have an environment where we can actually ensure both high availability and consistency and train and make sure that the consistency never get to eat it off again cell based architectures come back into this yeah so if I apply that to two EBS and EBS master what should we do is you can maybe start off with one in the zone and then you split the zone into - maybe it's Clifton into four and every time you reduce the blast radius of the impact of a failure of an or an overload of the configuration master but you're thinking about this we're thinking about what is actually the smallest unit of cell that we can actually achieve with EBS and then especially for the configuration mas and then it dawned on us that actually the EBS is a very any case in the configuration master Dara cell because not all data needs to be available for all clients that remember that in essence in the old-style database world that meant that you don't have this one database it needs to be accessible by all your planes that's not the case here because it's only the client only the ec2 instance and the EBS volumes that actually need to have access to this particular configuration data so instead of doing so the splitting it up into four we went to millions of tiny databases to ensure that the blast radius in EBS is as small as possible a phacelia is actually comes out of the from a lesson in the world it's the Portuguese man-of-war and it looks like a jellyfish but in essence it just consists out of homeless or thousands of really small microorganisms that have a colony together and present is one thing to you so that's where the name comes from if you look at cell about the data model is in it each volume that gets created gets a partition key and each database in phacelia manages only one partition key and then what you do recreate his colony of micro cells where each of these cells support only one partition key and so the really needs we end up with millions and millions of these cells but that's okay the small and simple to manage and the sail lives in the same environment as the Milt and so actually inside the cell there are several nodes runs Paxos and actually is able to have a distinguished proposal as the master so when seven cells with Paxos to have this state machine we be reliable one of the things that we've been able to do with for sadya as well is to make sure that these cells are always as close to the client as possible because these databases are really tiny and so what often happens is that clients move throughout the AZ that this gets volumes get attached to different service things Lanta so we freeze area were able to make sure that the configuration master lives as close to these cells as possible to the clients as possible in a search again reducing the blast radius so if you look at sort of what the impact has been of at phase area this is a before visalia this is sort of the error rate in a it's an aggregate error rate of accessing configuration master in the pre phacelia world every used always as you can see what happens after that it's actually pretty spectacular so again cell based architectures very very important role here and in this particular case we've been able to go to cell two cells that are as small as one single key understood significantly reducing the blast radius of any potential impact of a failure now if you think about sort of a cell based architectures is one thing there's some other techniques that we've learned over time at Amazon that I think it's very cool because especially if your application is either stateless or has soft states what are the kind of things that you can do yeah and so this is where clients actually are involved in the story as well think about sort of a regional architecture and I just use the deck of cards as representing the different customers the dice giving up here in Vegas if the the diamond one actually starts and failed starts introducing enormous workloads or he pushes something so hard that a bug is being triggered if you have a regional architecture it might take out the first node and what they will do of course it will immediately be trying and if that it will take out everything in your whole region now if you have a cell based architecture basically you map them onto you map your customers on to a particular cell now so if again the same scenario happens that what happens is that the two notes in the cell car taken out okay good in this particular case only 25% of your customers are affected this would take the the clubs well what is that that's clubs and so but what now if we go to something completely different and it's called shuffle sharding basically what you do if a number of nodes and you have you actually take each client twice and actually take do a random hash or just a randomly spread them over the different charts if now diamond is actually introducing failures what you can see is that they're actually not old not another customer that in the still shares the same cell is affected which means basically that if we if you look at the math behind this it's basically combinatorial because in this particular case with eight nodes and a shard size of two the failure rate of the impact of a particular failure is only 3.6 percent of your customers now that's if you have a very small set but imagine if you improve this to a hundred and have a shot size of five then you can see that any one client can almost not impact any of the other clients and so as n grows the convergent combinations grow and you can really make use of the math to actually really build a highly reliable system and really minimize the blast radius of any failure into the system and so it doesn't mean that you have to have a smart client that actually knows how to do eat rice and things like that but for the rest I think the math really builds Israel now if all of this building distributed systems is hard yeah and we've almost on that and we've done this at Amazon for the past 20 25 years at scale that is in parallel and so what many of you have always been asking us how do you guys do this I mean after 25 years you must have a lot of experience in building these kind of systems so how does furnace Amazon do this is sort of build resiliency into that how does Amazon engineer this scale but are the kind of lessons that you have learned about managing operations and so we've been thinking about what we can do there for you and we've gotten our best engineer and architects together who have given been given talks over the past years and I'm happy to announce today the Amazon builders library that will actually bring all of this information for you so that you can build highly reliable systems just like Amazon is doing so we be launching this with firm with 15 articles and in all sorts of different areas and for example improve how to implement health checks whether the best practices around that whether the what is the history of Amazon there what are the kind of things that we've learned there and so I hope that this all helps you build distributed systems at the same scale and the same reliability as that Amazon and AWS is doing and so if I think about that we've we all charging into uncharted territories yeah and then and mixed customer is one that is really charting new territories so sale zone is a very exciting startup that creates wind and solar powered autonomous surface vehicles and they making use of all sorts of technologies to charge everything indices so I'd like to invite the CEO of cildren so busting the hollow to actually come and talk to you about that Sebastian [Music] [Applause] [Music] our oceans are unbelievably vast covering 70% of the planets they act as a powerful engine driving complex planetary system that affect all of humanity and yet ocean data is scarce by any standards and that's because ocean are not just incredibly vast they are also unforgiving dangerous environments now on land we have grown accustomed to billion of connected sensors but at sea we only have hundreds principally for moorings imagine a large steel buoy headed to the ocean floor with a four-mile long cable weighted down by a set of train wheels which is both dangerous to deploy and expensive to maintain now of course satellites have been providing the big picture over the past 25 years but they can only measure a few variables with low resolution and they cannot see through water so we know we can do better after all we've been using robots to study distant world in a solar system for a while so it's about time we start quantifying our own planet because we cannot fix what we cannot measure and what we cannot prepare for what we don't know so this is what we set out to do at zeldron a breakthrough started 10 years ago pursuing the land sailing speed record on March 26 2009 founder Richard Jenkins broke the records in the Mojave Desert a hundred and twenty six point two miles per hour in a wind powered car called the Greenberg mark five that record is still standing and thank you and this was the birth of the sail drone at the core of the record was an innovative wing and tail arrangement similar to what provides lift to an airplane but tilted 90 degrees this is a solution that capable of producing immense forward propulsion for very long periods of time but it only consumes less than three watts of electrical power less than a refrigerator light bulb and each cell drone carries a suite of sensors to measure atmospheric and oceanographic variables with incredible precision things like wind speed and direction the air temperature pressure barometric pressure humidity solar radiation but also in the water water temperature salinity dissolved oxygen dissolved carbon dioxide atmospheric carbon dioxide underwater sound current profile biomass with symmetry down to 1,000 meters I'm talking about a powerhouse of data collection and of course not just one cell drone but a global fleet of cell drone and this incredible planetary infrastructure naturally is powered by AWS cildren is all about endurance and resiliency our robots are working around the clock achieving mission duration of 12 months or more soberness talk about resiliency is the exact reason which shows AWS as a cloud provider a partner that can not only massively scale but I can also provide industrial strength resiliency and it videos delivered enabling us to provide mission-critical data real-time around-the-clock to a global customer base without skipping a beat here's an example of why this resiliency is so critical better fish stock data is very important to manage our fisheries this is information that affects millions of jobs globally and after millennia of growing catches 1996 was peak fisheries catches have been flat indicating severe overfishing of our oceans but how do you manage a resource that you cannot measure so the mission is estimate the biomass of various fish stock such as  sardines mackerel and cildren do this using so nas a device that emits sounds a Sun wave and listens for the echo from the back of fish and from the seabed and by painting the ocean with sound you can develop large statistical model of biomass of a very very significant areas so we do this with fleets of cell drones because the fish migrate so the faster you count them the better the estimate so he's a fleet of sail drone at work of the bearing and truck GC in the US Arctic which is home to about one third of a commercial catch and closer to home we do this work every year along the west coast United States from Vancouver Island in Canada all the way down to the Mexican border this is truly groundbreaking work by autonomous vehicle above the surface our onboard cameras are busy accruing a very large dataset of tagged images which we have to come to think as the imagenet of the ocean and this dataset now power is the very first machine learning a drone optimized for maritime domain awareness which is a place where everything is always moving in every frame a very complex problem this is of course still work-in-progress because the ocean keeps on surprising us and the algorithm encounters novel scenes like a drone riding seal which is very hard to tag earlier this year sail Jones successfully completed the first ever unmanned autonomous circumnavigation of Antarctica you've seen from the deeper a so hardest to go around the track we went around Antarctica 196 days non-stop from New Zealand to New Zealand and data from this mission quantified the key role thank you that southern ocean plays in regulating our planet's carbon dioxide a key driver of climate change so to achieve this feat we relied on some serious data crunching on it areas to navigate from Waypoint to Waypoint first we had to ingest numerous numerical models describing changes in pressure systems which in turn drive a various wind patterns from different direction something that influences the trajectory of the drones in pretty dramatic ways below the surface we had to track currents which are adding around and swirling I can slow a progress and of course waves 60-foot loud large waves different wave height different periods which act as so many's obstacle that can slow a progress or literally destroy the vehicles so as you can see as we zoom in onto the drone you can see that the navigation logic is actually quite complex navigating these multiple fields in the most optical optimal manner and this is a task we accomplished seamlessly with clusters various compute and then sending the resulting instructions to the vehicles via satellite along the term vision is one we called the quantified planet it's not about just one failed road we're dividing the entire global ocean into 1,000 subdomains each six by six degree in size and we're working to deploy a drone in each of those boxes the goal is to achieve planetary coverage and thereby help deliver better insights into those planetary systems that affect humanity and we can do this because these systems like weather can now be modeled numerically on AWS using new instance types like P 3 and C 5 n instead of the old supercomputers so combining the Adria's compute and cell Jones unprecedented institute data we can deliver new insights into global precipitation for example or into global wind monitoring hurricanes storms and typhoons and of course for long-term monitoring of heat fluxes in the tropical Pacific the famous El Nino and we do this delivery in all all in near-real-time we compute package and deliver these insights in the hands of all users globally via sail drone forecast app so what's next or next frontier is mapping the global seabed as hard as it may be to believe 85 percent of the global seabed remains unmapped and unexplored we are hard at work to solve this data collection problem but big problem need big solutions so we have built the ultimate machine for this task and I'm very proud to present the sail John surveyor which is a 72 foot long wind powered vehicle carrying a one-ton sonar system capable of imaging the bottom of the sea down to 8,000 meters that's 24,000 feet so together with the partners we aim to complete this mission within the next 10 years creating the very first complete map of Earth for the benefit of humanity it's a true planetary endeavor and it involves unprecedented scope and data set and like so much of a work it's really made possible by our collaboration with AWS store and process this this amazing set of critical data so we excited to see what the future holds as we explore new Rams and new possibilities with sale drone and we look forward to continuing strengthening the amazing partnership we have with AWS thank you [Applause] [Music] thank you a big part of course of weather predictions fluid dynamics if you want to see how you can treat AWS as a super computer you should he watch Peter the scientist presentation from Monday night where he really explains how you can make use of easy to instances to build supercomputers I'm going to take a little bit of a different track now looking a bit at more at big industry kind of stuff that we've seen doing seen happening especially in the world of manufacturing and so industry 1.0 was of course was at the end of the 1800s when steam machine machines came into action and we saw the whole industrial revolution started to take place and the gene cards starting to be invented and so if you now look at sort of film industry 1.0 moving over to 2.0 is where electricity gets introduced it becomes this big source of power and you see you start to see major shifts in the manufacturing process as well because the first is the first assembly lines are being built in those things whereas 3.0 is when all the electronics start to the wife and all factory floor start to be sort of controlled for PCs and things like that and then in the the next phase in what we now this these days called industry 4.0 is where automation starts taking place now everything becomes automated and especially also things like logistics and everything else around but it's this having VD at industry 4.0 because I don't really believe that so much you know because if we look in in 2015 the average age of a of the the equipment in factories is 22 years and that they have never been so old as since 1935 in fact the equipment really is too old to be able to produce the data that we want to get out of this to create insights and so I don't think we are at 4.0 yet because factories and manufacturing sites need to change significantly if we really want to start creating insights into this world yeah and if you look at all the different pieces that are still still really a big deal in manufacturing sites there is no data that is helping them create that insights and this data needs to start flowing out of these manufacturing sites into places where you can actually do do the end of it and if you want to create insights there's a lot of insights to be had there I mean if I look for example at you know predictive maintenance or you know autonomous transportation variables collaborative robots all of these kind of things is in my eyes for industry 4.0 is about but it is hardly any manufacturing there is already at that pace and today generally factories are already producing about eighteen hundred petabytes of data a year but it's only a small fraction of others needed to really create the insights into this world and maybe that is in manufacturers or whether it is in smart cities or if you actually start moving this data into the cloud you can actually have multi layers approach and whether you want to do things that this is actually where we are here then or if you want to go out and actually start thinking about transportation and how companies came up just make smarter decisions about computation or for example move out into the level of of cities or go even further yeah go up on think about sort of what are the kind of things that we can and have to do around agriculture the world actually grows more and more the expectation is above its 2050 we have 35% more people in this world that need to be fed all the way all the way to transportation yeah we can have all these multiple layers of how sort of we should be collecting data and how this could data's need to really grow together to create new insights I sort of if I think about that we think about sort of bring that back to how Amazon operates I think back and sort of the physical parts of amazon.com and that's the fulfillment centers yeah so in the in the early days we sold books and we're about three million books when available when Amazon started and of course fulfillment was was challenging but you know they had their own logistical challenge but it's actually relatively simple however if you need to start selling TVs and toothpaste and pillows and shoes and coffee things become a lot more complex yeah and our plans was really to do that so in the early days she looked like a lot like a and like a normal warehouse would look like but that definitely is no longer the case that we ain't to really sort of create better deliveries well be we've moved a long moment from $25 free shipping and then to two-day shipping and one-day shipping now and if you is prime now you get it within an hour so how do all of these things change while you still need to improve work the worker safety and make sure that you can do the guarantees at the speed that you would like to do of course in all of that you know in the typical warehouse there's about 4 million bins and about 10 million items we use computer vision throughout the systems we set it out in enable Scotland Manhattan grid style where the paths are where the bitsy pods the kefir systems can actually follow they bring him to earth where the workers are such as you can put things in the box together and make sure that actually if two items that you've ordered that they do go into the same box together and let's search we use machine learning to actually predict how to do these things now and it's definitely in four different areas yeah this forecasting what products should we be buying and then there is who should we buy it from from is this from the large manufacturers is from a monomer pop shop and then the question is where do we place them and then if we will sleep place them what kind of promises can we give to our customers in terms of delivery and this is actually pretty challenging yeah because actually if it's a very popular product like something seasonal like like warm socks or Sun hats in the summer that's a easy year to do or if it's just coffee and things like that those are all easy things to predict because they actually sold across the world but what now if you need to if you have a Nicolas Cage reversible sequined pillow cover well if you have that one that's harder to predict where you would actually have to place that one and so but what you can do you can make a use of machine learning and look at thousands of thousands of similar items and start making predictions where you should buy them so that if you're in Vegas you want this pillow you probably can get it in the coming two days and that's a real machine living place in increasingly important role if you look at many of the things that we've done at Amazon in the past 20 25 years machine learning is probably at the basis of all of that and it is a small stuff like fenders and early detection of for detection now all of these kind of things that are all happening behind the covers but also major innovations like Alexa yeah or the drones or scout all of these are driven by machine learning or probably the most extreme bomb that you all know about is the Amazon ghost or you could just walk in take things off the shelf put it in your back and walk out you get charged there's enough challenges with all of that then you have to first figure out what in account is and how the account is moving for the story he is he and a lot of master CDV presentation of that and so some of this is he turning yellow and a Mesa we actually not really certain rudy account what in counties that is actually moving there with all those challenges i with computer vision is actually products now some some products are the same but they crumbled yeah or other products are actually really almost identical but they're different products and then also a lot of people actually interacting with the store and so we've invested a lot in generating synthetic information sisty we can actually start to making these algorithms more efficient and more accurate and with all the results in you can just scan in where you walk into the store and walk out and get charged but if we look at sort of outside of AWS outside of amazon there's so many cool things happening in the physical world that are actually powered by AWS so let's take a look at the few of those they are first of all about sort of workplace safety this is one of my favorite examples of customers that went on the on the path to to improve the quality of their operations and the safety this is wood site they are a liquid natural gas producer in australia and have actually significant operation one of the parts of that producing liquid near ignited the natural LPG whatever is actually to freeze it down to a whole nother sixty degrees under cell under zero and so that happens in this massive refrigerator over here and one of the things there in the old world if you would have sensors on them the only thing that these sensors would do is allowing you if something went wrong they didn't have any ability to produce data would site move to a system where they actually were producing data and actually so there's a process part of the Assessor failure part that's called foamy and that boats always saw there's an alarm going off and then the whole factory would have to shut down for maybe even weeks and it's a pretty hazardous environment and so what happens now that these sensors and the stencil 10,000 sensors in this refrigerator if actually they now can actually start to predict foaming and no longer create these hazardous conditions for their customers but they so after that this is the first experiment which which they did and after that they flipped the switch and brought two hundred thousand sensors online and actually started to create autonomous environments for their workers all these environments are extremely hazardous and so on one hand they have autonomous platforms that are out in the sea and there's no workers on there there's only one box and in this particular case you can see the robots that are actually moving throughout their plant which is an extremely hazardous plant without any danger to the workers because the workers sit in the in a centralized environment where they can actually see what these robots are also seeing this is boxes that you see popping up are IOT sensors and they run AWS IOT core there and they're able to actually take actions they sort of control things need to this take happen instead of just having been having to send people in big hazardous suits out there to do the work for them well Joe is in this another interesting company they make wearable devices to improve workplace safety like safety belts and gloves and things like that just so they can track how workers move for hazardous environments and that's one interesting story that they told me is that one of the major US airlines actually use these safety belts to measure how far people are actually bending over how hard I work us are bending over whether they actually used the right techniques to pick things up from the ground to really improve worker health United Rentals is moving to create these massive machineries that are completely autonomous so there's nobody longer leads to work with these massive machineries in hazardous environments another area that is really interesting for in this digital sort of physical world combination is the way that cities are being made smiling and there's a lot of work going on in that particular world and these are just a few fingers few interesting examples ShotSpotter measures gun activity in the city and apparently for every gang-related homicide there are a hundred gun fight when hundred gun shot accidents that are never reported they make use of multiple sensors to really be able to accurately and within 60 seconds be able to actually identify where the location was of a gunshot and sent and have law enforcement actually take that out for that the city of Miami has taken this on and in 2014 and since then homicides have dropped thirty five percent in May ma a.m. the city of Virginia Beach has put sensors out in the ocean to start measuring and predicting when floods are going to happen the same is for my everything they actually put was it sensors in around the streets so she can optimize transportation got a very interesting sort of physical digital world instead of agriculture and this there's a lot of work going on is about in finding new ways to feed the future and there's two of our interesting customers in that space one is the climate corporation they actually make use of digital we hold digital architecture this cultural climate fields for you that make use of all the dis censoring of their tractors and other equipment on site as well as set like imagery to help farmers optimize yields the farmers business network is an interesting one because here is farmers that are sharing anonymously information about the yields of their fields and the kind of crops that are going such that they can actually have collective bargaining with seed providers as well as setting the prices for the crops that they are selling and the same goes for the world of transportation there and whether it is Siemens that are putting sensors all around the world on train tracks because the biggest cause of delay is often the bending of the rails and things like that so they cannot measure that deutsche bahn the big german transportation provider is is putting this out in also in sensors in each of their trains so they can accurately measure delays and things like that Vantage power is an interesting customer because they've sensors in all the electric buses so they can do preventive maintenance of the batteries of these verses and then if you think about sort of coming back to where we talked about earlier it's really modern modernization of manufacturing this is all about creating data streams out of manufacturing to actually really optimize insights and to talk more about this we have a really interesting next speaker he has won the CIO Innovation Award of CEO magazine this year to talk more about this modernization of manufacturing is the group CIO Forks wagon dr. Martin Huffman hi I'm Martin Hoffman from Volkswagen volkswagen started with the beetle today we are a group of 12 iconic automotive brands and the brands with our portfolio are VW o D Porsche Bentley Bugatti Lamborghini seeit Skoda Ducati motorcycles M en and Scania trucks we have 365 models in our portfolio so if you want to drive a different model every day it's going to take you a year of pure fun and joy I promise we produce 11 million vehicles per year which about 44,000 a day why do I mention this number this is a massive scale and a requirement for any supply chain on a global basis to run in a very efficient and effective way so our supply chain is highly complex and global we have more than 1500 suppliers globally and they produce a manufacturer every day more than 200 million components and parts and these components and parts have to be shipped into our global factories so there are 18,000 trucks per day shipping components into our Factory 7700 ships on the oceans crossing the oceans with produced vehicles and in a year is about 75 million cubic meters of material that we process and we do this in hundred and twenty-two factories worldwide five in North America nine in Brazil and Argentina 71 Europe for in South Africa 33 China and India all these factories are running on different grown technology at a different age and so it's very hard to scale from an artistic so what we are doing together with EWS we're lifting 122 factories into the cloud and we do this with one common global architecture that we are building with AWS so this entire project is what we call the Volkswagen industrial cloud right now probably the biggest IOT project in the manufacturing world and we chose AWS not only because of technology but because of the ability to scale to provide us with standards for our factories implementation speed that we are getting from AWS methodologies the flexibility and the culture is helping us to really accelerate this project the way we build it in the center we built on AWS cloud what we call the digital production platform this is an AWS cloud platform in which we connect all the machines the robots pressure printer the bodyshop assembly machines the logistic system they all get connected into the cloud on which we run heavy lifting ai and machine learning algorithms IOT services and security controls to constantly optimize and compute situation of the factory and then what we do is on top of the AWS cloud we put what we call the Volkswagen Group app store this is where we develop use case based applications for the factory we develop it once and copy paste in all our factories that can download it from the cloud applications like predictive maintenance algorithms with manage and optimize factory functions so this is our digital production platform now if you take it and extend it to the outside world which means we are integrating connecting all our suppliers into that cloud we're integrating our logistics companies equipment manufacturers and all our business partners will be connected to the industrial cloud we're even that that we will open it up for other automotive manufacturers to use applications and technology in the industrial cloud they also invited to contribute and to load software into the cloud like an open source ecosystem so this is going to be one of the biggest ecosystems that will be built in the industry the architecture behind I can't go into all the details and you know them better than I do but there are four major building blocks that they were using the architecture one is the Ooty operation technology IT gateway connecting machines robots into the cloud it's the edge gateway because a lot of the functions and workloads have to run close to the machines we're using outpost to outpost per factory because there's several applications that have to run on Prem and this is why we are using outpost for our plant cloud and the fourth element is our DPP enterprise cloud Lucey application framework highly standardized we will be able to quickly higher speed develop applications for production system and keep them in the cloud now let me show you something [Applause] this is where it all happens this the shop floor this were the AWS cloud gets married with our machines with robots with welding systems and all you can imagine running a factory so thousands of sensors are constantly sending data into the AWS cloud into a digital production platform so that algorithms machine learning algorithms can constantly optimize setting of the factories and parameters of the machines and will also run applications for our employees based on the cloud to better manage our factory system as Rana mentioned earlier in his talk transformation in manufacturing those way beyond automation it's about full integration of all data points in the factory so Volkswagen s reload is the foundation for our new production strategy in the future we will have autonomous factories darkroom factories and this is the start in that direction but we will also reduce factory cost by doing that we define IT standards between the plants we increase product production program fulfilment that means delivering vehicles on time to our customers and our product launches will be much faster so we can come to market earlier with new vehicles in numbers it's a 30% increase in productivity we can decrease a factory cost by 30 percent and we are targeting 1 billion euros of savings in our supply chain has been an incredible journey with AWS as a partner thank you very much [Applause] [Music] so we have been fortunate in the past years to travel the world and meet with many of our customers and it's always interesting to see that there's a certain group of customers younger businesses that are trying to solve really part-human problems and whether that is around education whether it is around health all of them are working hard in tackling the hardest human problems that we have at this moment for example apple bite is a company out of Bergen it's in Bergen in Norway and they're working on how to create protein yeah the the protein is likely to become the major food source in the future and so what they do they grow Salmons and append like that easily has two hundred thousand sevenths and so it's interesting to see that they allow us to come on site and actually video this so we started a a TV series called now go built and there's been eight episodes by now and they all deal with some of the world's hardest problems we're young businesses are really tackling hearts problems in collaboration with AWS so this is a runt food this is one of my favorite this was the first episode we did it is a company called how a token in Jakarta and the problem in Indonesia is that many of the farmers if for small farm holders have no identity and as such they cannot get loans to buy seeds for their farms they have to go to long Chuck who they're in a militia often charged 60% and so by giving these farmers an identity but not only identity also measure the size of the plot of land and the yield of the plot of land they're able to give these farmers an identity and data that they can take to the banks and the banks are eager to actually give these farmers loans because the repay rate is almost a hundred percent so again these are companies that are really tackling really hard human problems but there was one episode there was a bit more fun in all of this and that's the episode we released today the episode that we did in Amsterdam Amsterdam I love this city my city I'm in Amsterdam for one of my favorite batteries the Amsterdam dance event it is exciting to see the role that technology is playing in removing obstacles between the solar the musician's health and the wharf sound it helps us do one thing so the other episode that we were that is released last week was in Rio de Janeiro where it's all about health care how to find new ways of providing health care to the poorest people in Brazil even though Brazil has a National Health Service they are not capable of actually keeping up with the needs of of the bridge Brazilians and especially not the poor resilience so I urge you to come check it out these are very inspirational stories or very young businesses on that running on AWS solving some of the world's hardest problems well with all of that I hope to see you guys tonight so have fun at the party and go built