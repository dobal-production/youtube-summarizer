안녕하세요 여러분, 이 세션에 오신 것을 환영합니다. Arc 3.12 (하이퍼스케일용 AWS 기반 셀 기반 마이크로서비스 아키텍처) 로의 여정에 오신 것을 환영합니다. 저는 디지털 네이티브 비즈니스 고객을 지원하는 AWS의 수석 솔루션 아키텍트입니다. 이들은 클라우드 우선 접근 방식을 취하고 비즈니스 성장을 지원하기 위해 하이퍼스케일 환경을 운영하는 고객들입니다. 저는 Doordash의 동료 J Wallace와 함께 했습니다. 안녕하세요 여러분 제 이름은 Jay입니다. Doordash의 클라우드 인프라 엔지니어링 매니저로 근무하고 있습니다. 저는 회사에서 약 5년 동안 근무했습니다.좋습니다. 오늘 아침, 저는 오늘 아침 이 세션에서 지난 5년 동안 우리의 아키텍처가 바뀌는 것을 볼 수 있었기 때문에 오늘 세션을 통해 여러분과 공유할 아젠다를 간단히 살펴보겠습니다. 가장 빠르게 성장하고 있는 지역 상거래를 지원하는 Lost My Delivery 플랫폼을 갖춘 기술 회사인 Doordash의 여정 (Journey of Doordash) 이라는 여정 (Monarith) 의 초창기부터 시작하여 마이크로 서비스 아키텍처로 어떻게 발전해 왔는지 채택 패턴: 하이퍼스케일이 운영의 어려움을 의미하는 바를 살펴보겠습니다.하이퍼스케일에서의 마이크로서비스와 셀 기반 아키텍처가 이러한 문제를 해결하는 데 어떻게 도움이 되는지에 대해서도 간략하게 살펴보겠습니다. 그런 다음 특히 Doordash Supercell (이 아키텍처를 구현한 프로젝트) 로 관심을 돌리고 몇 가지 주요 학습 내용과 다음 단계로 세션을 마치겠습니다. 그러면 AWS 네트워킹 서비스에 어느 정도 익숙해질 것으로 기대됩니다. 그런 다음 AWS에서 사용할 수 있는 몇 가지 컴퓨팅 및 데이터베이스 옵션을 저와 Jay가 설명하겠습니다. 제이드가 대시 하부를 거니는 동안 우리의 이야기를 끼워 넣어보세요여정을 통해 아키텍처와 AWS 서비스 에코시스템의 개념을 살펴보겠습니다. 먼저 Doordash의 비즈니스 모델을 살펴보겠습니다. 감사합니다. 많은 분들이 Doordash에 대해 들어 보셨거나 사용해 보셨을 것입니다. 하지만 익숙하지 않은 분들을 위해 Doodash는 기술 기술 회사이며 소비자들이 좋아하는 지역 비즈니스와 연결하는 것이 주요 목표입니다. 오늘날 우리는 27개국에서 사업을 운영하고 있습니다. 우리 비즈니스에 대해 조금 더 자세히 설명해 드리겠습니다. 소비자, 판매자, 우리 회사로 구성된 3면 마켓플레이스 운영Dasher는 식품부터 식료품, 가정용품에 이르기까지 다양한 업종에서 사업을 운영하고 있습니다. 오늘날 당사는 약 2,500만 명의 소비자와 55,000명의 판매자와 백만 Dasher 이상의 Dasher를 통해 플랫폼 내 배송 서비스를 제공하고 있습니다. 물론 전 세계 15,000명의 직원들의 노력 없이는 이 모든 것이 가능하지 않을 것입니다. 오늘 아침부터 Doordash의 아키텍처가 어떻게 변했는지, 그리고 무엇이 이러한 결정을 내렸는지 구체적으로 살펴보고자 합니다. 음 2013년은 사실 이걸 시작하기에 정말 좋은 곳이에요.이 해는 Doordash가 설립된 해였습니다. 대부분의 초기 스타트업들과 마찬가지로 초기에는 개발 및 납품에 초점을 맞추고 있습니다. 그래서 창립자들은 이를 알고 있었으며 이를 통해 팀은 신속하게 움직여 전면과 전면 모두에 통일된 프레임워크를 제공할 수 있었습니다. 모놀리스의 그림을 보면 우리와 크게 다르지 않습니다. 우리의 모놀리스는 Django 웹 앱이었고 우리의 메인 DB는 postgres였습니다. 그리고 이것은 기본적으로 많은 모놀리스가 있기 때문에 모노리스는 일반적으로대규모 시스템은 단일 코드 베이스를 사용하고 단일 유닛 또는 단일 서비스로 배포되며 일반적으로 로드 밸런서 뒤에 배치되며 초기에는 많은 이점이 있습니다. 음, 첫 번째 장점 중 하나는 단순성에 관한 것입니다. 모노리스는 구축, 테스트 및 배포가 간편하고 수평적으로 확장이 용이하며 다양한 구성 요소 간에 공유가 많기 때문에 기본적으로 한 번만 작업을 수행하면 구성 요소를 공유할 수 있습니다. 로깅, 파이프라인, 구성 관리 등과 같은 것을 구성 요소 전반에 걸쳐 공유하세요.물론 마지막으로 성능은 모놀리스와 관련하여 정말 큰 장점입니다. 왜냐하면 모든 것이 모놀리스의 일부인 다양한 서비스 간의 메모리 내 호출이기 때문에 내부 서비스 네트워크 지연 시간과 씨름할 필요가 없기 때문입니다. 물론 이러한 단점이 없는 것은 아닙니다. 음, 그렇지 않으면 우리는 항상 모놀리스를 사용합니다. 첫 번째는 코드 베이스의 관리 또는 확장성 및 지속적 배포에 영향을 미치는 긴밀한 결합입니다. 생각해 보세요. 새로운 기능을 없애고 싶다면 전체 배포를 해야 합니다.코드 기반이 커짐에 따라 엔지니어가 새로운 기능을 이해하고 기여하기 시작하는 것은 필연적으로 더 어려워집니다. 새로운 기능을 추가하는 것은 매우 느립니다. 마지막으로 공유가 장점이라는 것을 앞서 말씀드렸지만 코드베이스 전체에서 모듈을 공유하는 경우 폭발 반경 문제가 발생하여 누군가가 공유 모듈을 변경하면 바람직하지 않은 결과를 초래할 수 있다는 단점도 있습니다. 그 결과 관련 없는 서비스가 실패를 일으켰고 우리에게는 그 정도가 상당했습니다.우리가 최초의 마이크로서비스를 갖게 된 2014년까지의 세계 현황, 그것은 로지스틱스 AI 서비스였습니다. 저는 여기서 마이크로서비스라는 용어를 대대적으로 재구성하거나 그런 것의 일부가 아니었기 때문에 아주 대대적으로 재구성하거나 그런 것이 아니라 파이썬에서 CPU를 많이 사용하는 작업에 Scala가 더 나은 선택이었기 때문입니다. 그리고 이것은 사실 그리 드문 일이 아닙니다. 음, 지금 여러분의 여정에서 실제로 볼 수도 있습니다. 새로운 서비스를 출시하거나 독립적으로 작업을 진행하고 있는 팀이 있을 수 있으며, 그들은 원하는 것을 원하고 있습니다.고객의 요구에 더 잘 맞는 특정 프레임워크나 기술을 활용하기 위해 2017년에 우리는 모놀리스 외부에서 다양한 서비스를 가동하기 시작했지만, 분명한 방향과 의도가 부족했습니다. 우리의 모놀리스는 하나의 심각한 한계에 부딪히기 시작했습니다. 팀 자체가 초창기부터 크게 성장했기 때문에 소프트웨어를 더 자주 출시하지 못했고 개별 배포 가능 유닛도 없었기 때문에 파이프라인의 시작이 매우 느렸습니다. 단위 테스트를 했기 때문에 매우 느리게 되었습니다.그 결과 엔지니어들이 일부 단위 테스트를 생략하거나 특정 배포에서 보장이 불가능하다는 의미의 소프트웨어 배포 속도가 느릴 것이라는 사실을 받아들이는 결과를 낳았습니다. 음, 그리고 앞서 언급한 것처럼 엔지니어가 시작하기 위해서는 가파른 학습 곡선이 있었습니다. (음), 이전 슬라이드에서 언급한 것처럼 장애 격리가 없었기 때문에 업데이트가 한 곳에서 이루어졌습니다. 또 다른 단계에서 문제가 발생하는 경우가 많았습니다. 다음 단계는 회사가 올인했던 2018년이었습니다.마이크로서비스 이 단계에서 우리는 회사로서 계속 성장하여 다양한 새로운 업종으로 성장했으며 주문량이 증가하고 고객이 증가하고 판매자도 늘어났습니다. 하지만 당시에는 엔지니어가 독립적으로 구성 요소와 서비스를 작업하여 민첩성을 높일 수 있도록 하는 데 중점을 두었습니다. 하지만 이 시점에서 모노리스 자체는 여전히 많은 중요 흐름의 중간에 있었습니다. ku에서 사람들이 독립적으로 작업할 수 있는 마이크로서비스가 많이 있었습니다. 버네티스, 하지만 안타깝게도 이러한 마이크로서비스 중 상당수는 이러한 강력한 문제를 안고 있었습니다.의존성 — 신뢰성은 실제로 강력하게 얽혀 있는 서비스의 신뢰성의 산물이 되었습니다. 이것은 실제로 분산 모놀리스라고 불리우며 안티 패턴입니다. 2019년에 우리는 대부분의 노력을 다시 집중했고 마이크로서비스에 대해 생각하던 방식에 대해 훨씬 더 신중한 접근 방식을 취했습니다. 그리고 메인 DB와 도메인별 데이터베이스에서 모든 것을 가져오려는 공격적인 추진이 있었고, 전반적으로 표준도 만들었습니다. 주목할 가치가 있는 것은 우리가 kotlin의 채택을 추진한다는 것입니다.컨텍스트를 알려드리자면, 초창기에는 Python, go 또는 Java로 서비스를 작성하는 것이 그리 드문 일이 아니었지만, 이러한 새로운 표준을 채택함으로써 팀은 모든 서비스가 가지고 있던 일반적인 문제나 공유 문제를 해결하는 공통 라이브러리를 작성하는 데 많은 투자를 할 수 있었습니다. 예를 들어, 즉시 사용 가능한 요청, 대체 기술, 로드 쉐딩, 분산 추적 등을 통해 더 나은 가시성을 확보할 수 있었으며, 전반적으로 이 멀티가 실제로 등장했습니다. 여러 프런트 엔드로 구성된 레이어 아키텍처 (BFF)프런트엔드에 기능을 제공한 계층, 즉 백엔드와의 um 상호 작용을 조정하여 핵심 기능이나 백엔드 계층 (거의 모든 마이크로서비스의 전부), 즉 핵심 서비스에서 활용하는 플랫폼 서비스가 있었습니다. ID는 플랫폼 서비스의 좋은 예이고, 그 다음에는 기본 인프라 자체라고 생각할 수 있습니다. 예를 들어 데이터베이스, 데이터베이스 캐시, 인프라 팀에서 관리하던 모든 것을 큐로 볼 수 있습니다. Anon에게 전달하여 조금 더 공유하겠습니다.마이크로서비스가 어떤 모습인지에 대해 그는 일반적인 채택이 어떻게 보이는지에 대해 잘 알고 있을 것입니다. Jay가 바로 여기에서 잘 언급한 마이크로서비스처럼 애플리케이션을 독립적으로 배포 및 확장할 수 있는 느슨하게 결합된 소규모 자율 서비스로 구성할 수 있으며 이는 몇 가지 이점을 제공합니다. 따라서 먼저 애플리케이션을 확장하려면 애플리케이션의 특정 구성 요소만 확장하면 됩니다. 이제 이러한 마이크로 서비스는 느슨하게 결합되어 있으므로 그렇지 않습니다. 서로 상호 의존적이기 때문에개별 테스트가 가능하므로 시간이 지남에 따라 애플리케이션이 변화에 더 잘 적응할 수 있습니다. 혼란스러운 크고 복잡한 애플리케이션을 팀이 전문화할 수 있는 작은 애플리케이션으로 나누는 데 도움이 됩니다. 이를 통해 개발 팀이 더 빠르게 생산성을 높일 수 있습니다. 각 소규모 서비스는 테스트하기 쉽고 디버그하기 쉽습니다. 이제 이러한 종류의 아키텍처는 원래 모네와 동일한 언어 또는 기술 스택에 얽매이지 않기 때문에 이 팀에게 기술적 자유도 제공합니다. 이 모든 것에서 시작되었습니다도어대시의 여정에서 살펴본 것처럼 마이크로서비스 아키텍처로 마이그레이션하는 방법 중 하나는 스트랭글러 패턴 (Strangler pattern) 이라는 Martin Fowler가 개발한 패턴입니다. 이 패턴의 기본 개념은 현재 시스템을 중심으로 새로운 기능과 시스템을 구축하기 시작하여 둘 다 동시에 공존할 수 있기 때문에 애플리케이션에 영향을 주지 않고 마이크로서비스로 마이그레이션할 수 있습니다. 지속적인 운영이므로 기본적으로 두 가지 방식으로 애플리케이션을 리팩토링하고 새로운 기능을 추가합니다.별도의 마이크로 서비스로 만들고 마이크로서비스가 모놀리스에서 일부 기능을 가져와서 별도의 마이크로서비스로 만들도록 합니다. 이제 여기서 피해야 할 패턴 중 하나는 모놀리스 자체에 새로운 기능을 구축하는 것입니다. 알다시피 중간 수준의 애플리케이션이 마이크로서비스를 호출하도록 만드는 것은 축소하는 대신 모놀리스에 추가 코드를 도입하기 때문에 피해야 할 또 다른 패턴은 세분화될 것입니다. 기술 및 인프라를 사용하는 마이크로 서비스 접근 방식분해 대신 서비스 분해를 위한 도메인 기반 설계와 같은 접근 방식을 사용합니다. 이제 앞서 말씀드린 기술적 자유는 일부 서비스를 탄력적 컴퓨팅 (Cloud ec2) 에서 실행할 수 있다는 의미입니다. 즉, 다양한 유형의 워크로드에 적합한 다양한 인스턴스 유형을 가상 머신에 제공하고 이를 탄력적 로드 밸런서 뒤에서 실행할 수 있습니다. 이제 컨테이너화된 애플리케이션을 구축, 배포 및 확장할 수 있는 완전 관리형 서비스인 Elastic Container Service를 사용하여 일부 서비스를 컨테이너로 실행할 수 있습니다. 당신은 가지고 있습니다kubernetes 워크로드: Kubernetes 컨트롤 플레이의 가용성과 확장성을 관리하는 탄력적인 kubernetes 서비스를 활용할 수 있습니다. 이제 좀 더 이벤트 중심적인 서비스가 있고 서버리스 이벤트 기반 컴퓨팅을 제공하고 서버를 프로비저닝하거나 관리할 필요 없이 모든 종류의 애플리케이션을 실행할 수 있는 기능을 제공하는 AWS Lambda를 사용하고 있다고 가정해 보겠습니다. 그런 다음 데이터베이스를 선택하려면 Amazon RDS부터 시작하여 관련 목적으로 구축된 데이터베이스를 선택할 수 있습니다. 다양한 데이터베이스 엔진 유형과 Amazon을 지원하는 데이터베이스 서비스Arora는 완벽한 MySQL 및 postgres 호환성과 함께 높은 가용성과 확장성을 제공합니다. nosql 데이터 스토어를 찾고 있다면 완전 관리형 서비스인 Amazon Dynamo DB와 nosql 데이터 스토어를 제공하는 서버리스가 있고, 다른 모든 유형의 데이터에 대해서는 11줄의 내구성과 고가용성을 제공하는 Amazon S3가 있습니다. 이제 AWS에는 Amazon SNS Amazon sqs Event Bridge와 같은 일부 메시징 서비스가 있습니다. 모든 데이터 스트림을 지원할 수 있습니다. 이것들은 느슨하게 결합된 아키텍처를 구축하는 데 도움이 되며,개발자가 API를 게시하고 보호할 수 있게 해주는 완전 관리형 서비스인 Amazon API Gateway를 사용하여 마이크로서비스를 API로 공개하십시오. 이제 이 마이크로서비스 아키텍처는 확실히 유망하겠지만, 이 과정에서 직면하는 몇 가지 과제가 있습니다. 우선 올바른 서비스 경계를 식별하여 모든 서비스가 느슨하게 결합되고 자율적으로 작동하도록 하는 것이 이 시스템의 복잡한 환경에서 각 서비스가 데이터 스토어 전체에서 독립적으로 데이터를 관리하는 것이 어렵습니다. 데이터중복성은 현실이 됩니다. 예를 들어 한 서비스의 특정 트랜잭션에 대해 저장될 수 있는 데이터, 분석, 보고 등과 같은 이유로 동일한 데이터가 다른 서비스에 저장될 수 있는 데이터를 예로 들 수 있으며, 전체 시스템은 모든 서비스가 작업을 수행한 후에만 일관된 상태가 됩니다. 모놀리스 내의 인메모리 호출은 네트워크의 프로세스 간에 전송되는 호출이 되어 지연, 성능 지연에 대한 우려도 함께 발생합니다. 모든 모니터링 도구 및 테스트 도구상황이 빠르게 통제 불능 상태가 될 수 있고 모니터링해야 할 서비스가 더 많아지고 각 서비스에는 자체 잠금 세트가 있습니다. 이 파일은 문제의 원인을 찾기 어렵게 만듭니다. 따라서 서비스 간의 이러한 상호 의존성을 면밀히 모니터링해야 하며, 운영 중단이나 업그레이드로 인한 서비스 다운타임으로 인해 다운스트림 영향이 연쇄적으로 발생할 수 있습니다. 또한 대규모로 마이크로서비스를 구축 및 실행하려면 일관된 CI CD 관행이 필요합니다. 서비스에는 자체 매개변수가 있으며, 이를 기반으로 이 모든 추가 기능을 확장합니다.운영상의 복잡성에 대해 말하자면, Doordash는 하이퍼스케일을 겪었을 때 이런 일을 많이 겪었다고 생각합니다. 가장 주목할 만한 것은 아마도 언급할 가치가 있을 것입니다. 복잡성이 급격히 증가했기 때문에 옵저버빌리티 향상에 막대한 투자를 해야 했기 때문입니다. 그래서 네트워크 호출을 모니터링하고 추적을 분산하기 위해 ebpf와 같은 것을 채택했습니다. 그래서 마이크로서비스의 호출 패턴과 종속성을 제대로 이해하게 되었습니다. 아, Jay가 하이퍼스케일이라는 용어를 언급한 것처럼 말이죠. 그럼 다음과 같이 이해해 봅시다.기업을 S자 곡선으로 바라보면 S자 모양은 시간이 지남에 따른 성장을 나타냅니다. 처음에는 급성장 시기에는 속도가 느리고, 그 다음에는 초고속 성장이 줄어드는 양상을 보입니다. 조직의 연평균 성장률이 정상 성장률보다 훨씬 높은 40% 를 초과할 때 초고속 성장 비즈니스는 모든 벤처 캐피탈이 부러워합니다. 하지만 슬픈 사실은 초고속 성장을 경험하는 대부분의 기업이 확장성과 처리 능력을 갖추지 못했기 때문입니다. 그 과정에서 발생하는 몇 가지 어려움은아시다시피 기업이 몇 년 동안 초고속 성장 단계를 지속하려면 이러한 기업이 지속적으로 혁신하고, 고객을 위해 새로운 서비스를 빠르게 출시하고, 고객 경험을 개선해야 합니다. 또한 모든 종류의 수익 손실을 방지하기 위해 애플리케이션 또는 플랫폼의 가용성과 성능을 높이고자 합니다. 이러한 기업은 애플리케이션 또는 플랫폼 사용이 엄청나게 증가하고 있으며, 이를 하이퍼스케이프라고 부르는 하이퍼스케이프라고 합니다. 자체 세트를 제공합니다.챌린지와 도어대시는 이러한 문제들을 성공적으로 해결한 회사 중 하나인데, 이번 세션에서 알아보도록 하겠습니다. Doordash의 하이퍼스케일은 어땠을까요? 예, 훌륭합니다. 오늘날 우리가 운영하는 규모와 복잡성에 대한 약간의 통찰력을 제공할 수 있는 몇 가지 수치를 말씀드리자면, 현관에서는 평균 15만 개의 HTTP 요청이 종종 내부적으로 수천 개의 요청으로 확산될 수 있습니다. 현재 엔지니어링 팀은 20개의 kubernetes 클러스터와 다음 중 하나에서 1,000개가 넘는 서비스를 관리하고 있습니다.대규모로 운영되고 시간이 지남에 따라 우리 고유의 아키텍처 텍스처가 진화하는 것을 보면서 제가 공유할 수 있는 주요 교훈은 무언가가 아무리 잘 설계되었더라도 실패는 항상 가능성의 영역 내에 있다는 것입니다. 그래서 인간과 관련된 모든 것은 말 그대로 보편적인 진리이기 때문에 Doordash에서 조금 더 파고들어 실패를 세 가지 주요 유형으로 분류할 수 있었습니다. 주목할 가치가 있습니다. 이것은 릴리스 프로세스 초기에 문제가 발견되지 않는 부분입니다.이러한 유형의 장애를 방지하는 데 많은 투자를 했습니다. 유닛 테스트, 통합 테스트, 부하 테스트, 사용자에게 영향을 미치기 전에 문제를 조기에 발견하기 위한 프로그레시브 배포 수행, 두 번째 유형은 폭발 반경 (blast radius) 과 관련된 것으로, 일종의 공유 상태 또는 강력한 결합으로 인해 시스템에 단일 장애 지점이 있습니다. 이와 같은 좋은 예로는 시크릿 스토어나 미니 서비스가 비밀을 검색하기 위해 이를 의존할 수 있습니다. 장애가 발생하면 분명히 모든 서비스가 영향을 받은 우리는 t0 서비스이며 다음과 같은 경우사용할 수 없게 되면 이러한 유형의 장애를 완화하기 위해 업스트림에서 연속적인 장애가 발생합니다. 우리는 도메인 격리를 통해 특정 변경의 영향을 제한하고 그 영향을 최소화하기 위해 부하 차단 및 회로 차단과 같은 가드레일을 배치했습니다. 마지막 실패는 장애 유형이 복잡해서 단일 에이전트의 모델이 정확하지 않을 수 있다는 것입니다. 즉, 실수를 훨씬 더 쉽게 만들고 시스템을 전반적으로 디버그하기가 더 어려워진다는 뜻입니다.-음, 어떤 유형의 실패를 경험하셨는지 궁금하네요. 정확히 말씀하셨어요. 초성장 단계에 도달하면 애플리케이션에 기대하는 규모가 새로운 수준에 도달합니다. 따라서 앱에 대한 수요가 증가하면 모든 기본 구성 요소가 확장에 맞게 조정되어야 하고 앱이 크로스 노드 잠금 조정과 같은 초선형 스케일링 요소를 경험하기 시작할 것입니다. 또 다른 문제는 애플리케이션에 새로운 기능을 자주 추가하려고 할 때 배포가 복잡하다는 것입니다. 여러 마이크로서비스를 병렬로잘못된 코어 배포 및 의도하지 않은 CI CD 구성 문제는 드문 일이 아닙니다. 이로 인해 네트워크가 스트레스 테스트를 받고 있더라도 현재 대규모 환경에서 모든 고객에게 영향을 미칠 수 있습니다. 이로 인해 네트워크가 제대로 프로비저닝 및 구성되지 않은 경우 상당한 지연 시간과 시간 초과가 발생할 수 있으며, 이로 인해 온라인 워크플로우에 영향을 미쳐 애플리케이션에 액세스하는 동안 고객 경험이 저하될 수 있습니다. 서비스가 지역 제한 또는 계정 제한이 있는 리소스에 의존할 수 있습니다. 빠르게 에스컬레이션될 수 있음초과한 경우 미리 생각하고 이러한 제한을 계획하는 것이 중요합니다. 예를 들어 특정 지역의 Aurora DB에 있는 클러스터 수는 40개이고 이 중 일부는 소프트 제한이므로 미리 조정할 수 있지만 어려운 제한도 있습니다 (예: ec2 인스턴스 네트워크 대역폭에 대해 생각해 보세요). 따라서 본질적으로 마이크로서비스의 비선형 확장은 애플리케이션을 허용하거나 애플리케이션을 숨겨진 경합점에 더 가깝게 만듭니다. 이 결과를 테스트하기 어려운 캐스케이딩 실패 또는 타임아웃을 호출합니다.운영 중단이나 다운타임이 모든 고객에게 영향을 미친다는 것을 알고 있습니다. 이러한 관점에서 보면 폭발의 반경이 더 큽니다. 혁신, 어, 고객 경험 개선, 수익 손실 방지와 같은 초고속 성장의 주요 목표를 기억한다면 이 모든 것이 큰 타격을 입을 수 있습니다. 그렇다고 해서 복잡한 환경에서 마이크로서비스를 사용하는 것이 나쁜 생각이라는 것은 아니지만 완벽해지기가 너무 어려워서 상황이 순식간에 악화될 수 있습니다. ordash: 앞서 언급한 문제점들을 모두 고려했고, 저와 아님 모두가 공유한 문제점들을 고려했고, 저희는 이를 받아들였습니다.이러한 실패는 피할 수 없었습니다. 우리는 이를 아키텍처의 다음 단계에 대해 어떻게 생각하는지에 대한 주요 설계 원칙으로 사용하고 있습니다. 궁극적으로는 내부적으로 프로젝트 슈퍼셀 (Project Supercell) 이라는 코드명을 붙였습니다. 2020년에는 Doordash의 서비스 스토리지를 한 번 배포하면 단일 계정의 단일 VPC에서 모든 시장의 모든 트래픽을 처리했습니다. 단일 배포가 실패하면 전체 Doordash 비즈니스가 영향을 받은 프로젝트 Supercell은 점진적 프로젝트 추가를 모색했습니다.모든 잠재적 장애에 대비하기 위해 비즈니스를 여러 번 격리하고, 몇 가지 주요 요구 사항이 있었습니다. 이러한 주요 요구 사항은 사용자 변경, 서비스 장애 또는 관리형 클라우드 서비스의 장애로 인한 것이든 다양한 장애 시나리오로부터 장애를 격리해야 한다는 것이었습니다. 또한 개발자가 추가적인 마찰 없이 평소와 같이 계속 개발할 수 있도록 오버헤드가 발생하지 않도록 해야 합니다. 그런 다음 우리가 지원하는지 확인해야 합니다. 기존 마이크로서비스 아키텍처새로운 슈퍼셀 배포와 함께, 서비스가 어디에서 실행되고 있든 관계없이 라우팅이 가능하도록 해야 했기 때문에 이제 Anon으로 다시 전달하여 익숙하지 않을 수도 있는 사람들을 위해 셀 기반 아키텍처에 대해 조금 더 설명하겠습니다. Chief 프로젝트에 대해 알아보기 전에 이 아키텍처가 초고속 성장 환경에서 발생하는 몇 가지 문제를 해결하는 데 어떻게 도움이 되는지 이해해 보겠습니다. 이 아키텍처는 대규모 규모를 전제로 합니다. 병렬화가 필요하며 이를 위해서는 다음과 같은 구성 요소가 필요합니다.이러한 고립된 고립된 영역을 셀이라고 부릅니다. 각 셀은 애플리케이션의 완전히 독립적인 인스턴스이며 최대 크기가 고정되어 있습니다. 이제 애플리케이션은 Auto Scaling 그룹 또는 여러 컨테이너 또는 kubernetes 클러스터를 포함하는 ec2 인스턴스로 구성될 수 있습니다. 기본적으로 각 셀에서 이들 각각의 개별 복사본을 실행하고 나면 추가 사용자 또는 트래픽을 지원하기 위해 더 많은 셀을 추가하여 환경을 확장할 수 있습니다. 한 셀에서의 장애는 영향을 미치지 않습니다. 다른 사람들은 이제 이것을 다음과 같은 것과 혼동하지 않습니다.가용성 영역 또는 지역 전체에 분산되어 인프라 수준에서 물리적 격리를 제공하는 반면, 이러한 격리는 애플리케이션 수준에서 이루어지며, 애플리케이션 환경 자체가 서로 분리되어 있는 논리적 수준에 있는 애플리케이션 수준에서 이루어지며, 마지막으로 최상위에 얇은 계층을 구축하여 트래픽을 이러한 셀로 라우팅합니다. 우리는 이것이 복잡한 논리가 아니라 효율적인 라우팅 메커니즘이어야 한다는 것을 모두에게 상기시키기 위해 가능한 가장 얇은 계층이라고 부릅니다. 이 아키텍처는예를 들어, 한 셀에 치명적인 고장이 발생했는데 다른 셀은 영향을 받지 않으므로 해당 셀에서 서비스를 받는 고객만 영향을 받는다는 의미로 보면 레오의 일반적인 고장에 대비할 수 있는 격벽 유닛입니다. 즉, 이제 폭발 반경이 짧아질 뿐만 아니라 이러한 셀은 일정한 크기의 캡사이드를 유지하며 정기적으로 테스트를 거치기 때문에 정전이 발생할 확률도 높아집니다. 아시다시피, 평균 실패 간격이 더 길수록 이러한 셀은 복구하기도 더 쉽습니다.문제 진단과 긴급 코드 배포 및 구성을 위해 수정 및 분석해야 하는 호스트의 수를 제한하므로 이제 평균 복구 시간을 줄일 수 있습니다. 즉, 최대 크기 (Behavior) 를 잘 이해하고 테스트 가능한 최대 확장도 가능하므로 테스트 용이성이 향상됩니다. 이제 Canary 테스트를 셀 중 하나나 테스트 (예: 카오스 몽키) 에서 실행할 수 있으며 다른 셀에 영향을 주지 않고 모두 배포하고 있다고 가정해 보겠습니다. 셀을 사용하면 버전 2에서 새로운 기능을 사용할 수 있습니다.하나의 셀에 배포할 수 있습니다. 제대로 작동하는지 확인한 다음 다른 셀에 배포할 수 있습니다. 이제 배포가 잘못될 경우 언제든지 다른 셀에 영향을 주지 않고 롤백할 수 있으므로 문제가 있는 배포의 관점에서도 블래스트 반경이 줄어들고 마지막으로 부작용으로 스케일 업이 아닌 확장이 가능하고 확장성이 향상되었습니다. 이제 몇 가지 개념을 살펴보겠습니다. 물론 이 아키텍처의 하나는 고객 또는 워크로드를 셀에 매핑하는 방법을 결정하는 배치 전략입니다.라우터는 고객 트래픽이나 요청을 처리하여 올바른 셀로 보내는 구성 요소입니다. 그러면 이 아키텍처는 셀의 최대 크기를 유지함으로써 이점을 얻을 수 있습니다. 미리 결정된 트래픽 규모를 기반으로 셀 크기를 결정하려는 경우 각 셀에 대해 좀 더 자세히 살펴보겠습니다. 배치 알고리즘은 셀, 구성, 다양한 고객 또는 워크로드가 셀에 매핑되는 방식을 추적하는 기본 구성 요소이므로 몇 가지 도움이 필요합니다. 예를 들어 시장 부문 또는 고객 계정을 다음과 같이 사용매핑 기준을 적용하기 위해서는 비즈니스 컨텍스트를 기반으로 데이터나 트래픽을 어떻게 분할할지 어느 정도 생각해 보아야 합니다. 예를 들어 B2C 애플리케이션과 B2B 애플리케이션의 경우 다를 수 있습니다. 하지만 명심해야 할 중요한 점은 완전한 격리가 가능한 서비스 범위를 기반으로 파티셔닝하려는 것입니다. 이제 배치 전략도 성장에 영향을 미치므로 환경에 새 셀을 추가할 때 필요합니다. 이제 고객이 플랫폼에 액세스할 때 이를 추적할 수 있어야 합니다.편리하게도, 알다시피 올바른 셀 엔드포인트로 라우팅하면 이 기능이 라우터에서 처리됩니다. 이제 이 기능은 대역외 검색 메커니즘이 될 수 있습니다. 이를 통해 클라이언트가 연결해야 하는 판매 엔드포인트를 파악할 수 있습니다. 예를 들어, 가용성이 높고 확장 가능한 DNS 서비스인 Amazon Route 53을 사용하여 이를 달성할 수 있습니다. Amazon Route 53은 셀 라우팅 정책을 위한 고유한 도메인 이름, 상태 점검 등 라우팅 레이어에 대한 몇 가지 중요한 기능을 제공하며 이를 기반으로 장애 조치 셀로 리디렉션할 수 있습니다. on 또는 라우터가 프록시일 수 있음요청을 프런트엔드한 다음 적절한 백엔드 셀로 보내는 Amazon API Gateway와 같은 서비스입니다. 이 경우 요청 자체의 파라미터 요청을 사용하여 라우팅 경로를 결정할 수 있습니다. 클라이언트는 백엔드 셀 설계에 대해 전혀 알지 못할 것입니다. 라우터는 지연 시간을 최소화하는 것이 이상적입니다 (마이크로초 단위) 여야 하고 너무 복잡하지 않아야 합니다. 이 역시 전체 가용성 관점에서 중요한 구성 요소이며 그 자체가 단일 지점이 되어서는 안 됩니다. 사이즈 조정에 실패하면라우팅 기준에 따라 결정하는 것이 중요합니다. 즉, 셀이 작을수록 블라스트 반경이 작아지고, 쿼리할 로그 항목이 적기 때문에 문제를 진단하고 해결하기가 더 쉬우며, 개별 셀 수준에서 운영하기가 더 쉬워집니다. 반면에 대형 셀이 적으면 용량 활용도가 향상되어 웨일즈처럼 대규모 고객을 대형 셀에 수용할 수 있고 운영이 더 쉬워집니다. 이제 시스템 수준에서 예제가 있습니다.응용 프로그램은 HA 아키텍처를 활용하기 위해 여러 가용 영역에 분산되어 있습니다. 셀 기반 아키텍처는 응용 프로그램의 전체 기능을 제공하는 각 셀과 비슷하며 서로 완전히 격리되어 있고 셀 간 통신이 없으므로 기본 파티셔닝에 대해 아는 유일한 구성 요소는 라우터입니다. 이제 지리적 위치를 기반으로 파티셔닝하거나 세그먼트화하려는 경우 지오베이스 셀을 사용할 수 있습니다. 기반으로 수행고객 계정: 효율적인 할당 및 활용을 위해 일종의 해싱 알고리즘을 사용하여 계정을 특정 셀에 매핑할 수 있습니다. 하지만 여전히 특정 셀 내에서 고가용성을 보장해야 합니다. 따라서 셀 내의 애플리케이션 및 애플리케이션 구성 요소를 가용 영역 전체에 분산하는 것이 좋습니다. Amazon 가상 사설 클라우드 또는 VPC는 여러 가용 영역과 프로브에 단기간 사용할 수 있고 셀 경계 역할을 할 수 있기 때문에 단일 VPC일 필요는 없지만 셀이 구성될 수 있습니다. 여러 vpc의 사용과 이것은애플리케이션 요구 사항에 따른 VPC 크기 조정 또는 서로 다른 팀과 해당 애플리케이션 구성 요소 간의 격리에 따라 결정될 수 있습니다. 따라서 이들을 서로 다른 vpc로 분리하거나 비즈니스 로직 구성 요소를 데이터 계층 구성 요소와 분리하려는 경우 PPC 피어링을 통해 vpc 간에 지연 시간이 짧은 네트워킹 연결을 제공하고 VPC 간에 트래픽을 동일한 네트워크에 있는 것처럼 라우팅할 수 있습니다. 이제 이 아키텍처를 지원할 수 있는 매우 우수한 네트워크 성능을 제공합니다. 가져야 할 모범 사례 중 하나라우터 및 각 셀에 대해 별도의 AWS 계정을 제공합니다. 따라서 하나의 AWS 계정에서 작업이 다른 계정에 영향을 미치지 않고 하드 서비스 할당량 제한의 위험도 줄어듭니다. 이는 대부분 계정 수준에서 이루어집니다. AWS 조직을 사용하여 이 아키텍처를 지원하는 다중 계정 환경을 만들 수 있습니다. 그런 다음 안전한 다중 계정, AWS 환경 또는 랜딩 존을 쉽게 설정하고 관리할 수 있게 해주는 AWS 컨트롤 타워와 같은 일부 서비스도 있습니다. 그리고 이건 계속 이어지죠계정 관리 및 거버넌스 모범 사례는 고객이 클라우드로 이전할 때 고객과 함께 작업하면서 수년간 학습한 것입니다. 이제 특정 지역 내에 여러 셀을 보유하고 AWS Transit Gateway를 사용하여 셀을 상호 연결할 수 있습니다. AWS Transit Gateway는 확장성과 가용성이 뛰어난 중앙 집중식 라우팅 허브로, 네트워크 토폴로지를 단순화합니다. 온라인 고객 워크플로를 위한 것이 아니더라도 대역 외 데브옵스 팀이 달성할 수 있는 경로를 제공할 수 있습니다. 배포를 위한 문제 해결을 위해 이러한 셀에 연결하고따라서 AWS Direct Connect Site to Site VPN과 같은 서비스를 사용하면 기업 네트워크 또는 온프레미스 데이터 센터에서 이 아키텍처로 연결할 수 있습니다. 원격 인력은 AWS 클라이언트 VPN도 사용하여 이 아키텍처에 연결할 수 있습니다. 이제 이 Transit Gateway Hub 및 스포크 엄 (Spoke um) 모델을 사용하면 다른 오프라인 사용 사례에 대한 연결을 지원할 수 있습니다. 예를 들어, 사용 사례를 구축하기 위해 이러한 셀에 연결하여 모든 데이터를 캡처하거나 모든 데이터를 쿼리해야 하는 데이터 플랫폼 환경이 있다고 가정해 보겠습니다. 분석 및 기계 학습 등에 관해서는 현재여러 지역에 셀을 구축하는 경우 다음 단계로 나아갈 수 있습니다. 이는 설문 조사를 실시하거나 해당 시장에 셀을 더 가깝게 배치하는 등의 이유가 있을 수 있습니다. 예를 들어 성능 및 지연 시간 개선의 명백한 이점을 위해 인접 지역으로 확장하거나 순전히 확장성 향상을 위해 인접 지역으로 확장하거나 클라우드 리소스에 대한 지역 제한을 초과하기 위한 것일 수도 있습니다. 특정 시장에 서비스를 제공하는 동안 데이터 지역성과 같은 규제상의 이유 때문일 수도 있습니다. 하지만 이것이 활성 환경을 나타내기 위한 것은 아니라는 점을 명심하세요. 이 아키텍처처럼 여러 지역에 걸쳐다시 말씀드리지만 셀 간의 완전한 격리에 의존하지 않고 셀 간의 완전한 격리에 의존하고 있습니다. 이러한 설계를 지원할 수 있는 몇 가지 우수한 글로벌 AWS 서비스가 있습니다. Amazon Route 53은 요청을 여러 지역의 판매 DNS 엔드포인트로 라우팅할 수 있도록 하는 다양한 라우팅 라우팅 정책을 갖춘 DNS 서비스입니다. Amazon Cloud Front를 사용하면 Amazon Global 백본을 사용하여 짧은 지연 시간과 빠른 전송 속도로 콘텐츠를 안전하게 전송할 수 있습니다. 를 사용하여 여러 출처의 콘텐츠 제공'행동'이라는 기능이 있는데, 이 기능은 라우팅 경로를 결정할 수 있으며, 이를 사용하여 적절한 셀 엔드포인트에 매핑할 수 있는 Cloudfront 함수 Lambda at Edge와 같은 기능이 있습니다. 이제 클라우드프론트 CDN의 주요 목표는 콘텐츠를 캐싱하고 엣지 로케이션에서 제공하는 것입니다. 하지만 애플리케이션에서 사용자 트래픽이 백엔드 애플리케이션까지 계속 흐르도록 요구하지만 지연 시간 성능이 우수하다고 가정해 보겠습니다. AWS 글로벌 액셀러레이터를 사용할 수 있습니다. 글로벌 액셀러레이터는 환경을 개선하는 네트워킹 서비스입니다.글로벌 네트워크 인프라를 사용하여 사용자 트래픽의 성능을 최대 60% 까지 사용할 수 있습니다. 인터넷이 혼잡할 때 애니캐스트 기술을 사용하여 사용자의 트래픽이 백엔드 애플리케이션으로 이동하는 경로를 최적화할 수 있으며 패킷 손실, 지터 및 지연 시간을 일관되게 유지합니다. 사용자 지정 라우팅 액셀러레이터라는 기능이 있습니다. 이 기능을 사용하여 라우팅 로직을 작성하고 글로벌 액셀러레이터 뒤의 특정 엔드포인트 또는 셀에 사용자를 매핑할 수 있습니다. 세포가 고장나서 당신이 원한다고 가정해 봅시다.다른 셀로 리디렉션하여 다른 셀의 트래픽을 처리합니다. 그러면 Route 53 애플리케이션 복구 컨트롤러가 도움이 되므로 애플리케이션 복구 컨트롤러 서비스는 셀 내의 애플리케이션 및 구성 요소가 트래픽을 수신할 준비가 되었는지 확인하고 준비 검사 및 라우팅 제어 기능을 사용하여 페일오버를 관리 및 조정할 수 있도록 도와줍니다. 따라서 기본적으로 새 세트가 트래픽을 수신할 준비가 되었는지 확인한 다음 이 서비스를 사용하여 트래픽을 해당 셀로 이동할 수 있습니다. 여기에는 여러 가지 방법이 있습니다이 아키텍처를 알고 설계하고 구현할 수 있습니까? 이 설계를 위해 자체 개발 구현이나 타사 솔루션을 고려할 수도 있습니다. AWS는 이 설계에 대해 생각하고 이 아키텍처를 구현할 수 있는 훌륭한 도구 세트를 제공합니다. 이제 이 아키텍처를 살펴보았으니 음, 아시다시피 대시가 하이퍼스케일 성장을 지원하기 위해 이를 어떻게 구현했는지 살펴보겠습니다. 고마워요. 우리의 글로벌 셀을 보세요. 이것은 기본적으로 우리의 기존 셀이라는 점을 강조할 가치가 있습니다.마이크로서비스 아키텍처는 방금 슈퍼셀 라이브로 아직 마이그레이션되지 않은 글로벌 셀 및 서비스로 이름을 변경했습니다. 여기에는 기본적으로 쿠버네티스에서 실행되는 모놀리스가 포함되며, 기본 DB, 다양한 기타 도메인별 데이터베이스와 글로벌 서비스를 수용하는 소수의 쿠버네티스 클러스터가 포함됩니다. 이 모든 것이 여러 AZ에 배포되어 있습니다. 프로젝트 슈퍼셀의 일환으로 다양한 라우팅 요구 사항을 지원하기 위한 서비스 및 내부 라우터를 도입했습니다. 그 이후로 모든 것이 이전에 배포되었던 기본 계정에 모두 배포되었습니다.말그대로 doordash의 시작입니다. 슈퍼셀의 일부인 셀 중 하나를 살펴보겠습니다. 아주 간단합니다. 음, 기본적으로 일부 스토리지와 일부 컴퓨팅이 있습니다. 이번에는 단일 라우터와 서비스 라우터가 있어야 합니다. 서비스 등록 디스커버리를 위한 콘솔과 소수의 kubernetes 클러스터, 오늘날에도 여전히 공유되고 있는 일부 도메인별 데이터베이스를 포함해야 합니다. 물론 다양한 사용 사례에 일시적인 게이트웨이와 피어링을 사용합니다. VPC 네트워킹 및 연결성에 대해서는 잠시 후에 다루도록 하겠습니다.사용자 액세스의 경우 서비스-서비스 네트워킹을 위한 다양한 내부 리소스에 액세스하기 위해 AWS 클라이언트 VPN과 함께 Transit Gateway를 사용하고, 불필요한 지연 시간을 야기할 수 있는 추가 홉을 방지하기 위해 피어를 사용합니다. 그리고 Transit Gateway 연결이 있기 때문에 둘 간의 라우팅이 가능할 수도 있지만, 셀 크기 및 할당과 관련하여 셀 간 트래픽을 제한하는 방식으로 모든 라우팅 테이블을 구성해야 합니다. 곧 있을 일앞서 말씀드린 바와 같이 저희는 어떤 경로로 나뉘어질 것인지 고민하기 시작했습니다. 우리 회사는 여러 지역에 걸쳐 분산되어 있는 여러 시장으로 이루어져 있습니다. 대부분의 경우 이러한 시장을 결정하는 것은 매우 간단합니다 (음). 왜냐하면 우리는 배송 주소와 같은 것을 사용하여 시장을 주도하는 사용자의 마켓이 BFF를 사용하여 다양한 고객에게 반환되는지 결정할 수 있기 때문입니다. 다음 슬라이드에 대해 설명하겠지만, 제가 말씀드리고 싶은 것은게스트 마켓 중 하나인 마켓이 다른 마켓보다 규모가 작은 이유에 대해 좀 더 자세히 알아보겠습니다. 또한 이러한 Pro 속성을 고려하면 마켓의 주문 부하를 4개 셀 중 3개 셀에 균등하게 분배하고 첫 번째 셀을 의도적으로 작게 유지하여 피크 타임이 다르면 프로그레시브 롤아웃을 수행할 수 있는 유용한 자산으로 활용할 수 있습니다. 다른 기간 동안의 시장지난 슬라이드에서 말씀드렸듯이 거래량이 적을 때는 BFS에 크게 의존합니다. 익숙하지 않은 사용자를 위해 BFF는 백엔드의 약자로 프론트엔드를 나타냅니다. 기본적으로 클라이언트 간의 프록시입니다. 예를 들어 모바일 앱과 같은 것이 좋은 예이자 백엔드 서비스이므로 소비자 서비스와 마찬가지로 일반적인 플로우는 다음과 같습니다. 예를 들어, 모바일 클라이언트가 모바일 BFF를 호출한 다음 모바일 BFF를 호출한 다음 BFF는 내부적으로 소비자 서비스를 호출합니다. 백엔드 서비스는 소비자의 집 주소와 같은 것을 사용하여 결정합니다.고객이 어느 시장에 있는지, BFF에 대한 응답과 함께 고객에게 (즉, 해당 시장 ID를 가진 쿠키) 로 시장을 돌려줍니다. 이제 지금까지 공유한 모든 내용을 제공했으니, 요청의 일반적인 라이프사이클이 어떻게 보일지 살펴보겠습니다. 음, 먼저 클라이언트가 요청을 하면 일반적으로 잘 진행되고 항상 CDN으로 전달되며, 이 시점에서는 첫 번째 요청은 그렇지 않을 가능성이 높습니다. 음, 요청한 시장이 CDN 작업자의 소유라는 것과 같은 정보가 있으면 Robin의 요청을 다음 중 하나로 반올림합니다.셀에 상주하는 서비스 라우터 4개 (요청이 셀 서비스인 경우 잠시 후 서비스 라우터에서 다른 유형의 요청을 받습니다. 음) 셀 내에서 서비스 라우터에서 요청은 BFF 계층으로 계속됩니다. BFF 계층은 적절한 백엔드 서비스와 상호 작용하여 사용자가 시장 ID에 속해 있는 시장을 확인한 다음 이에 대해 좀 더 자세히 설명합니다. 이 요청은 CDN에 다양한 용도로 사용됩니다. DDOS URL이 로드 밸런싱을 다시 작성하는 이유이지만 여기서 언급할 가치가 있는 중요한 것은작업자 함수는 시장 ID를 기반으로 요청을 라우팅할 서비스 라우터를 처리하기 위한 미들웨어 역할을 합니다. 따라서 먼저 마켓 ID 쿠키를 확인하고 요청이 없으면 쿠키가 존재하는지 확인합니다. 쿠키는 다시 네 셀 중 하나로 라운드 로빈으로 이동합니다. 따라서 이 경우 요청은 두 셀 판매로 넘어갈 수 있습니다. 그리고 앞서 언급한 것처럼 기본 인스턴스가 Envo에서 모두 실행되는 ALB인 서비스 라우터로 이동합니다. 이 경우 콘솔 콘솔과 콘솔은 실제로 서비스를 지원하기 위한 것입니다. Discovery는 실제로 서비스를 위한 것입니다.검색 용도도 있고, 음, Envoy가 검색에 사용하는 특정 도메인을 사용하여 호스팅됩니다 (그림에는 없습니다). 음, 이 모든 것이 작동하는 방식에서 중요한 점은 셀의 각 kubernetes 클러스터에서 카탈로그 동기화가 실행되고 있다는 것입니다. 서비스가 클러스터에 나타나면 서비스 등록 서비스를 콘솔에 제공합니다. Discovery Envoy는 물론 정적 V 호스트 항목에 대해 앞서 언급한 것처럼 서비스 디스커버리 도메인과 같은 서비스 디스커버리를 사용합니다. 각 클러스터가 주어진 워크로드를 해당 kubernetes 클러스터 중 하나로 해결하도록실제 Envoy 숨겨진 그림 자체는 S3에서 Node의 런타임 데몬을 통해 주기적으로 풀다운됩니다. 이 경우 요청이 소비자 BFF를 잘 해결하려고 한다고 가정해 보겠습니다. 콘솔 DNS 서버를 사용하여 먼저 요청을 해결하고 해당 서비스에 대한 IP를 반환합니다. IP에서 전체 반환은 kubernetes에서 AWS VPC cni를 활용하여 플랫 네트워크를 운영하기 때문에 실제로 가능합니다. 기본적으로 클러스터의 워크로드는 확인 가능한 IP 주소를 얻습니다. 이제 실제 IP가 있으므로 요청은 다음으로 전달됩니다.소비자 BFF 및 해당 BFF는 일반적으로 앞서 언급한 것처럼 집 주소와 같은 것을 사용하여 일부 백엔드 서비스와 상호 작용하여 사용자의 시장 ID를 결정합니다. 따라서 후속 요청에서 요청이 CDN에 도착하면 이제 시장 ID 쿠키를 갖게 되고 CDN은 요청을 가져온 다음 해당 시장 ID를 기반으로 특정 서비스 라우터로 라우팅합니다. 그러면 서비스는 kubernetes 클러스터에서 실행되는 워크로드로 라우팅됩니다. 물론 적절한 셀 (um) 에 들어가서 좀 더 자세히 살펴보면 요청이 CDN에 도착합니다.작업자 함수가 시장 ID를 기반으로 셀 조회를 수행합니다. 적절한 셀을 알게 되면 작업자가 이번에는 요청을 보낼 서비스 라우터를 알게 됩니다. 이 예제에서는 Market ID 쿠키가 1, 2, 3으로 설정되어 있고, Market 1, 2, 3으로 설정된 요청이 셀 1에 있는 서비스 라우터로 전송되고 음, 기본적으로 어떤 경우에는 아직 온보딩되지 않은 서비스에 대한 요청이 있을 수 있습니다. 슈퍼셀은 우리의 글로벌 셀에 여전히 존재할 수 있습니다. 이러한 슈퍼셀은 우리의 글로벌 서비스로 구성되어 있습니다.CDN과 요청은 글로벌 셀에서 실행 중인 서비스 라우터로 전송됩니다. 그런 다음 표면 라우터는 해당 글로벌 셀에서 실행되는 kubernetes 클러스터 중 하나로 요청을 라우팅합니다. 문제를 해결하려고 한다고 가정해 보겠습니다. CDN 내에 구성된 DNS 레코드를 기반으로 하는 Food Service라는 가상의 글로벌 서비스를 모릅니다. 그런 다음 요청이 글로벌 셀로 전송되고 나서 해당 글로벌 셀에서 실행되는 서비스 라우터로 이동합니다. 셀 서비스 라우터가 aob로 실행되고 일부 인스턴스는 콘솔과 Envoy um을 실행합니다.기본적으로 글로벌 서비스 및 글로벌 kubernetes 클러스터를 해결하기 위한 셀 서비스 라우터와 동일합니다. 물론 한 가지 더 언급할 가치가 있는 시나리오가 있습니다. 바로 um 요청을 모놀리스로 라우팅해야 하는 경우입니다. 안타깝게도 여전히 이런 일이 발생하여 요청이 먼저 CDN으로 이동한 다음 글로벌 셀에서 평소와 같이 서비스 라우터 (음) 로 이동합니다. 여기서 가장 큰 차이점은 이 경우 서비스 라우터가 구성된다는 것입니다. 모놀리스에 요청을 내부에서 내부 라우터라고 하는 것으로 보냅니다.라우터 (router) 에는 모놀리스에 대한 요청이 쿠버네티스에서 관리되는 서비스 유형 로드 밸런서로 전송되는 구성이 있는데, 여기서 좀 더 자세하고 더 자세히 설명하자면, 여기서 라우팅에 대해 살펴보아야 할 중요한 점은 글로벌 서비스 라우터에 특정 요청을 내부 라우터로 보내는 것을 알고 있고 내부 라우터에는 모노리스에 대해 구성된 일부 엔드포인트가 있다는 것입니다. 이러한 요청을 모놀리스의 서비스 유형 로드 밸런서로 보내는 내부 라우터는요청을 적절한 서비스 라우터로 적절하게 전달하는 데에도 사용되므로 셀 서비스를 해결해야 하는 글로벌 서비스가 있다고 가정해 보겠습니다. 먼저 해당 요청을 내부 라우터로 보낸 다음 내부 라우터가 기본적으로 이를 적절한 서비스 라우터 (um) 로 전달합니다. 이 예에서는 셀 서비스 라우터와 슈퍼셀 VPC로 전송합니다. 지금까지 살펴본 바와 같이 글로벌 서비스 셀과 4개의 슈퍼셀을 운영하므로 잘 알고 있습니다. 약간 혼란스럽기 때문에 고려 사항에 대해 조금 공유하고 싶었습니다.슈퍼셀에 서비스를 온보딩하고 글로벌 셀에서 어떤 종류의 체류를 유지할지 고려할 때 가장 먼저 이해해야 할 것은 서비스 종속성입니다. 따라서 기본적으로 서비스가 무엇을 호출하고 어디에서 실행되는지, 이것이 중요한 이유는 서비스가 통신할 수 있는 네트워크 경로가 제자리에 있고 트래픽이 한 VPC에서 다른 VPC로 이동할 수 있도록 하여 서비스가 중단되지 않도록 해야 하기 때문입니다. 마이그레이션됩니다. 이해해야 할 또 다른 중요한 사항은 지연 시간에 미치는 영향입니다.서비스를 옮길 때 가장 원하지 않는 것은 서비스를 이동하는 것입니다. 대부분의 종속성이 함께 실행되지 않기 때문에 시스템의 전체 성능에 영향을 미치는 불필요한 대기 시간이 많이 발생합니다. 서비스를 슈퍼셀로 이동한다고 상상해 봅시다. 하지만 호출하는 대부분의 항목이 글로벌 셀에서 실행되거나 아마도 모든 곳에서 실행되어 많은 결과를 초래할 것입니다. 글로벌 셀과 슈퍼셀 셀 간의 불필요한 트래픽 호핑과 이 트래픽에는 다음과 같은 명백한 비용 영향이 있습니다.슈퍼셀의 우선 적용 범위를 벗어나는 몇 가지 것들은 싱글톤과 같은 것들입니다. 아이템 효력이 없거나 스케줄러가 아닌 워크로드를 상상해 보세요. 여러 사본을 실행하지 않을 것이기 때문에 훌륭한 후보가 아니기 때문에 항상 단일 셀에 있을 가능성이 높습니다. 우리에게는 이것이 글로벌 셀입니다. 슈퍼셀에 서비스를 온보딩하는 것을 고려할 때, 마지막으로 티어는 슈퍼셀에 서비스를 온보딩할 때 가장 중요한 요소입니다. 우리는 티어 제로 서비스에 초점을 맞췄습니다. 티어 제로 서비스는 비즈니스를 운영하는 데 필요한 서비스이기 때문입니다.Supercell 프로젝트에서 가장 신경 썼던 점은 비즈니스를 운영하고 전체 비즈니스의 사본을 여러 개 운영할 수 있다는 점이었습니다. 배포와 일반적인 배포가 어떤 모습인지에 대해 간단히 설명하겠습니다. 슈퍼셀에 있는 경우 첫 번째 셀이 의도적으로 더 작다는 점을 다시 한 번 기억하세요. 배포 시 셀 제로 원에 배포할 때 미치는 영향은 훨씬 적습니다. 먼저 셀 제로 1에 카나리아 배치를 수행하고 카나리아 분석을 통해 후속 조치를 취합니다.모든 것이 괜찮아 보이면 청록색 셀을 배포합니다. 여기서 기본적으로 해당 셀에서 이전 버전과 새 버전의 서비스를 실행하고 이전 버전을 새 셀로 점진적으로 이동시키면서 잠재적인 빠른 롤백을 위해 이전 버전을 유지하면서 필요한 경우 모든 것이 좋아 보이면 나머지 셀로 계속 진행합니다. 솔직히 이것은 글로벌 서비스 셀에 대한 전략과 똑같습니다. 좋아요, 마지막으로 요약하고 싶습니다. 이제 회복력에 대해 얘기하고 싶은데요. 세포가 얼굴을 보는 모습을 상상해 봅시다.일종의 가상의 오류 (런타임 변경일 수 있음) 일 수 있습니다. 어쩌면 c 그리드에 대한 잘못된 변경일 수도 있습니다. 배포가 잘못되어 연쇄적인 실패가 발생할 수도 있습니다. 가장 먼저 지적해야 할 것은 그 영향이 단일 셀에만 국한되고, 해당 셀에 있는 시장만 영향을 받는다는 것입니다. 중단이 발생하면 다른 세 셀은 문제 없이 완전히 운영됩니다. 우리가 가장 먼저 하는 일은 트래픽을 다른 셀로 전환하는 것입니다. 기본적으로 세 개의 셀로 모든 시장을 다른 세 개의 셀에 다시 매핑하고 음, 제거하죠.로빈풀 주변의 특정 셀을 통해 요청이 전송되지 않도록 합니다. 일단 트래픽이 불량 셀에서 완전히 넘어갔는지 확인한 후 팀은 해당 셀 내에서 문제를 판단하여 해결하고, 마지막으로 모든 문제가 해결된 후 셀을 다시 활성화하고 라운드 로빈 풀에 다시 추가합니다. 이 모든 작업은 내부적으로 보유하고 있는 CLI에 의해 구동됩니다. 힐러, 좋아요, 음, 앞서 말씀드렸듯이 공유 스토리지는 일종의중요한 것, 즉 공유 도메인별 데이터베이스가 매우 중요합니다. 어, 이전 예제에서 한 셀과 다른 세 개의 정상 셀 간의 트래픽 조정을 왜 피할 수 있는지 궁금해하실 수도 있습니다. 이는 주로 슈퍼셀이 다단계 프로젝트이기 때문입니다. 1단계의 초점은 공유 스토리지를 계속 유지하면서 기본 네트워킹 라우팅을 마련하는 것이었기 때문입니다. 즉, 우리에게 이것은 소프트웨어 배포를 의미합니다. 이제 여러 셀에 걸쳐 서로 마주할 수 있습니다.공유 스토리지 모델은 필요한 경우 모든 셀로 시장을 확장할 수 있습니다. 즉, 공유 스토리지 모델은 2단계에서 사용할 다음 단계로 넘어갈 것입니다. 즉, 단일 장애 지점이 되는 것을 원하지 않기 때문입니다. 따라서 공유 데이터베이스 중 하나에 문제가 생기면 말 그대로 오늘날의 모든 셀에 영향을 미치기 때문에 2단계에서는 각 셀이 각 도메인별로 여러 시장 데이터의 하위 집합을 보유하는 데이터 샤딩에 중점을 둡니다. 데이터베이스를 통해 주어진 역할을 보존하는 여러 개의 셀을 갖는 이점을 여전히 얻을 수 있습니다.시장에서는 1단계만으로도 컴퓨팅 문제를 먼저 해결하는 데 많은 이점을 제공했고 모놀리스를 더 이상 사용하지 않는 것도 중요했고 스테이트풀 시스템을 샤딩하는 것은 비용이 많이 들었고, 그래서 여러분도 이 점을 염두에 두었습니다. 1단계를 생각할 때 마지막 3단계는 말 그대로 이 전체 설정을 한 지역에 배포하여 매우 가능성이 낮은 지역적 운영 중단이 발생하지 않도록 하는 것입니다. 하지만 이 새로운 아키텍처에 대한 전반적인 경험에서 제가 말할 수 있는 한 가지는훌륭합니다. 정상 셀로 트래픽을 재조정하는 기능은 거의 초강대국처럼 느껴집니다. 게다가 엔지니어들은 변경 사항으로 인한 영향이 미미하고 필요한 경우 트래픽을 조정하거나 전체 셀을 비활성화한 다음 다른 세 가지로 트래픽을 조정할 수 있다는 사실을 알고 변경 사항을 반복하고 새로운 기능을 출시하면서 자신감이 향상되었습니다. 또한 처음부터 mttr이 급격히 감소하고 개발 속도가 전반적으로 증가했습니다. 슈퍼셀의 전반적인 상황은 훌륭했지만 음, 그 자체로도 소수 없이는 가능하지 않았습니다.여기저기서 문제가 많았지만, 대부분은 단기적으로 모노리스 또는 글로벌 및 슈퍼셀 배포를 지원하기 위해 받아들인 복잡성에서 비롯되었습니다. 첫 번째로 주목할만한 과제는 솔직히 사람들이 온보딩보다 훨씬 빠르게 온보딩할 것으로 예상했지만 다양한 서비스 종속성으로 인해 처음에는 예상보다 더 어려워졌습니다. 셀 DPC에서 글로벌 VPC까지 예상보다 높은 지연 시간이 발생했기 때문에 툴링에 투자했습니다. 우리가 모두 이동한 네트워크 경로의 병목 현상을 식별하기 위한 관찰 가능성이러한 네트워크가 빠르게 나타나 지연 시간이 크게 개선되었습니다. 라우터는 실제로 단일 장애 지점이고 전체 시스템에 취약하기 때문에 구성 변경을 천천히 배포하고 적절하게 검증해야 합니다. 여정은 아직 끝나지 않았습니다. 슈퍼셀과 관련된 다양한 이니셔티브를 계속 진행하고 있습니다. 앞서 말씀드린 것처럼 셀당 데이터 격리를 포함하여 전체 라우팅 설정을 단순화하는 것이 포함됩니다. 실제로 내부 라우터를 제거할 수 있는 기회가 있습니다.일단 서비스 메쉬가 완전히 채택되고 나면 전반적인 온보딩 경험을 개선하기 위해 툴링에 대한 투자를 개선하거나 엔지니어가 서비스를 온보딩하기 위해 여러 리포지토리에서 열어야 하는 PRS 수를 최소화하는 데 투자하면 됩니다. 따라서 서비스를 온보딩하기 위해 한 곳으로 이동하기만 하면 되는 슈퍼셀에 온보딩하는 사람들을 위한 정상적인 추상화를 통해 클라우드가 이 문제를 해결하는 방법은 무엇일까요? 우리도 노력하고 있습니다. 여러 셀을 통해 여러 시장에 계속 서비스를 제공할 수 있도록 하는 것에 대해 마지막으로 제가 계속 말씀드리고 싶은 것은하지만 우리는 이 모든 것을 여러 지역에 배포하고 싶습니다. 음, 이 모든 것이 슈퍼셀입니다. 이별의 생각을 위해 Anon에 다시 전달하겠습니다. 이 여정을 공유해 주신 Jay에게 정말 감사합니다. 그래서 이 여정을 바탕으로 떠오르는 몇 가지 모범 사례나 고려 사항을 말씀드리고 싶습니다. 그래서 세포 크기 조정에 대해 올바르게 논의했기 때문에 먼저 여러분과 공유하고 싶었습니다. 즉, 세포가 작을수록 블래스트가 작아진다는 뜻입니다. 반경이므로 항상 해당 각도에서 설계에 접근하므로 진단이 빠르고 셀이 작아도 문제를 쉽게 해결할 수 있습니다.테스트를 통해 필요한 경우 성장할 수 있는 여지를 더 남길 수 있습니다. 다른 한 가지는 각 세포의 건강 상태를 제대로 점검하는 것입니다. 따라서 각 세포의 상태를 이해하기 위해 개별 세포 수준에서 칼로리, 메트릭, 알람, 대시보드와 같은 세포 수준 메트릭을 구축하는 것이 매우 중요합니다. 물론 그런 관점에서 볼 때 다른 고려 사항은 운영 복잡성에 대한 지식이 조금 늘어난다는 것입니다. 시차를 두고 셀을 배치하므로 배포 기간도 달라질 수 있습니다.증가하므로 운영 복잡성 측면에서 이 점을 고려하시기 바랍니다. 이를 운영 플레이북의 일부로 만들 수 있습니다. 이제 셀 라우터 관점에서 보면 단일 장애 지점이 될 수 있다는 점을 깨달았을 것입니다. 따라서 트래픽을 셀에 분산하려는 단일 개체로 생각하지 말고 가용성이 높은 중복 서비스 또는 관리 서비스를 활용하여 라우터가 이제 마지막 지점인 셀 마이그레이션 및 셀 마이그레이션에 도달했다는 것을 구현하십시오. 기본적으로 워크로드 이동을 의미하거나고객이 다른 셀로 트래픽을 이동하는데 이는 데이터 마이그레이션을 거꾸로 수행하기 때문에 복잡한 문제입니다. 장애 복구와 같이 셀이 다운되어 트래픽을 다른 셀로 리디렉션하려는 시나리오에서 특히 그렇습니다. 하지만 셀 마이그레이션에 대해 생각해 볼 수 있는 다른 시나리오도 있을 수 있습니다. 예를 들어 셀에 과부하가 걸리는 것과 같은 셀에 고객이 한 명 또는 몇 명의 고객이 있다고 가정해 보겠습니다. 셀 설계에서 일종의 최적화를 수행하고 싶어서 이동하려는 경우특정 데이터 파티션을 다른 셀과 연결하므로 이 셀을 너무 복잡하게 만들지 마십시오. 음, 음, 알다시피 첫날에는 문제가 되지 않을 것입니다. 셀 기반 아키텍처를 채택하고 있기 때문에 여전히 적절한 셀 크기 등을 보장하는 전략을 사용하는 것이 좋습니다. 한 고객 또는 소수의 고객이 과부하가 너무 크지 않습니다. 그래서 저는 마지막으로 이별을 고하고 싶습니다. 저희 도시 원더 보겔이 말씀드렸듯이, 모든 것은 항상 실패하고 여러분은 그 실패를 통제할 수 없습니다만여러분은 그 영향을 확실히 통제할 수 있습니다. 그래서 오늘 말씀드린 것처럼 기업들은 규모, 배포 복잡성 및 리소스 제한이라는 문제에 직면해 있습니다. 이로 인해 새로운 기능을 빠르게 배포하는 것이 어려워지고 업타임을 유지하면서 수익과 고객 경험에 영향을 미칩니다. 오늘 살펴본 셀 기반 아키텍처는 몇 가지 유망한 특성을 가지고 있으며 장애 격리를 파악하고 스케일 아웃의 이점을 얻을 수 있습니다. 또한 마이크로 서비스 아키텍처의 대안이 아니라 여러분을 위한 한 가지 방법입니다. 아시다시피 접근 방식마이크로 서비스를 민첩성과 확신을 갖춘 동시에 실패로 인한 영향이 최소화된다는 것을 알 수 있습니다. 따라서 오늘 배운 개념과 Doda 사례에서 배운 점을 고려할 때 여러분 모두 이러한 사고 과정을 가져와 환경에 맞는 이 아키텍처를 만드는 데 사용할 수 있는 다양한 서비스 중에서 선택해 보시기 바랍니다. 앞서 논의한 바와 같이 AWS는 이러한 설계에 도움이 되는 훌륭한 도구와 서비스 세트를 제공합니다. 살펴볼 만한 몇 가지 리소스를 소개합니다. 클라우드에 대해 잘 아는 것부터 시작해서 비슷한 주제에 대해네이티브 아키텍처 시리즈에는 Well Architected의 안정성 기둥을 활용할 수 있는 좋은 블로그 시리즈가 있습니다. 복원력 허브뿐만 아니라 많은 유용한 리소스와 Focus 및 Resilience Hub에 대한 유용한 정보를 제공합니다. 그리고 그 중 하나가 자체 AWS 서비스 내에서의 장애 격리 처리와 일부 셀 기반 아키텍처 원칙을 사용하는 방법에 대해 설명하는 블로그 (괜찮음) 입니다. 그럼 마지막 주제에 대해 이야기하면서 비슷한 주제에 대한 몇 가지 관련 세션을 안내해 드리고자 합니다. AWS 리인벤트 2022의 일부였던 주제는 다음과 같아야 합니다.AWS의 YouTube 채널에서 볼 수 있습니다. 여러분 모두가 이 내용을 살펴보길 강력히 권합니다. 저와 Jay 모두 시간을 내어 주셔서 감사합니다. 여러분의 피드백을 환영합니다. 감사합니다.