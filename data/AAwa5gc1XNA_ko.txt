- 좋아요.어서 오세요, 제 이름은 롤랜드 바르시아예요.저는 전문 기술 팀의 전 세계 책임자입니다.발표를 하게 되어 영광입니다.
크리스티나와 빅터, 훨씬 똑똑한 사람들과 함께요.그들은 자기소개를 할 거예요.
그들이 시간의 관심을 끌기 위해 말하기 시작할 때.그럼 시작해 볼까요, 왜냐하면 우리에겐 많은 것들이 있으니까요.
통과해야 할 재료.이 세션은 400레벨로 구성되어 있습니다.
그래서 우리는 아주 빠르게 깊이 들어가고 싶습니다.제가 시작할게요. 그리고
크리스티나한테 넘기기 전에 컨텍스트를 좀 정해놓는 게 좋겠어요그리고 좀 얘기해 볼게요.
먼저 데이터에 대해 알아보겠습니다.분명히, 컨퍼런스에서
제너레이티브 AI, LLM, Bedrock 등에 대해 많이 논의하고 있는 상황에서 데이터는 아마도
우리가 가지고 있는 주요 상품 중 하나죠.그리고 정말 많아요.
다양한 데이터 형식, 다양한 사용자
또는 데이터 페르소나.이제 더 이상 분석가만의 문제가 아닙니다.개발자들은 데이터를 사용합니다.
최종 사용자는 데이터를 사용하고, 내부 직원은 데이터를 사용하며, 사람들은 데이터를 만들어야 합니다.
빠르고 신속한 의사 결정.그래서 데이터에 대해 이야기할 때는 페르소나에 대해 생각하고 싶어요. 왜냐하면 우리는 AWS에 있기 때문이죠.
우리는 고객에 집착하기 때문에 누가 데이터를 사용하는가의 관점에서 데이터를 생각해야 합니다.그래서 데이터 처리와 같은 것에 대해 좀 더 깊이 알아보도록 하겠습니다.
Spark를 예로 들어보죠.하지만 생각해 보고 싶은 건
외부 사용자 같은 것들이요.따라서 비즈니스의 일환으로 사용자에게 공개하는 데이터가 있습니다.다음과 같은 경우가 종종 있습니다.
과거 데이터, 배치 데이터, 사람들이 보는 것
월별, 주별로, 알려진 패턴이 있습니다.그리고 점점 더 많아지고 있습니다.
데이터를 활용하여 실시간으로 의사결정을 내려야 합니다.제너레이티브 AI가 많이 사용되는 부분이 바로 이 부분일 것입니다. 그렇죠?사람들이 즉석 쿼리, 질문에 대한 임시 답변 등을 위해 프롬프트 엔지니어링과 같은 것들을 사용하는 곳이죠.
그리고 그런 것들도 있죠.내부적으로는 페르소나가 있습니다.
데이터를 활용하여 다음과 같은 결정을 내리고 싶은 사람
내가 어떻게 운영하는지부터 뭐든지
시스템이 더 효율적인가요?어떻게 하면 더 잘 확장할 수 있을까요?보안에는 어떤 것이 있을까요?
지금 보고 있는 감사 내용이요?그리고 옵저버빌리티 도구
도움이 좀 될 것 같아요.그런 다음 처리해야 합니다.
정말 많은 데이터죠, 그렇죠?이제 Spark, 클러스터 기술, 과거의 Hadoop 같은 것들에 대해 알아보겠습니다.그리고 Flink와 같은 새로운 기술들이 가져다 주었습니다.
스트리밍 데이터와 배치 데이터를 함께 처리하려면 어떻게 해야 할까요?
이러한 결정을 내리기 위해서요.그럼 잠깐 얘기해 보죠.
플랫폼 엔지니어링에 대해많은 고객들이
쿠버네티스에서 표준화되었습니다.엘라스틱 쿠버네티스 서비스인 EKS를 사용합니다.이번 주 트랙의 다른 세션에서도 Auto Mode 등과 같은 멋진 발표가 몇 가지 있습니다.하지만 스타트업일 때는 개발팀만 있고 그 개발팀의 일원으로 플랫폼 엔지니어링을 하는 경우가 많습니다.하지만 시간이 흐르면서 회사가 성장함에 따라 Kubernetes와 함께 플랫폼 엔지니어링이 등장하게 되었습니다.그리고 이러한 문제 중 상당수가 1세대에 집중되어 있었습니다.
웹 애플리케이션, 마이크로서비스, 이벤트 기반 아키텍처에 대해서요.저는 이러한 등장을 항상 이렇게 부릅니다.
페르소나와 목표 사이의 약간의 충돌이죠, 그렇죠?개발자들은 자유를 원하는 곳에서는 자신의 자유를 활용하고 싶어하죠.
가장 좋아하는 오픈 소스 도구, 기술, 그들은 자율성을 원합니다.새로 만들고 싶어요
앱, 배포하고 싶어요. 빨리 꺼내고 싶어요.그리고 플랫폼 팀이 여러 가지로 고민하고 있을 겁니다.
보안 시스템, 확장성, 비용, 성능 같은 것들이죠.그래서 1세대는
아시다시피 이 중에서 플랫폼 팀은 정말
웹 애플리케이션, 마이크로서비스, 트랜잭션 시스템을 생각해 봅시다.그리고 플랫폼 엔지니어링
자율성을 제공하는 것과 표준 같은 것들을 개발자와 비슷한 방식으로 자동화하는 것 사이의 중간에서 만날 수 있는 방안으로 떠올랐습니다.관련 논의가 많이 진행되고 있습니다.
전체 플랫폼 엔지니어링.목요일에 하나 할게요.
서버리스 트랙에서는 개발자 페르소나 관점에서 플랫폼 사용자입니다.자, 이렇게 할 수 있겠죠.
제가 시작해보면 세션이요하지만 우리가 이야기할 때는
플랫폼 엔지니어링에 대해 말하자면,
고객들은 종종 어려움을 겪습니다. 개발자와 이를 사용하는 사람들 사이의 경계는 어디일까요?
플랫폼, 그리고 플랫폼 팀?클러스터를 판매하나요?코드를 서비스로 판매할 수 있나요?개발자가 쉽게 사용할 수 있도록 만들 수 있나요?
그냥 코드를 체크인하기 위해서?그래서 이것들은
1세대 문제들이죠.다 해결됐죠?하지만 아닐 수도 있겠죠.여기서 경계선이 어디인지에 대해서는 여전히 많은 논쟁이 있을 것입니다. 바로 워크로드 때문이죠.자, 이제 본론으로 넘어가겠습니다.
데이터와 수많은 데이터의 시대, 그리고 데이터 과학자와 엔지니어들이 데이터 개발을 시작했습니다.
노트북과 관련된 것들, SQL 데이터 처리를 사용하죠.이들은 스테이트풀 애플리케이션을 구축하고 있습니다.개발 중입니다.
스트리밍 및 이벤트 워크플로가 있는 애플리케이션.노트북을 사용하고 있습니다.
Python 또는 R을 사용하여 애플리케이션과 노트북을 빌드합니다.
제너레이티브 AI, ML 또는 모든 유형의 데이터 처리를 수행하는 기업그들은 데이터를 만들고 있습니다.
호수와 데이터 메시, 그리고 데이터를 연합하기 위해 그 앞에 있는 애플리케이션.그리고 플랫폼 팀은 갑자기 사용하기에 가장 적합한 스토리지가 무엇인지와 같은 문제에 대해 걱정해야 합니다.그들에게 GPU를 줄 수 있나요?오늘 아침에 인페렌티아2와 Trainium2가 발표되었는데 그 얘기가 나왔는데
그것도 마찬가지죠?그래서, 새 제품이 생겼습니다.
DevOps 유형, MLOP, 데이터 파이프라인, LLM의 라이프사이클, MyData의 라이프사이클.이제 이러한 문제들은 새로운 관심사입니다.
이 다음 세대에서 말이죠.그래서 저는 그 얘기는 안 할게요
이 모든 게 다 소진됐어요. 하지만 많은 목표가 있어요.
플랫폼 엔지니어링과 데이터 워크로드에 맞죠?그렇다면 어떻게 해야 올바른 결과를 얻을 수 있을까요?
리소스, 개발자?제대로 된 걸 찾고 싶어요
머신 유형, 올바른 유형의 GPU,
워크로드, 노트북, 데이터 처리에 적합한 스토리지 유형고객들은 적절한 보안을 원하고,
적절한 격리.그들은 데이터를 원하지 않아요.
작업을 방해하기 위해 여기로 작업이 실행되고 있습니다.
트랜잭션 시스템이 저기 있어요.그리고 저는 그 곳에서 하고 싶어요.
가능한 최고의 가격대죠.그리고 물론, 마치
개발자, 데이터 과학자, 데이터 엔지니어는 매우
PyTorch 프레임워크, 텐서플로우 등 각자 좋아하는 다양한 유형에 대해 의견을 개진했습니다.
데이터 애플리케이션을 위한 프레임워크가 많이 있습니다.그렇다면 데이터 집약도가 매우 높은 이 차세대 애플리케이션에서 이러한 자율성을 어떻게 지원할 수 있을까요?다양한 과제가 많이 있습니다.
스테이트풀 워크로드의 경우, 그렇죠?지금 얘기하고 있는 게
어떻게 하면 수천 개의 노드를 사용할 수 있을까요?
정반대의 문제라도 말이죠. 정말 큰 이미지는
시작하는데 시간이 좀 걸려서 데이터를 워밍업하세요.쿠버네티스에 있는 것들 중 일부는 정말 최적화하고 있습니다.
컴퓨팅을 매우 빠르게 가동하고 문제가 있는지 감지한 첫 번째 세대입니다.
패스를 할 때마다 실패하고 포드를 죽이면 새 포드를 불러오죠.그리고 때때로 이러한 데이터 워크로드는 체크 마크나 체크포인트 같은 작업을 수행해야 할 때가 있습니다.
데이터 처리 중입니다.그들에게는 이런 새로운 문제가 생겼습니다.
스테이트풀 애플리케이션과 함께 말이죠.때로는 스케일러가 너무 빠르거나 네트워크 구성이 다를 수 있습니다.모델에 중력이 있나요?데이터에 중력이 있나요?심지어 사람들은 어떤 경우에는 데이터가 더 저렴하다는 것을 깨닫고 있습니다.
컴퓨터에 더 가까이 다가가세요.아시다시피, 모든 것이 있습니다.
이러한 패턴의 변동이 심하기 때문에 플랫폼 팀은 이에 적응해야 합니다.다음은 그 중 몇 가지입니다.
우리가 보게 될 문제들은 크리스티나와 빅터가
그들이 이걸 어떻게 구현했는지 실제 사례를 들어보죠.아주 빠르게 말이죠.알다시피, 다른 게 있어요.
사람들을 위한 옵션.꼭 서버리스 방식으로 Spark, EMR을 할 수 있습니다.
일을 할 때는 서버리스 패러다임을 사용하세요.
AWS에 좀 더 기본적으로 적용되며 일부 기본 기능도 제공됩니다.
서비스, 많은 장점.많은 고객이 선택합니다.
표준화를 위한 쿠버네티스.우리는 최고의 제품 중 하나를 보유하고 있습니다.
EKS에 있는 쿠버네티스 서비스는 다음과 같습니다.
보유한 에코시스템 덕분에 Spark를 실행하는 다양한 방법이 있습니다.오퍼레이터를 사용할 수 있습니다.
Spark를 직접 실행하세요.물론 아마존도 있습니다.
EKS에서 실행되는 EMR은 물론 다음과 같은 옵션도 있습니다.
두 세계의 장점을 모두 누릴 수 있게 해줍니다.
관리 및 유연성, 최고의 오픈 소스 프레임워크.그럼 쿠버네티스와 데이터 맞죠?이에 대해 이야기해 보면 다양한 내용이 있습니다.
패턴은 초기부터 스토리지로 시작되었고
사용자 지정 리소스 정의, 이벤트 기반으로 이동
이벤트를 제공하는 Kafka를 사용하는 애플리케이션,
이벤트 스트리밍, 메시징.그럼 본격적으로 시작해볼까요?
이러한 유형의 Hadoop 워크로드에서 벗어나는 아키텍처는 메모리 집약적인 병렬 프로세싱의 워크로드를 처리합니다.그런 다음 Apache로 넘어갑니다.
플링크는 마치 실시간 데이터가 둘 다 필요한 것과 같습니다.
그리고 배치 데이터가 필요하고 처리를 해야 합니다.
이 두 가지 모두에 대해 말씀드리자면, GPU와 다른 유형의 특수 기술이 필요합니다.
집약적으로 실행하기 위한 하드웨어, 모델 트레이닝 등등.그리고 특수 스케줄러
서비스형 노트북과 같은 기능을 지원합니다.그래서 우리는 진화를 거듭했습니다.
데이터를 위한 쿠버네티스.프로젝트가 하나 있어요. 맡아주세요.
EKS에 관한 데이터를 정말 빠르게 사진으로 보여드리죠.나중에 저희에게 오실 수 있다면, 다양한 청사진이 많이 있습니다.
그리고 EKS에서 Spark를 실행하는 것과 같이 다양한 패턴을 프로비저닝하는 데 도움이 되는 모범 사례도
EKS에서 Flink를 실행하거나 EKS에서 Kafka를 실행할 수도 있습니다.따라서 시작하는 데 도움이 되는 다양한 유형의 스크립트가 있습니다.마지막으로 말씀드리자면,
데이터에 대해 말씀드리자면, 실제로 라이프 사이클이 있습니다.그래서 우리는 데이터 플랫폼이 갖춰야 할 지원에 대해 이야기했습니다.예를 들어, 어떻게
데이터가 사용자 환경, 시스템 인제스트에 들어오나요?그리고 지원도 필요하죠.
다양한 유형의 도구, Kafka 기반 도구.관리형 작업을 수행할 수 있습니다.
Amazon MSK와 같은 서비스나 Kafka 및 쿠버네티스를 실행할 수 있습니다.기본 옵션이 있습니다.
키네시스 같은 것들이죠.그리고 데이터를 스테이징하는 데 도움이 되는 워크플로 도구도 있습니다. 다음과 같은 것들이죠.
스텝 함수, 에어플로우, 아르고 워크플로
일부 인스턴스를 제공하는 다양한 배치 스케줄러
더 많은 스테이트풀 패턴이 나왔고 이미 말씀드렸지만
데이터 처리에 대해서요.그런 다음 데이터 처리 계층으로 들어가서 알아보겠습니다.
일괄처리 스케줄링처럼, 일종의 모든 작업을
하룻밤 사이에 처리해야 합니다.그리고 나서 원하는 건
데이터를 밖으로 내보내고 사용하세요.변환을 할 수도 있고, 이에 대해 SQL을 할 수도 있습니다.
다른 방법으로 데이터를 카탈로그화하고 데이터를 API로 사용할 수 있도록 하세요.이것이 바로 데이터의 라이프사이클입니다.이제 그걸로 할게요
이제 더 깊이 들어가서 크리스티나한테 건네줄게크리스티나, 잠깐 시간을 내줬어요. - 고마워요, 롤랜드안녕하세요, 여러분.다음으로 세 가지를 다루겠습니다.
할 수 있는 일들.그래야 자신의 상황을 최적화할 수 있습니다.
성장을 위한 쿠버네티스 기반 분석 플랫폼.이제 시작하실 준비가 되셨군요.
분석 워크로드는 AWS로 빠르게 유입될 뿐만 아니라 다양한 지역으로 확장됩니다.제 이름은 크리스티나 안도노프입니다.
저는 솔루션 아키텍트로서 분석을 구축하는 데 있어 고객 여러분을 도와 드립니다.
쿠버네티스 기반 플랫폼.롤랜드가 말했듯이, 그럴 만한 한 가지 이유가 있습니다.
여기 여기 계신 건 이미 달리고 계신 거잖아요
쿠버네티스의 비즈니스 애플리케이션.사용하고, 확장하고, 이제 분석을 하는 것이 편합니다.
워크로드가 들어오고 있습니다.그래서 우리가 참여할 때
이런 고객들은 보통 이 곳에서 두 팀으로 나뉘어 있습니다.
동일한 컴퓨팅을 중심으로 두 개의 개별 플랫폼을 구축합니다.그 이유는 아닙니다.
트래픽만큼이나 컴퓨팅 자체도 마찬가지입니다.
해당 컴퓨팅에 빌려주는 워크로드의 패턴.보세요. 비즈니스 애플리케이션의 경우 트래픽 패턴이 엄청납니다.
캘리포니아의 날씨처럼요.대부분의 경우,
최고점 80대, 저점 60대, 그리고 사소한 예외를 제외하면
매우 예측 가능합니다.에 대한 트래픽 패턴
분석 워크로드는 뭐, 뭐, 좀 더 비슷하죠.
허리케인 시즌의 카리브해 날씨그리고 일자리가 넘쳐나면
클러스터에 도착하면, 그 데이터 플랫폼 팀의
책임은 이러한 클러스터를 확장할 수 있도록 하는 것입니다.
매우 짧은 시간 내에 작업을 수집하고 최적화하여 작업을 빠르게 처리하고 이 모든 작업을 비용 효율적으로 수행할 수 있도록 합니다.다음으로 수행할 수 있는 작업에 대한 몇 가지 모범 사례를 살펴보겠습니다.
이러한 클러스터를 최적화하세요.그리고 제가 모범 사례를 말씀드렸을 때, 제가 가정하고 있는 건
이미 Kubernetes에서 비즈니스 애플리케이션을 실행하고 계실 텐데요, 다음 부분만 살펴보도록 하겠습니다.
비즈니스 플랫폼 간의 모범 사례 차이
그리고 귀사의 데이터 플랫폼.우리는 처음부터 모범 사례를 바탕으로 클러스터를 구축할 것입니다.빌드를 분할해 보겠습니다.
세 개의 논리적 계층으로 이루어져 있습니다. 여기서 계층 1은 기본적이면서도 프로덕션에 바로 사용할 수 있는 클러스터를 구축할 것입니다.
분석에 최적화되었습니다.레이어 2가 설치될 예정입니다.
클러스터를 만들기 위한 다양한 오픈 소스 도구
특수 제작된 클러스터.그리고 레이어 3은
해당 클러스터에서 테넌트를 온보딩하세요.그리고 실제로 여러분 앞에도
클러스터를 생성하더라도 네트워크가 제대로 작동할 수 있도록 네트워킹을 설정해야 합니다.
규모를 확장하면 IP가 충분합니다. 왜냐하면
IPv4에서는 IP 고갈이 심하다고 들었는데
오버레이 네트워크를 사용하는 것이 자연스러운 성향일 수도 있습니다.하지만 오버레이 네트워크는 필연적으로 약간의 지연 시간을 추가하게 되는데, 이는 역효과를 낳습니다.
여기서 달성하고자 하는 것은따라서 오버레이 네트워크 대신 라우팅할 수 없는 특수한 범위의 IP를 사용할 수 있습니다.이 예제에서는 노드와 포드에 사용할 수 있는 130개의 IP를 제공하는 두 개의 CIDR 블록을 사용합니다.제가 주로 궁금해하는 부분은 다음과 같습니다. IPv6은 어떨까요?네, 네, IPv6를 사용하면
우리의 모든 피로 문제는 결국 사라집니다.쿠버네티스는 IPv6을 지원합니다.
2년 전부터요.스파크는 작년부터 IPv6을 지원합니다.
연도, 버전 3.4 이상.하지만 가능성은 얼마든지 있습니다.
스택의 어딘가, 또는 클러스터가 통신하는 곳에서도 아직 IPv6을 지원하지 않을 수 있습니다.따라서 선택사항임은 분명하지만, 만약 사용하기로 한다면
꼭 테스트해 보세요.어느 쪽이든 여기저기 가시면 IP가 충분하다고 판단할 거예요. 그러면 저희가 진행하도록 하겠습니다.
클러스터를 생성하고, 클러스터를 설치하기 시작합니다.
클러스터에 애드온 추가.첫 번째 애드온은
여기에 들어가는 것은 VPC CNI입니다.그리고 VPC CNI가 등장합니다.
이 기본 설정을 사용하면 WARM_ENI_TARGET=1입니다.그게 무슨 뜻일까요?그게 무슨 뜻이냐면
인스턴스가 생기면 ENI가 생성되고 그 ENI에는 미리 워밍된 IP 집합이 들어 있습니다.이러한 IP 중 하나가 작업자 노드로 이동한 다음 스팟이 나타나면 IP가 할당됩니다.
예열된 IP에서 말이죠.자, 만약 그 인스턴스가
c5.2xlarge가 될 경우 해당 ENI는 15개의 IP를 보유하게 됩니다.하지만 분석의 경우 경향이 있습니다.
c5.18xlarge와 같은 훨씬 더 큰 인스턴스를 사용하려면
인스턴스는 두 개의 ENI와 함께 제공되며 각각 50개의 IP를 보유합니다.즉, 100개의 IP입니다.분석을 위해 말씀드리자면, 저희 포드는
더 커지는 경향이 있습니다. 즉, 이 인스턴스에서 거의 100개의 포드를 스케줄링할 수는 없습니다. 그리고 이 모든 IP는 대부분
그 중 일부는 낭비될 것입니다.그리고 그 130명이라는 풀은 그냥
그걸론 충분하지 않을 수도 있겠다고 말했죠.여기서 할 수 있는 일은 정해져 있습니다.
VPC CNI의 경우 MAX_ENI는 1입니다.그 다음은 두 번째입니다.
여기 옵션이 있습니다. 맥팟은 30개입니다.큐블릿의 설정입니다. 30과 같은 정적 숫자로 설정하거나 데이터를 확인할 수 있습니다.
청사진도 있고요.패턴은 저마다 다릅니다.
여기에 따라 해당 옵션을 자동으로 설정합니다.
다양한 유형의 Linux에 대한 인스턴스의 크기마지막으로 VPC의 경우 CNI, VPC가 필요합니다.
CNI는 매우 수다스러운 편이고 누구와 대화하기를 좋아하는지,
가장 친한 친구인 EC2 API입니다.일반적으로 VPC CNI가 만드는 모든 IP를 확인해 보세요.
EC2 API에 대한 호출.그리고 만약 당신이 시도한다면
한 가지 예를 들어보죠. 그건 문제가 아니에요.하지만 시도하고 있다면
한 번에 100개의 인스턴스를 가져오려면 어떻게 될까요?API를 제한할 거예요.여기서 할 수 있는 일은 접두사 위임을 활성화하는 것입니다.enable 프리픽스 위임의 기능은 16개의 IP를 하나의 쿼리로 패키징하고 EC2 API를 쿼리하므로 쿼리가 줄어듭니다.
EC2 API 폴드 16으로.좋아요, VPC CNI가 설정되었습니다.다음으로 수수께끼를 하나 드릴게요.CoreDNS가 왜 나오는지 아세요?
모든 파티에 초대됐나요?그게 모든 걸 해결해주니까요.뭐, 대부분 그렇죠.분석용으로는 보통 CoreDNS를 사용합니다.
많은 인스턴스가 등장하기 때문에 사전에 확장해야 합니다.그리고 과거에는 이렇게 해야 했습니다.
CoreDNS를 확장하려면 클러스터 비례 오토스케일러라는 오픈 소스 프로젝트를 사용하세요.그리고 좋은 소식이 있어요.지난 5월에 저희가 발표한 바 있습니다.
CoreDNS를 위한 다양한 스케일링.즉, 다음과 같은 경우
EKS 버전 1.25와 CoreDNS 1.9에서 해당 버전으로 한 번 업그레이드한 적이 있습니다.
또는 5월 이후부터는 이 기능을 이미 사용할 수 있으며, 다음과 같은 작업만 하면 됩니다.
설정하고 활성화하기만 하면 CoreDNS가 작동합니다.
필요에 맞게 사전 예방적으로 확장할 수 있습니다.또한 설치해야 합니다.
노드로컬 DNS라는 오픈 소스 프로젝트.노드/로컬 DNS는
설치한 데몬셋은 모든 단일 노드에서 실행됩니다.
그리고 쿼리를 캐싱하기 때문에 문제가 줄어듭니다.
CoreDNS로 가는 쿼리.마지막으로 한 가지 더 말씀드리자면
CoreDNS가 외부 도메인을 해결하는 방법에 대해 조금 이야기해 보겠습니다.도메인을 주면
s3.amazonaws.com처럼 해당 구성으로 이동하면 ndots:5라는 설정이 있는데 ndots:5가 표시됩니다.이것이 의미하는 바는 CoreDNS입니다.
그 도메인을 봅시다. 아, 이 도메인에는 점이 두 개 있고, 두 개는 다섯 개보다 작습니다.따라서 이것은 내부적인 것임에 틀림없습니다.
내 클러스터 도메인으로그래서 제가 할 일은 여기로 가서 모든 것을 추가하는 것입니다.
검색줄에 옵션을 넣으면 문제가 해결됩니다.
제가 외부로 나가기 전에 불필요한 질문 다섯 개를 해봤는데
도메인이 어디에 있는지 확인해 보세요.여기서 할 수 있는 일 한 가지
무엇보다도, 제발 바꾸지 말아주세요
노드 5개를 CoreDNS로 설정하지만 노드는 설정할 수 있습니다.
포드에서만 2까지.그게 무슨 소용이 있냐면
도메인을 살펴보세요. “오, 점이 두 개 있는데 바로 해결할게요.” 라고 적혀 있을 거예요.한 번의 쿼리로 해결될 거예요.그러면 문제가 완화될 거예요.
CoreDNS 포드에 가해지는 압박, 이것이 바로 CoreDNS가 유지할 수 있는 방법입니다.
파티 셀러브리티 신분이죠.다음으로, 비즈니스 애플리케이션의 경우 여기에서 일부 컴퓨팅을 확장해 보겠습니다.따라서 비즈니스 애플리케이션의 경우 이 오픈 소스 프로젝트를 사용하는 경향이 있는데, 많은 고객들이 이 오픈 소스 프로젝트를 사용하는 경향이 있습니다.
클러스터 오토스케일러라고 합니다.클러스터 오토스케일러는 CPU와 메모리를 기반으로 인스턴스를 확장합니다.그리고 그 기능은,
인스턴스를 확장하는 데 보통 2~3분 정도 걸립니다.
인스턴스를 가동하기 위해서요.데이터 플랫폼 팀이 보입니다.
다른 오픈 소스로 전환한 첫 번째 팀입니다
카펜터라는 프로젝트.카펜터는 에서 나왔어요.
AWS는 그것을 오픈 소스로 만들어 기부해서 찾고자 했습니다.
작년 오토스케일링.그리고 올해 우리는 GA로 졸업했습니다.그래서 지금은 V1이고 안정적입니다.
이제 바로 사용할 수 있습니다.차이점이 있다면
카펜터와 함께라면 카펜터 한 명이 완벽하다는 거죠.
AWS 요금에 대해 알고 있습니다.따라서 포드에 맞는 인스턴스를 선택하는 것만이 아닙니다.
메모리와 CPU 얘기가 나와서 말인데 제일 많이 뽑을 거예요
비용 효율적인 인스턴스.또한 카펜터는 매우
이러한 인스턴스를 훨씬 더 빠르게 확장하는 방법을 빠르게 확인할 수 있습니다.보통 1분 이내에 인스턴스를 확장하는 것을 볼 수 있습니다.자세히 살펴보기 전에
카펜터 구성, 잠깐 얘기해 보죠
Spark 작업의 작동 방식에 대해 알아보겠습니다.보통 데이터 엔지니어가
Spark 작업을 제출하면 드라이버 포드가 나타나고 해당 드라이버 포드는
작업 관리를 담당합니다.해당 드라이버 포드가 담당합니다.
실행기를 스케줄링하는 역할을 하며, 만약 있다면
실행기가 중단되면 드라이버 포드는 다음을 알고 있습니다.
다시 일정을 잡고 작업을 완료합니다.드라이버 포드가 중단되면 전체 작업을 다시 시작해야 합니다.이것이 Karpenter에게 의미하는 바는 드라이버 포드를 온디맨드 인스턴스에 설치할 수 있다는 것입니다.
그리고 스팟 용량이 대폭 할인된 상태에서는 실행기가 이상적입니다.Karpenter의 경우 실제로 하나의 NodePool을 설정하고 두 용량을 모두 제공할 수 있습니다.
NodePool에 입력한 다음 두 주석 중 하나를 사용하십시오.
또는 레이블, 테인트, 랜드에 대한 톨러레이션도
각 워크로드좋아요, 좋아요.이제 컴퓨팅을 확장하도록 설정했습니다. 다음 메뉴에는 스토리지가 있습니다.스토리지라고 하면
스파크 셔플 스토리지 말이에요.보세요, 이런 인스턴스가 있습니다.
이름에 점 앞에 d를 붙여서 입력하세요.d가 의미하는 바는 해당 인스턴스가 SSD 드라이브와 함께 제공된다는 뜻입니다.
인스턴스에 내장되어 있습니다.그게 가장 빠를 거예요
스토리지가 제공됩니다.따라서 해당 인스턴스와 스토리지를 활용하는 것이 좋습니다.이제 어떤 인스턴스에는 하나가 있고, 어떤 인스턴스에는
하나 이상의 SSD 드라이브.그리고 최대한 활용하기 위해서요.
전체 용량 중에서 이러한 드라이브를 설정해야 합니다.
카펜터를 사용하여 RAID0 모드로 전환하세요.아주 간단한 인스턴스입니다.
소스 정책 RAID0.이전에 사용한 적이 있는지는 모르겠지만 예전에는 계산을 수행하는 사용자 데이터 스크립트였습니다.정말 멋지네요.멋질 뿐만 아니라 더 이상 실행기를 위한 호스트 포드를 설정할 필요가 없습니다.엑시큐터에게 직접 연락할 수 있습니다.
해당 스토리지에 액세스할 수 있습니다.뭐, 그래도 필요하실 수도 있겠네요
Spark에서 사용할 스토리지의 양을 제한하세요
구성이지만 그게 전부입니다.그러니까 단기적으로는
작업은 완벽하지만 장기 실행 작업의 경우 해당 인스턴스가 중단되면 드라이버 포드가 이를 알고 다른 실행 프로그램을 불러오지만 이제 체크포인트를 잃어버렸습니다.따라서 이 두 실행자는 처음부터 다시 시작해야 합니다.따라서 실행 기간이 더 오래 걸리는 작업이라면 더 나은 옵션이 있을 수 있습니다.
EBS 볼륨을 사용하는 것입니다.그리고 Spark 구성에서는
그렇게 할 수 있습니다. 드라이버 포드를 만들 수 있습니다.
이 구성의 EBS 볼륨을 인식합니다.그리고 만약
인스턴스가 중단되면 다른 실행기가 나타납니다. 드라이버 포드는 EBS 볼륨의 위치를 알고 새 실행기에 연결하며 중단된 실행기가 중단된 곳에서 새 실행기가 시작됩니다.
EBS의 체크포인트 데이터.스토리지에 관한 마지막 사항은 이 두 가지 옵션이라는 것입니다.
상호 배타적이지 않습니다.사용할 수 있고 제공할 수 있습니다.
둘 다 최종 사용자에게 제공되며 최종 사용자는 다음을 선택할 수 있습니다.
실행 중인 작업에 따라 어느 것을 사용할지 선택하세요.앞서 말씀드렸듯이, 카펜터
인스턴스를 매우 빠르게 불러옵니다.다음으로 해야 할 일은 해당 인스턴스가
이미지를 다운로드하고 포드를 실행해야 합니다.그리고 경험상 가장 좋은 방법은 다음과 같습니다.
인스턴스를 만들고 싶은 순간부터 가지고 있는 순간까지
내 포드를 가동하고 실행하려면 해당 프로세스를 1분 미만으로 완료할 수 있습니다.여기서 몇 가지 최적화를 할 수 있습니다.무엇보다 먼저,
해당 이미지는 인스턴스와 최대한 가깝게 배치하세요.ECR에 저장하는 경우 지역 간 복제가 가능한 지역에 해당 이미지가 있는지 확인하세요.저장하는 경우
다른 리포지토리에서는 ECR용 풀스루 캐시를 지원하고, 풀스루 캐시를 사용하고,
해당 지역에 저장하세요.VPC 엔드포인트를 설정하여 이미지가 다운로드되도록 하세요.
네트워크를 통하면 밖으로 나갔다가 다시 들어갈 필요가 없습니다.그걸로 충분하지 않으면 충분하지 않을 수도 있습니다.
1분 내로 사진을 찍을 수 있도록 말이죠. 이미지가 예쁘다면
크기가 크면 5~10기가라는 뜻인데 할 수 있는 일은
이미지에서 대용량 파일 (예: JAR) 을 제거할 수 있습니다.
파일 및 기타 라이브러리S3 익스프레스 존 1에 저장할 수 있습니다.그런 다음 이미지를 간결하게 만들고 다운로드하면 S3-Mountpoint를 사용하여 이 S3 버킷을 다음과 같이 마운트합니다.
실행기로 가는 드라이브.자, 그럼 이제 1분 내로 처리하겠습니다.마지막으로, 첫 번째 레이어에서 모니터링을 하고, 프로덕션에 적용하기 전에 모니터링을 설정하세요.여러분 대부분이 Spark와 오픈 소스를 모니터링한다는 것을 알고 있습니다.
사용 중인 소프트웨어에는 지표가 함께 제공됩니다.세 가지를 모니터링해 주셨으면 좋겠어요.
여기에 더 많은 것들이 있습니다.첫 번째는 쿠버네티스 컨트롤 플레인을 모니터링하는 것입니다.우리는 다음과 같은 내용을 공개합니다.
쿠버네티스 컨트롤 메트릭스.EKS 모범 사례 가이드를 확인하고 반드시 모니터링하세요.AWS API를 모니터링해야 합니다.CloudWatch에서는 지표를 제공합니다.앞서 말씀드렸듯이
VPC CNI를 사용하는 경우 EC2 API를 제한할 수 있습니다.액세스 권한이 있는지 확인하세요.
CloudWatch를 데이터로 변환하여 이러한 측정치를 제한할 수 있습니다.
Grafana 또는 모니터링 공급업체에 소스를 제공하고 해당 지표의 스로틀 메트릭을 확인하십시오.EBS API도 마찬가지입니다.마지막으로, 꼭 확인하세요.
네트워크를 모니터링합니다.예를 들어 CoreDNS를 참조하십시오.
UDP 프로토콜을 사용하고 있습니다. 즉,
리눅스의 컨트랙트 테이블, 연결 트래킹
테이블이 가득 찼습니다. 해당 CoreDNS 패키지
삭제될 거야.그리고 너도 그걸 알고 싶어지잖아
CoreDNS 메트릭을 보면 네트워크를 다시 모니터링해야 합니다. EKS 모범 사례 가이드
네트워크 모니터링에 대해서는 확인해 보십시오.이것으로 첫 번째 레이어가 끝납니다.이제 확장도 가능하고 성능도 충분히 낼 수 있는 클러스터가 생겼습니다.
그리고 비용 효율적입니다.다음으로 추가해 보겠습니다.
이 클러스터에서 만들 수 있는 다양한 오픈 소스 소프트웨어
용도에 맞게 구축된 클러스터입니다.고객이 가장 많이 사용하는 오픈 소스 프로젝트는 Apache Flink와 Apache Spark입니다.보통 궁금한건, 이걸 하나로 합칠 수 있느냐는 거죠.
같은 클러스터에 넣을까요, 아니면 개별 클러스터로 분할해야 할까요?이에 대한 답은
뭐, 상황에 따라 다르죠.클러스터가 더 작거나 클러스터가 최대 2-300개 노드인 경우 실행할 수 있습니다.
동일한 클러스터에서.하지만 클러스터가 시작되면
그 이후로도 성장한다면 시작하는 것이 좋을 것이다.
둘을 분리할 생각이에요.나머지 강연은 여기서는 주로 Apache Spark에 초점을 맞출 것입니다.아파치 스파크의 경우 오픈 소스 버전을 실행 중이라면 스파크 오퍼레이터를 사용하는 것이 좋습니다.올해 초,
EKS 데이터 관리자는 커뮤니티와 협력했으며
스파크 오퍼레이터를 Kubeflow 커뮤니티에 기부했습니다.그 이후로 저희는
엄청난 버그 수정을 거쳤고, 유지 관리자들이 활발히 활동하고 있습니다.그러니 아파치 스파크를 사용하세요.또 다른 하나는 선택사항이지만 쿠버네티스를 참조하세요.
스케줄러: 선입선출 방식으로 작업을 스케줄링할 수 있습니다.하지만 만약 여러분이 어디서 오신다면
Hadoop 및 YARN 세상처럼 우선 순위가 필요할 수도 있습니다.
큐 또는 갱 스케줄링.이를 활용하려면 이 다른 오픈 소스 프로젝트를 사용하는 것이 좋습니다.
아파치 유니콘 (YuniKorn) 이라 불리는데 스파크와 정말 잘 어울립니다.마지막으로 중요한 것은 워크플로우가 필요하다는 것입니다.
작업을 위한 엔진.가장 흔히 볼 수 있는 것은 아파치 에어플로우입니다.설치하여 자체 관리하거나 관리형 제품을 사용할 수 있습니다.박람회도 볼 수 있습니다.
Argo 워크플로의 양, 심지어 최근에도 Step Functions가
워크플로를 수행하려면 여기를 클릭하십시오.이것으로 두 번째 레이어를 마칩니다.다음으로 테넌트 격리에 대해 조금 이야기해 보겠습니다.
테넌트 온보딩으로 넘어가기 전에 전략을 세워보세요.보세요, 일부 고객의 경우
클러스터당 하나의 팀을 사용하지만 대다수를 차지합니다.
실제로 멀티테넌트 클러스터를 사용하고 있는 고객 중
네임스페이스를 서비스로 사용그리고 만약 당신이 사용하는 경우
서비스로서의 네임스페이스는 사용자를 위한 세 번째 계층에서 몇 가지 구조를 만들어야 합니다.
네임스페이스, 스파크 API, 심지어 주피터 노트북,
그 밖에도 몇 가지 더 있어요.그럼 이걸 잠깐 살펴보죠.
다른 관점인데요, 관점은 다음과 같습니다.각 계층의 자동화는 누가 만들고 누가 자동화를 소비합니까?
각 계층의 자동화?따라서 레이어 1의 경우 보통
데이터 플랫폼 팀을 볼 수 있습니다.그들은 선택의 도구죠.
일반적으로 테라포밍. 그래서 그들은 테라폼을 만들고 그 테라폼도 사용할 것입니다.레이어 2는 매우 비슷합니다. 테라폼을 만들 것입니다.
그리고 다른 도구들도 있지만 이걸 설치해 줄 거예요.
오픈 소스 소프트웨어만 있으면 거기서 관리할 수 있죠.하지만 세 번째 레이어는 외관상으로 바뀝니다.
조금 다릅니다.그리고 다르게 보이는 것은
데이터 엔지니어들은 보통 티켓팅 시스템을 거쳐야 한다는 것이죠. 아니면 데이터 엔지니어들이 접근 권한이 있다면 말이죠.
Terraform 플랫폼을 사용하세요. 정통하지 않아서 도움을 받으려면 티켓을 열어야 합니다.이러한 티켓이 나오는 이유 중 하나는 사실 이러한 AWS 리소스 때문입니다.나머지 부분에는 몇 가지 도구가 있고, 이를 기본 차트에 올릴 수 있고, 다른 도구처럼 사용할 수 있습니다.하지만 제작을 해야 한다면
AWS 역할, 정책, S3 버킷, RDS 인스턴스,
권한이 있는 AWS의 모든 리소스, 데이터
엔지니어가 티켓을 열고 보안 담당자가 이 티켓을 승인해야 합니다. 데이터를 바탕으로 누군가가 티켓을 승인해야 합니다.
플랫폼 팀에서 Terraform을 집어 들고 복사하여 붙여넣을 것입니다.
이 구조를 만들면 규정 준수 팀이 이를 감사해야 합니다.이 프로세스를 사용하는 대신 다음과 같이 최적화할 수 있습니다.
사용자에게 적절한 인터페이스를 제공하면
API가 되어야 한다고 생각하는데, 다음을 사용할 수 있습니다.
이를 위해서는 쿠버네티스 API가 필요합니다.그리고 이걸 설치할 수 있습니다.
API를 순서대로 확장하기 위한 쿠버네티스의 오픈 소스 프로젝트
이를 위해서는 IM 정책, S3 버킷 등을 생성해야 합니다.따라서 ACK는 오래 전에 AWS가 오픈 소스로 사용했던 오픈 소스 프로젝트입니다.최근, 올해 EKS는
서비스 팀이 ACK의 모든 컨트롤러를 소유하게 되었습니다.그리고 현재 GA 컨트롤러는 50개입니다.즉, 보장을 받을 수 있다는 뜻이죠.
50개의 AWS 서비스에 대해.그리고 GA가 여러분에게 의미하는 바는 이 문제가 다음과 같이 보장된다는 것입니다.
엔터프라이즈 지원.따라서 ACK를 사용하여 다음을 수행할 수 있습니다.
쿠버네티스 API를 확장하여 API를 생성할 수 있습니다.
테넌트를 온보딩하면 모든 작업을 수행할 수 있습니다.
테넌트를 위한 네임스페이스 벤딩클러스터당 한 팀을 사용하는 경우 해당 고객을 알 수 있습니다.
이를 세 계층 전체로 확장하려고 합니다.하지만 일반적으로 고객 대다수가 이곳을 이용하고 있으며, 이 점에 매우 만족하고 있습니다.제가 처음 시작했을 때 말씀드렸듯이, 여기가
저희는 고객들이 서로 다른 두 팀을 가지고 있는 것을 볼 수 있습니다.
동일한 컴퓨팅을 중심으로 두 개의 개별 플랫폼을 지원합니다.경영진이라면
방에 계시면 아마, 뭐, 이게 좋은 일인가요?나쁜 일인가요?어떻게 해야 하나요?합쳐야 할까요?어떻게 해야 할까요?어떻게 해야 할지 말해줄게.그러니까 제한을 하고 싶진 않으시겠죠?
가능했으면 하는 조직의 성장, 숫자
여러분이 보유하고 있는 플랫폼 팀의 수는 다소 상관이 없습니다.당신이 하고 싶은 것은 바로 당신입니다
도구와 관행을 표준화하고 싶으시다면
조직의 성장을 촉진할 수 있습니다.테라폼에 대해 한 마디 해주세요.그래서 분할을 시작하면
플랫폼 팀이 끝났다고 가정해 봅시다.
플랫폼 팀이 10개이고 Terraform으로 표준화하면 결국 10명으로 늘어날 것입니다.
다양한 코드베이스가 보장됩니다.따라서 표준화하고 싶으신가요?
도구뿐만 아니라 도구가 어떻게 사용되는지에 대해서도요.다시 말씀드리지만, 말씀드렸듯이, 저희는
쿠버네티스 API를 이러한 도구 중 하나로 활용하면 엔지니어에게 API를 제공할 수 있습니다.따라서 설정을 위해 수행해야 할 세 가지 사항은
확장 가능한 분석 플랫폼은 모범 사례를 사용하는 것입니다.
방금 말씀드렸듯이, 최적화, 최적화를 할 수 있도록 말이죠.
확장성, 성능, 비용 측면에서 클러스터를 최적화하세요.수를 제한하는 것이 아니라 조직 성장을 촉진하세요
보유하고 있는 플랫폼 팀의 수 (단, 표준화 기준)
조직의 도구, 모범 사례 및 프로세스.그리고 끝까지 기쁘게 생각하세요.
사용할 수 있는 인터페이스를 갖춘 사용자
플랫폼에 온보딩하세요.이론상으로는 이 모든 것이 훌륭하고 이론에 불과할 것입니다.
우리 고객인 여러분이 이 제품을 실제로 적용해 보지 않았다면 말이죠.저희 고객인 AppsFlyer를 모시게 되어 기쁩니다. Victor가 그 방법을 알려줄 것입니다.
그들은 이 모든 것을 실천에 옮겼을 뿐만 아니라 훨씬 더 많은 것을 제공합니다.
하지만 그들은 대규모로 해냈어요. - 고마워요.고마워요, 크리스티나여기 오게 되어 정말 기쁩니다.안녕하세요, 여러분.롤랜드는 다른 것에 대해 이야기했습니다.
Spark 워크로드를 실행할 수 있는 옵션.말씀드릴 수 있다면 어떨까요?
단 한 번의 결정으로 데이터 조직을 바꿀 수 있습니다.성과를 높일 수 있고,
옵저버빌리티를 강화하고 비용을 절감하며 개발자의 역량을 강화하세요.허구처럼 들리죠?저는 오늘 우리가 1년 전에 내린 결정에 대해 말씀드리려고 합니다.제 이름은 빅터예요.
지난 6년간 앱스플라이어에서 일했던 저는
리얼타임을 담당하는 데이터 플랫폼 그룹을 이끌고 있습니다.
및 분석 데이터 플랫폼.저는 AWS에서 풍부한 경험을 가지고 있습니다.
에코시스템 및 데이터 처리, 그리고 가장 큰 것 중 하나
AppsFlyer의 장점은 대규모로 처리할 수 있다는 것입니다.더 많은 것이 있다는 것을 알고 계셨나요?
스마트폰이 70억 개가 넘나요?평균적으로
각 휴대폰에 60개 이상의 앱이 설치되어 있습니다.보여주시면
휴대폰과 애플리케이션을 보면 앱스플라이어 SDK가 탑재된 앱을 확실히 알아볼 수 있을 것입니다.AppsFlyer는 앱 소유자가 광고 캠페인을 최적화하고 해당 앱에 적합한 잠재고객을 찾을 수 있도록 도와줍니다.디지털 분석을 공개합니다.
그리고 이를 실현하기 위해 매일 엄청난 양의 데이터를 처리합니다.이제 바로 시작해 보겠습니다.
분석 워크로드에 대해 알아보고 AppsFlyer에서 어떻게 실행하는지 살펴보세요.먼저 Spark에 대해 조금 이야기해 보겠습니다.Spark는 대규모 데이터 처리를 위한 오픈 소스 분석 엔진입니다.거의 다 찾아보실 수 있을 겁니다.
대규모로 데이터를 처리하는 모든 조직에서 말이죠.다음 중 몇 가지를 살펴보겠습니다.
주요 특징.스파크는 보통
소비를 위한 일괄 처리로 사용되며
다운스트림 데이터 생성.작업에 따라 달라질 수 있습니다.
필요한 CPU, 메모리 및 IO 성능은 서로 다릅니다.처리 시간은 매우 중요하며 적절한 컴퓨팅이 필요합니다.
그리고 확장 전략이 핵심 요소입니다.그리고 Spark 작업은 일반적으로
무국적자 성격을 띠고 있죠.하지만 중단될 경우 데이터 재처리가 필요하므로 SLA에 영향을 미칠 수 있습니다.이제 AppsFlyer의 Spark 작업 관련 문제점에 대해 이야기해 보겠습니다. AppsFlyer는 매일 100페타바이트 이상을 처리합니다.저희는 수천 개의 매우 다른 제품을 운영하고 있습니다.
일자리는 언제든지 가능합니다.우리의 컴퓨터는 널리 분산되어 있습니다.
인텔부터 그래비톤, CPU, 메모리,
스토리지 최적화 인스턴스.기본적으로 이름만 지정하면 바로 사용할 수 있습니다.저희 얘기가 나오면 굉장히 역동적이죠.
우리의 데이터 트렌드에 따르면요.우리는 초당 수백만 개의 이벤트를 처리하므로 트래픽을 확장할 수 있습니다.
매우 빠르게 증가하거나 감소하므로 효율성이 매우 높아야 합니다.
우리의 스케일링 전략을 통해서요.마지막으로, 저희는
SLA를 엄격하게 준수하고 있습니다.데이터 회사로서 우리는 데이터를 제시간에 처리해야 합니다. 그렇지 않으면 비즈니스에 영향을 미칠 수 있습니다.그래서 우리는 다음과 같이 결정했습니다.
이러한 문제를 해결하기 위한 최선의 조치
구성 관리 및 내부 도구로 관리되는 원래 EC2 인스턴스에서 EKS로 워크로드를 이전하고 있습니다.EKS를 선택해야 하는 이유는 무엇일까요?자세히 살펴보죠.몇 가지 영역이 있습니다.
분석 처리와 관련하여 EKS 에코시스템이 탁월한 분야입니다.세 가지를 말씀드리죠.
그리고 그 가치를 보여드리죠.다음에 대해 이야기해 볼게요
스케일링 및 컴퓨팅 최적화를 위한 카펜터옵저버빌리티 (Observability): 강화될 수 있고 가치 있는 결과를 가져올 수 있습니다.
데이터에 대한 인사이트.그리고 지원, 우리의 방법
데이터 엔지니어의 역량을 강화하세요.이 슬라이드를 기억하세요.
인그레스, 소비, 다운스트림을 완벽하게 보여줍니다.이 영역인 데이터 레이크에 초점을 맞추어 보겠습니다.주요 데이터 처리 방법을 예로 들어 보여드리겠습니다.
압축은 EKS에서 실행됩니다.압축된 데이터는 조각난 작은 데이터 파일을 더 크고 체계적인 파일로 병합한 결과입니다.스토리지를 최적화하려면
효율성과 성능은 일반적으로 이것이 첫 번째입니다.
데이터 레이크의 진입점입니다.매시간 실행하고 런타임이 서로 다른 약 150개의 작업을 처리하고 있습니다.
각 반복은 60테라입니다.먼저 문제를 해결하고 목표를 달성하는 데 도움이 되는 Karpenter부터 시작하겠습니다.
컴퓨팅, 스케일링, 비용 성능에 적합합니다.우리의 오래된 모습을 한 번 살펴보세요.
EC2 기본 스파크 클러스터는 이전 모습이었습니다.
EKS와 카펜터로 전환했습니다.구성을 통해 관리되었습니다.
관리 도구 및 eNOS.노란색 선은 사용률을 나타내고 보라색은 사용률을 나타냅니다.
클러스터 크기.규모가 커지는 것을 볼 수 있습니다.
메커니즘이 효과적이지 않습니다.사용률이 떨어지면 노드 규모 축소가 이를 따라갈 수 없습니다.Karpenter가 문제를 해결합니다. 적합한 컴퓨팅을 선택합니다.
구성에 따라 활용도에 따라 효율적으로 확장 및 축소할 수 있습니다.반복할 때마다 규모를 확장합니다.
최대 60개 노드까지 가능하며 처리가 끝나면 다시 축소됩니다.노드 사용률을 살펴보면 약 80% 가 최고점에 달한다는 것을 알 수 있는데, 이는 우리의 최적 지점이고
기존 용량에서는 안정성을 유지하세요.우리는 규모를 축소하기 시작했을 뿐입니다.
사용률이 떨어질 때데이터 처리 비용이 매우 많이 듭니다.
컴퓨팅 파워 측면에서요.이를 통해 유휴 시간을 최소화하고 리소스를 절약할 수 있습니다.
낭비와 불필요한 비용.24시간 주기로 보면
생성 및 종료 모두 1,600회 이상 반복하고 있습니다.그리고 이것뿐이라는 걸 기억하세요.
우리의 컴팩션 워크로드우리에겐 수백 개의 다른 사람들이 있습니다.
프로세싱 워크로드가 서로 다르기 때문에 어떻게 될지 상상만 할 수 있습니다.
종료 및 생성 노드는 매일 표시되는 모습입니다.인스턴트 스프레드를 살펴보겠습니다.카펜터의 전략은
말하자면 가장 안정적이고 비용 효율적인 노드입니다.
언제든지 말이죠.저희는 그래비톤 3세대를 사용합니다.
용량이 없을 때는 2세대로 돌아가죠.스팟 인스턴스만 사용합니다.그리고 베어 메탈 노드를 살펴보세요.머신 리소스의 완전한 제어, 직접적인 하드웨어 액세스,
하이퍼바이저 오버헤드가 없고 성능이 매우 뛰어납니다.노드 풀의 15% 입니다.Spark와 같은 스테이트리스 또는 동적 애플리케이션을 위해 수동으로 베어 메탈 노드를 선택한 사람이 마지막으로 언제였나요?또한 옵션도 제공합니다.
차세대 인스턴스를 사용하고 이를 프로비전할 수 있습니다.
출시되자마자또한 노드를 여러 가용 영역에 배포합니다.Karpenter에서는 가장 비용 효율적인 영역에서 프로비저닝할 수 있도록 합니다.그날은 구역 A가 승자였습니다.영역 B에 비해 노드가 20% 더 많았습니다. 또한 작업 포드가 동일한 가용 영역 내에서 실행되도록 하여 AZ 간 데이터를 제거했습니다.
전송 및 관련 비용.하지만 그날 모든 것이 순조롭지는 않았습니다.현장에서 여러 번 방해를 받았어요.
그 24시간 동안 말이에요.어떤 경우에는 한 시간에 수십 개씩, 엄청난 피해를 줄 수도 있습니다.
우리 SLA에 맞죠?하지만 효과적이기 때문에
Karpenter의 종료 처리를 통해 스팟을 연결할 수 있습니다.
Spark에 대한 종료 신호는 다음과 같은 옵션을 제공합니다.
2분 이내에 중간 단계의 데이터를 마이그레이션할 수 있습니다.이 접근 방식을 사용하면 데이터에서 다시 처리할 필요가 없습니다.
노드 장애 발생 시.거의 스팟 종료가 발생합니다.
워크로드가 원활하게 처리되어 SLA를 잘 준수할 수 있었습니다. 24시간 동안 가장 긴 작업은 33분에 불과했습니다.몇 가지 좋은 결과를 보여드렸습니다.이제 어떻게 할 수 있는지 봅시다.
몇 가지 간단한 구성 변경으로 거의 동일한 성능을 얻을 수 있습니다.확장을 위해 빠른 부팅에 최적화된 Amazon Linux 2024를 사용합니다.
시간 및 커널 성능.이를 통해 프로비전할 수 있습니다.
10초 이내에 노드를 만들 수 있습니다.서비스 해제에 대해서는 조정합니다.
처리 추세에 따른 노드 분배 예산.가능한 시간을 정해 놓았습니다.
유휴 시간을 줄이기 위해 더 적극적으로 해체하고, 우리가 할 때는 덜 공격적으로 해체합니다.
일반적으로 고성능을 유지하기 위해 사용률이 최고조에 달합니다.이 구성은 Spark가 종료 없음을 인식하는 데 사용됩니다.
그리고 스파크 셔플링을 활성화하세요.그리고 우리가 할 수 있도록
2분 내에 마이그레이션할 수 있습니다. 로컬 스토리지를 활용합니다.
최적의 성능을 위해복원력과 비용 효율성을 높이기 위해 각 Spark 작업이 동일한 가용 영역 내에서 실행되도록 구성합니다.다시 말씀드리지만, AZ 간 트래픽과 관련 비용을 제거해 드립니다.그리고 이 섹션에서는 다음을 정의합니다.
로컬 스토리지와 함께 Graviton 인스턴스 사용
최적의 성능.이제 말씀드려야 할 것은
특정 노드를 배치해 보세요. 하지만 아무리 많은 변형을 시도해도 Karpenter는 자동으로 선택됩니다.
비용 효율성 측면에서 지속적으로 우수한 성과를 보이고 있습니다.튜닝은 끝났습니다.이제 우리가 하는 것에 대해 이야기해 보죠.
옵저버빌리티로 할 수 있습니다.카펜터가 어떻게 우리를 도와주는지 봤어요.
컴퓨팅을 관리하고 확장하세요.이제 결합 방법을 살펴보겠습니다.
카펜터, 쿠버네티스, 스파크의 메트릭이 도움이 됩니다.
플랫폼에서 몇 가지 귀중한 통찰력을 얻을 수 있습니다.아시는 분이 얼마나 되세요?
각 데이터 처리 흐름의 백분율은 얼마입니까?압축에서는 모든 처리의 비율이 얼마인지, 언제 시작되고 언제 끝나는지 정확히 알 수 있습니다.
각 처리 주기에서.여기서 확인할 수 있는 내용은 다음과 같습니다.
클릭은 워크로드의 약 28% 를 차지하며, 처음에는
각 사이클의 중간에이를 통해 각 데이터셋의 분포와 가중치를 볼 수 있습니다.
언제든지 가능합니다.게다가 우리는 매일 볼 수 있어요.
주간 및 월간 추세 및 시스템 이해
그리고 비즈니스에 미치는 영향.이 지표를 보세요.클릭이 일어나는 것을 볼 수 있습니다.
지난 주에 비해 처리량이 8% 감소했습니다.그리고 다른 데이터셋도
35개나 증가했는데 조금 걱정될 수도 있겠죠?Datadog 쿼리를 살펴보면 이 정보를 확인할 수 있습니다.
다음의 메트릭을 결합하여 쉽게 얻을 수 있습니다.
쿠버네티스와 스파크하지만 언제 무슨 일이 일어날까요?
가격 추정을 위해 카펜터 메트릭을 추가할까요?카펜터가 비용을 보내줍니다.
인스턴스와 AZ당, 그리고 Spark와 쿠버네티스를 추가하면 얼마인지 계산할 수 있습니다.
각 데이터 처리 비용그래서 우리는 가격을 책정합니다.
분당 데이터를 거의 실시간으로 처리합니다.이 두 가지 이유 모두 엄청나죠.
엔지니어링 및 비즈니스 목적어떻게 하는지 알 수 있습니다.
공동 배포는 비용에 영향을 미치므로 추세에 따라 결정을 내리세요.더 나은 서비스 가격을 책정할 수도 있습니다.
고객에게 제공하세요.이를 통합하여 한 단계 더 나아갈 수도 있습니다.
데이터 계보에 적용하세요.전체 데이터 처리 파이프라인의 총 비용을 결정할 수 있으므로 어떤 비용이 필요한지 결정할 수 있습니다.
최적화된 항목과 중복되는 항목옵저버빌리티 메트릭을 결합하면 종합적인 결과를 얻을 수 있습니다.
데이터 흐름을 파악하고 다음을 수행할 수 있습니다.
데이터에 대한 데이터 기반 결정.음, 이 모든 지표와
제가 보여드린 성능은 플랫폼 엔지니어들만 사용하고 조정하는 방법을 안다면 아무 소용이 없습니다.그리고 보여드린 것만 보여드렸어요.
몇 가지 옵션이 있습니다.우리는 격려하고 최선을 다합니다.
데이터 엔지니어는 자신에 대한 완전한 자율성과 통제권을 갖습니다.
애플리케이션 및 플랫폼.물론 우리는 최고를 제공합니다.
기본값 및 정책을 실천하지만 전체적으로 변경될 수 있습니다.
필요에 따라 다릅니다.모든 것이 완료되고 있습니다
저희 소스 코드를 통해서요리포지토리의 동작을 정의하는 상세한 Git 구조를 만들었습니다.배포 유닛 (두 가지 용도 모두)
인프라 애플리케이션 및 서드파티 통합그리고 환경,
개발, 스테이징, 프로덕션을 구분합니다.각각 고유한 Git 또는 플로우가 있습니다.이 접근 방식을 통해 다음을 수행할 수 있습니다.
단일 인터페이스에서 Kubernetes 및 애플리케이션 구성 요소의 인프라를 관리할 수 있습니다.
자동화된 워크플로우 및 검증을 가능하게 합니다.
실행 및 배포.구성 변동으로부터 우리를 보호하고, 현재 상태를 유지하고, 가동할 수 있게 해줍니다.
몇 분 안에 애플리케이션과 인프라를 수정할 수 있습니다.마지막으로, 이를 통해 플랫폼 엔지니어의 종속성을 없앨 수 있습니다.속도가 빨라지고
데이터 엔지니어의 자율성을 높이고 양쪽 모두의 지식에 기여합니다.그래서 처음에 저는 한 가지 결정을 내렸습니다.
데이터 조직을 바꾸세요.아시다시피, 이 결정은
Spark 워크로드를 EC2에서 EKS로 옮기고 있었습니다.이제 그 가치를 보여드리겠습니다.이건 저의 젊은 버전이에요.기존 EC2와 비교하면
인텔 바이 스파크 클러스터에서 EKS, 카펜터, 그래비톤을 사용하여 비용을 60% 절감했습니다.SLA를 35% 개선하고 대폭 강화했습니다.
우리의 옵저버빌리티.그리고 위에 있는 체리는
플랫폼 엔지니어의 운영 오버헤드를 줄이고 전체 인력을 향상시켰습니다.
그 과정에서 행복이 가득했습니다.고마워요.(관중들의 박수) - 좋아요.정말 멋진 프레젠테이션이에요. 둘 다 고마워요.뭐 가져갈 게 있다면, 그렇죠?EKS를 최적화하고 모니터링하세요
분석 및 모범 사례.도구 및 관행을 다음과 같이 조정합니다.
조직 성장을 촉진하세요.그래서 우리는 다음과 같은 계층들을 보았습니다.
크리스티나가 이야기했잖아요. 빅터처럼 행복할 수 있으니까요.그리고 API를 제공하세요.개발자, 데이터 엔지니어, 데이터 과학자는 여러분이라는 점을 기억하세요.
플랫폼 고객.고객이 구축할 수 없다면, 여러분이
API를 제공할 수 없어요. 당신이 할 수 있는 건
사용 중인 플랫폼.따라서 API를 사용하여 데이터 엔지니어가 독립적으로 작업할 수 있도록 하세요.제어를 위한 자동화 기능을 계속 제공하면서 자율성을 유지하세요.우리 모두 행복한 노조를 이루고 있어요.정말 고마워요.가입해 주셔서 감사합니다.세션을 잊지 마세요
EKS에 있는 데이터와 같은 리소스를 클릭하면 QR 코드를 스캔할 수 있습니다.모두 참석해 주셔서 감사합니다. 남은 컨퍼런스를 즐겁게 보내세요.(관중들의 박수 갈채)