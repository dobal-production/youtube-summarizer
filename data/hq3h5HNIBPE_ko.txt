- 오늘, 의 일환으로
SaaS 407 세션에서는 다양한 멀티테넌트 세대 AI 아키텍처를 구축하는 방법을 안내해 드리겠습니다.주로 다양한 문제를 해결할 수 있는 방법을 안내해 드리겠습니다.
SaaS 아키텍처 문제를 통해 강력한 차세대 AI 멀티테넌트 아키텍처를 얻을 수 있습니다.이 세션은 400레벨 세션입니다.코드를 좀 더 자세히 살펴보도록 하겠습니다.주로 다양한 문제를 해결하는 것에 대해 이야기할 때
아키텍처 관련 문제가 발생하면 코드 일부를 가져와서 해결 방법을 안내해 드리겠습니다.
특정 과제에 대해 설명해 주시면 어떻게 해결될 수 있을지 설명해 주세요.
강력한 세대 AI 아키텍처.그리고 마지막에는
세션에서는 대부분의 코드를 포함하는 GitHub 보고서 링크를 제공할 것입니다. 이 링크에는 대부분의 코드가 포함되어 있고 우리가 만든 워크숍의 repo 링크도 제공됩니다.
우리가 만든 새로운 워크샵으로, 다음과 같은 개념의 대부분을 다루고 있습니다.
오늘 얘기해볼게요.그렇긴 해도, 저, 우즈왈 부카, 저는 선임 해결사입니다.
아키텍트는 AWS 팩토리 팀 출신입니다.우리 팀은 주로 이러한 SaaS 여정을 통해 다양한 ISV와 기업을 지원합니다.당사는 비즈니스 및 기술 지침을 제공하므로 이를 위해 노력하고 있습니다.
SaaS 여정을 가속화하세요.제 동료도 저와 함께 있어요. - 안녕하세요 여러분.제 이름은 메란 나자피예요.저는 수석 솔루션 아키텍트입니다.
캐나다 토론토에 거주하고 있습니다.이곳에 오게 되어 정말 행복합니다
re:Invent의 첫 날 그리고 Gen에 대해 이야기하기
AI와 멀티테넌시.아시다시피 LLM이 내장된 솔루션을 구축하는 것은 한 명의 고객에게 서비스를 제공하는 것조차 복잡할 수 있습니다.우리는 LLM을 다루고 있습니다.둘 중 하나에 호스팅해야 할 수도 있습니다.
비용이 많이 들거나 일부 SaaS를 사용하고 있는 하드웨어 액셀러레이터
토큰당 솔루션 지불 방식도 복잡하고 비용이 많이 들 수 있습니다.세부 조정이 필요할 수도 있습니다.
고객에게 서비스를 제공하기 위한 모델.그런 다음 호스팅해야 합니다.고객 데이터를 다루고 있습니다.고객 데이터는 다음과 같을 수 있습니다.
민감하고 기밀이 보장되며 사용 중인 경우
어떤 에이전트 워크플로우를 다루고 계시나요?
복잡한 에이전트이기도 하죠.그래서 그 요원은
API와 다른 데이터베이스 또는 타사에 액세스할 수 있어야 합니다.따라서 단일 서비스를 제공하는 경우에도 마찬가지입니다.
고객은 복잡할 수 있습니다.이제 스케일링에 대해 생각해 봅시다.
수천 명의 테넌트, 수천 명의 고객으로 말이죠.그래서 우리에겐 훨씬 더 많은 과제와 더 많은 문제가 있습니다.
여러 LLM을 다루고 있는데 괜찮았을 수도 있습니다.
각 도메인 또는 각 유형의 사용자에게 서비스를 제공하도록 조정되었습니다.이제 다음 사항을 다루고 있습니다.
많은 고객 데이터.고객 한 명이 실수로 또는 의도적으로 데이터에 액세스하는 일이 없도록 해야 합니다.
또 다른 고객 데이터.일부 사용 사례의 경우 비용이 기하급수적으로 높아질 수 있습니다.따라서 일부 사용 사례는 그대로입니다.
경제적으로 불가능합니다.아니면 요원들도요이제 우리가 다루고 있는 것은
요원들이 아주 많죠, 그렇죠?그래서 많은 아키텍처가 있습니다.
이번 Ujwal과의 강연에서 우리가 살펴볼 문제점들은
아시다시피, 그 중 많은 것들을 보세요.그리고 AWS가 어떻게 활용하는지 보세요.
관리형 솔루션이 도움이 될 수 있습니다.규모를 확장하는 데 도움을 줄 수 있습니다.
정말 집중할 수 있는 멀티테넌트 LLM 기반 솔루션
솔루션에 더 특화된 영역, 그리고 떠나는 영역
이러한 복잡한 부분은 AWS에 있습니다.먼저 두 가지를 살펴보겠습니다.
인기 있는 세대 AI 아키텍처.언제 원하는지 알 수 있죠.
LLM 기반 솔루션을 구축하세요. 아시다시피
매우 널리 사용되는 사용 사례 또는 매우 인기 있는 아키텍처는 RAG를 통해 구축하는 것입니다.다음으로 말씀드릴 것은 미세 조정에 관한 것입니다.하지만 RAG의 경우 일반적인 LLM을 활용한다는 아이디어가 떠오릅니다.자세한 내용은 다루지 않습니다.
커스터마이징과 미세 조정.우리는 많은 데이터를 기반으로 이미 훈련된 LLM을 사용합니다.우리는 이를 그대로 사용합니다.고객 요청에 더 구체적으로 적용할 수 있는 방법
RAG를 통해 가능합니다.검색을 위한 RAG 스탠드
증강 제너레이션.여기에 우리가 내장한 고객 데이터가 있습니다.우리는 일부 벡터 데이터베이스를 사용합니다.
우리는 그것들을 임베드하고 벡터화합니다.그 지식은 저장될 것입니다.
그 벡터 스토어 안에그런 다음 해당 사용자가 요청하면
사용자가 벡터 저장소로 이동해 달라고 요청하면, 우리는
해당 데이터베이스의 유사성 검색 기능을 사용하여 이러한 지식을 검색하십시오.
해당 사용자 프롬프트 또는 사용자 쿼리와 관련이 있습니다.그런 다음 이를 LLM에 제공합니다.모두들 확실해요
아마존 베드록에 대해 들었어요.아마존 베드록은 마치
AWS를 통해 다양한 LLM 옵션에 연결할 수 있습니다.베드록이 그 요청을 보내주세요.
이러한 관련 지식을 바탕으로 베드락 뒤의 LLM에 전달해 주세요.아마존 제품일 수도 있습니다. 아마존 타이탄처럼 말이죠.
우리의 파트너인 트로픽 클라우드 메타, 라마 3, 코히어 등.그러면 응답이 생성되어 사용자에게 다시 전달됩니다.이것이 우리의 RAG입니다.그럼 다른 패턴은
미세 조정을 사용하고 있습니다.자, 우리의 목적은
이러한 상황이나 관련 지식을 보내지 마세요.
그럴 때마다 프롬프트가 길어질 수 있습니다.이렇게 하는 대신 우리의 훈련 데이터를 사용합니다.
사용자가 모델을 미세 조정합니다.그럼 트레이닝 작업을 진행해 보세요.
정교하게 튜닝하고, LLM을 커스터마이징해서 이러한 지식을 우리 모델에 이미 포함시키세요.따라서 미세 조정된 모델을 가지고 있을 때, 사용자 요청이 오면
그러면 그 배경과 지식에 대해 이미 알고 있는 거죠.그러면 응답이 생성될 것입니다.
그리고 해당 사용자에게 전송됩니다.여기에 몇 가지 요점이 있습니다.우선, 많은 용도로 사용됩니다.
경우에 RAG를 사용하거나 미세 조정을 사용할 수 있습니다.각각의 장단점이 있습니다.RAG의 경우 미세 조정할 필요가 없고 사용할 수 있기 때문에 LLM에서 훨씬 더 간단합니다.
일반적인 공유 버전이죠.미세 조정에 대해서는, 아니요, 미세 조정 과정을 거쳐야 하는데
LLM이 있으면 그건 커스터마이징이 되고 미세 조정이 되는 거죠.
우리 고유의 사용 사례를 위해서요.즉, 호스팅해야 한다는 뜻입니다.액셀러레이터, 즉 배후에 있는 하드웨어에 비용을 지불해야 합니다.하지만 비용을 절감하고 있습니다.
프롬프트의 길이.포함시킬 필요는 없습니다.
사용자가 프롬프트를 표시할 때마다 이러한 컨텍스트
LLM으로 전송됩니다.하지만 앞으로 보게 되겠지만, 어떤 경우에는 이 두 가지를 조합해서 사용합니다.우리는 RAG 아키텍처를 가지고 있습니다.
일반 LLM을 사용하는 대신 우리는
미세 조정 모델 사용.아시다시피, 저희는 미적 요소를 사용합니다.
데이터를 사용하여 모델을 미세 조정하고 그 역학을 조정할 수 있습니다.
모델을 1분, 매일 밤, 매주 미세 조정하고 싶지 않은 부분이죠.그래서 우리는 이 부분을 걸레로 사용합니다.그럼 곧 살펴보도록 하겠습니다.앞서 말씀드린 것처럼 두 번째 요점과 그 목적은
이 세션은 관리형 서비스를 갖춘 AWS가 구축이 가능한 이러한 복잡성 중 상당부분을 추상화하는 데 어떻게 도움이 되는지 알아보는 데 도움이 됩니다.
멀티테넌트 솔루션이 더 쉬워졌습니다.RAG 측면에서 보면 아마존은
베드록에는 기본적으로 관리형 RAG와 비슷한 아마존 베드락 지식 베이스라는 기능이 있습니다.연결하는 데 도움이 됩니다.
Bedrock 지식 베이스를 S3와 같은 데이터 스토어에 연결하면 거기에 사용자 데이터가 있습니다.그런 다음 OpenSearch와 같은 벡터 저장소에 연결하면 됩니다.
이번 강연의 경우 서버리스를 사용할 수도 있고 다른 옵션일 수도 있고 다음과 같이 구성할 수 있습니다.
LLM, 어떤 LLM을 사용할까요?그러면 Amazon BedRock 지식 베이스가 모든 것을 대신 처리해 줍니다.데이터를 내장하고 있습니다.
벡터 저장소에 저장하면 검색을 수행하고 이를 베드록으로 보냅니다.제가 여기에 무엇을 넣었든, Amazon Bedrock 지식 베이스로 추상화될 수 있습니다.반면 미세 조정을 위해 Amazon Bedrock에는 다음과 같은 기능이 있습니다.
Bedrock이 데이터가 저장되는 위치를 가리키고 어떤 기능을 정의하기만 하면 되는 맞춤형 모델 기능
사용자 지정하려는 LLM을 선택한 다음 사용자 지정 작업을 실행하십시오.따라서 실제로 얻을 수 있는 혜택은 다음과 같습니다.
바로 사용할 수 있는 것처럼 다음 사항에 집중할 수 있습니다.
이제 어떻게 멀티테넌시에 넣을 수 있을까요?자, 이제 한 가지만 살펴보죠.
한 명의 사용자에 대해 설정한 값을 조정하고 그 사용자가 어디에 있는지 확인하세요.
멀티테넌시 측면이 떠오릅니다.이제 하나만 있는 것은 아닙니다.
사용자, 테넌트 수가 많아요.여기 두 개가 보이는데
수천 개가 될 수도 있어요.테넌트가 두 개인 경우 각 테넌트에 자체 데이터 저장소가 있다고 가정해 보겠습니다.벡터 저장소에 저장해야 합니다.여기서 가장 먼저 해야 할 과제는
벡터 저장소가 얼마나 많은지요.벡터화나 테넌트에 하나의 벡터 저장소를 사용하시겠습니까?아니면 격리된 하나를 갖고 싶은데 그 중 여러 개를 갖고 싶은가요?어떤 식으로든, 우리는 다음을 만들어야 합니다.
각 테넌트 지식이 다른 테넌트 지식과 섞이지 않도록 격리되었는지 확인하십시오.다음으로 이 정보를 다음과 같이 입력해야 합니다.
SaaS 솔루션 프레임워크.따라서 SaaS는 단지 여러분만을 위한 것이 아닙니다.
한 명의 고객에게 서비스를 제공하는 거죠.우리에게는 여러 가지 과제가 있습니다.
각 테넌트에는 특정 전용 리소스와 테넌트 관리 기능이 있을 수 있으므로 해당 테넌트에 리소스를 프로비저닝하기 위해 테넌트를 온보딩하는 데 사용됩니다.요금 청구, 모니터링 등 무엇이든 제어할 수 있습니다.그래서 여기서도 해야 할 것이 있습니다.
LLM을 지원하는 SaaS 솔루션을 살펴보세요.그리고 사용자가 해당 SaaS 솔루션을 통해 프롬프트를 보내면
멀티 테넌트가 있는 벡터 스토어로 이동합니다.
여기에 포함된 지식과 테넌트 컨텍스트와 함께 관련 지식이 추출되어 베드록으로 전송됩니다.LLM은 기본적으로 베드록의 기반입니다.이건 RAG입니다.모델을 미세 조정할 필요도 없고 모델을 사용자 지정할 필요도 없습니다.따라서 동일한 일반 공유 LLM을 사용하여 테넌트에 서비스를 제공할 수 있습니다.이것은 RAG에 있었습니다. 멀티테넌시가 있는 것을 보면 알 수 있겠죠.미세 조정을 위해 말씀드리자면, 이제 사용자는 한 명도 없습니다.
테넌트가 많이 있습니다.각 테넌트에는 자체 데이터 저장소가 있습니다.Bedrock 사용자 지정 기능을 사용하여 미세 조정 모델을 만듭니다.
각 테넌트에 대해Bedrock을 사용하여 각 테넌트를 프로비저닝 처리량 모델로 호스팅할 수 있습니다. 이를 통해 다른 테넌트나 다른 사용자는 호스팅하지 않을 수 있습니다.
해당 테넌트에 대한 액세스 권한이 있어야 합니다.따라서 해당 LLM은 전담입니다.
우리 임차인 개개인에게이제 해당 SaaS를 통해 테넌트 요청이 들어오면
해결책은 특정 테넌트와 관련된 미세 조정 모델로 전송됩니다.아시다시피, 이건 정말
RAG와 미세 조정이 어떻게 되는지에 대한 높은 수준의 설명
멀티 테넌시 컨텍스트에서 본 것처럼 보입니다.이제 좀 더 깊이 들어가보도록 하겠습니다.
각 SaaS, 멀티테넌시 문제를 살펴보고 이러한 문제를 어떻게 해결할 수 있는지 살펴보겠습니다.우리가 살펴볼 때
SaaS에는 여러 가지 격리 패턴이 있다는 것을 잘 알고 계실 것입니다.그 중 하나가 우리가 활용하고 있는 풀이라고 합니다.
공유 리소스.따라서 동일한 서비스를 사용하되 여러 테넌트에 사용하려고 합니다.다른 한편으로는 각 테넌트에게 리소스를 전용으로 할당하는 사일로가 있습니다.이제 이 강연에서는 이 두 가지 극단적인 부분을 살펴보도록 하겠습니다. 하지만 여러분의 사용 사례를 말씀드리자면
여러분만의 애플리케이션을 보시면 아시겠지만,
아시다시피 중간에 있는 무언가, 공유 서비스를 갖는 것이 합리적이고 어떤 것이 합리적인지
전용 서비스를 이용하세요.첫 번째 질문은
아마도 모든 SaaS 공급자가 다음과 같이 대답할 것입니다.
사용자 경험을 향상하고 싶으신가요?AI 세대를 위한 추가 정보
특히 새로워요, 그렇죠?고객이 너무 많아요.
서비스를 받기 전에 먼저 서비스를 체험해보고 싶으신가요?
더 비싸고 더 많은 돈을 받는 경험을 좋아하죠.다양한 유형의 사용자를 지원하는 계층화 전략을 마련하는 것이 좋습니다.여기서 중요한 것은
기본 등급의 경우 가장 경제적인 등급입니다.
실현 가능한 아키텍처는 원하지 않기 때문입니다.
돈을 잃는 것보다 비싸게 만드는 거죠.그러니 정말 갖고 싶으실 겁니다.
최대한 저렴하게.그럼 우리는 다음과 같은 것을 더 사용하고 있습니다.
풀, 공유 서비스.최대한 많이 사용하고 싶습니다.
가능한 한 공유 서비스를 제공하지만 동시에
아시다시피 테넌트 격리, 확장, 이런 모든 측면도 필요하죠.기본 등급의 경우, 저처럼
앞서 말씀드렸듯이 여기서의 목표는 가능한 한 많은 공유 서비스를 사용하는 것이며 여기서는 RAG를 사용하고 있습니다.RAG를 사용하는 이유는 무엇일까요?LLM을 사용하고 싶기 때문입니다.
아마도 솔루션에서 가장 복잡하고 비용이 많이 드는 부분일 것입니다.우리는 가고 싶지 않아요.
한 테넌트에 대해 미세 조정하면 다른 테넌트는 사용할 수 없기 때문에 미세 조정을 진행합니다.그런 다음 호스팅해야 합니다.시간당 요금을 지불해야 합니다.토큰당 결제할 수 없습니다.
대부분의 경우.프리미엄 등급을 살펴보면 다음과 같은 내용이 더 많습니다.
RAG와 미세 조정 기능.하지만 여기서는 기본 티어의 경우 RAG를 사용합니다.먼저 데이터를 저장하거나 테넌트하는 데 필요한 스토리지가 있습니다.우리는 하나라도 활용하고 있습니다. 이는 극단적인 경우라는 점을 기억하세요.그래서 우리는 버킷 하나를 사용하고 있지만 그 버킷 안에는
우리는 각 테넌트에게 접두사를 전용으로 할당합니다.그런 다음 테넌트를 사용하고 있습니다.
아마존 베드락 지식 베이스.아마존 베드락 지식 베이스
그 추상화 계층인가요?그 자체로 말하자면
비용은 전혀 들지 않아요.리소스와 그 리소스가 사용하는 서비스에서 발생하는 비용이죠.지식 기반에서는
스토리지에 연결되었습니다.이것이 저희 S3입니다.그런 다음 데이터가 주입되고 지식 기반이 만들어집니다.
Bedrock을 사용하여 해당 데이터를 임베드하고 벡터화한 다음 벡터 스토어에 저장하세요.벡터 스토어의 경우 다음을 사용하고 있습니다.
Amazon OpenSearch 서버리스를 사용하면 동일한 컬렉션을 사용할 수 있지만 테넌트에만 한정됩니다.
해당 컬렉션 내부의 인덱스.따라서 인덱스를 여러 개 가질 수 있습니다.각 인덱스는 하나를 나타냅니다.
우리 컬렉션의 테넌트그럴 필요는 없어요.
테넌트마다 컬렉션이 다릅니다.이제 테넌트와 다른 테넌트가 이러한 기본 사항을 각각 살펴보면
티어 테넌트 요청이 오면 API 게이트웨이를 거쳐야 합니다.
다시 공유될 거예요.그럼 풀 컴퓨팅이 필요하죠.이것은 람다 함수일 수 있습니다.
이것은 EC2, EKS, ECS 등과 같을 수 있습니다.
LLM을 호출하는 로직.이것은 RAG입니다. 첫 번째 단계는 지식을 검색하는 것입니다.
테넌트에게 하나의 지식 베이스로 이동하라는 프롬프트와 관련이 있습니다. 지식 베이스는 거쳐야 합니다.
OpenSearch 서버리스에서 관련 지식을 찾으면 해당 요청은
해당 공유 베드록으로 전송되었습니다.그래서 저희는 기본적으로 토큰당 비용을 지불하고 있습니다.이것이 에이전트 워크플로우라면 그렇지 않다는 뜻입니다.
질문에 대한 답변에 대해서요.해야 할 일이 몇 가지 있어요.API를 호출하고 데이터베이스에서 데이터를 검색해야 합니다.공유 에이전트를 사용하고 있습니다.따라서 베드락 에이전트도 가능합니다.
일부 컨텍스트를 통해 멀티 테넌시를 지원합니다.
어떤 API 게이트웨이, 어떤 API, 어떤 작업 그룹을 호출할지, 어떤 데이터베이스를 사용할지 결정하세요.여기서는 에이전트가 한 명뿐이고 테넌트당 각 지식 기반이 여러 개 있기 때문입니다.나중에 프리미엄에서 살펴보겠지만.따라서 프리미엄에서는
상담원과 지식 기반 간에는 일대일 관계가 있습니다.하지만 여기서 상담원에게는 다음이 필요합니다.
컨텍스트를 살펴보려면 어떤 테넌트 ID를 결정했는지 결정한 다음 해당 세부 ID로 이동하세요.
해당 테넌트에 대한 기술 자료테넌트 2와 매우 유사하게, S3에 자체 지식 베이스로 연결되는 전용 접두사가 있습니다.전용 인덱스가 있습니다.
OpenSearch 서버리스 내에서 테넌트 투 요청이 오면 베드록으로, 테넌트까지 가서 지식을 얻게 됩니다.
해당 테넌트에 서비스를 제공하기 위한 기반.이제 프리미엄 등급을 살펴보겠습니다.프리미엄 등급은 등급입니다.
이미 지불하고 있다는 것.그래서 저희가 제공하고자 하는 것은
최고의 사용자 경험, 가장 낮은 지연 시간,
이들에게는 가장 고립된 느낌이었죠.그리고 우리는 사일로 패턴을 보고 있습니다.아시다시피 각 서비스에 대한 전용 서비스를 제공합니다.
저희 패턴에는 RAG와 미세 조정을 사용하고 있습니다.먼저 데이터 또는 학습 데이터를 사용하여 모델을 미세 조정합니다.
Amazon Bedrock 사용자 지정 모델.이 테넌트를 위한 미세 조정 모델이 있습니다.이제 솔루션의 RAG 부분에 대해 다시 한 번 말씀드리지만, 다음과 같이 데이터를 입력해 보겠습니다.
지식 베이스에 저장해 두세요.아마 이게 더 많을 거예요
동적인 특성을 지닌 데이터.저희는 전용 오픈서치를 운영하고 있습니다.
각 테넌트와 우리를 위한 서버리스 컬렉션
그 안에 인덱스가 있습니다.따라서 요청이 오면 전용 이벤트 API 게이트웨이가 생깁니다.전용 컴퓨팅이 있습니다.
전용 람다, 전용 EC2처럼 말이죠.우리 같은 회사가 있는 것으로 알고 있습니다.
이에 대한 워크숍을 진행했는데 작업 코드가 몇 개 있습니다.
Git 리포지토리이므로 사용할 수 있습니다.전용 지식 베이스로 이동합니다.검색 요청
op의 데이터.공유 리소스에서 전용 리소스에 이르기까지 이러한 리소스와 프리미엄을 모두 지원합니다.그리고 에이전틱 워크플로우라면
이 프리미엄 등급의 전담 상담원이 전담 작업을 담당합니다.
API 및 데이터베이스를 포함하는 그룹 또는 다음과 같은 제3자가 있는 그룹
이 에이전트는 작업을 수행합니다.이제 다음 과제는 바로 우리입니다.
SaaS 솔루션을 구축하고 싶습니다.말씀드리자면...컴포넌트, 하나는 컨트롤
플레인, 문제를 해결하는 SaaS 컨트롤 플레인
테넌트 온보딩에서는 테넌트를 원한다는 것을 알 수 있습니다.
정보, 결제 데이터, 티어 유형
가입하고 싶습니다 (기본 또는 프리미엄).또한 테넌트 관리를 살펴보면 수집하려는 항목이 있습니다.
로그를 통해 사용자가 서비스를 어떻게 사용하고 있는지 보여주는 몇 가지 메트릭이 있습니다.솔루션 내부의 테넌트 활동을 기본적으로 모니터링하는 데 도움이 되는 모든 데이터를 사용합니다.테넌트 프로비저닝의 경우
프로비저닝해야 하는 몇 가지 리소스가 있습니다.
해당 테넌트가 온보딩된 경우 (이는 경우에 따라 다릅니다)
기본 및 프리미엄 등급.기본적으로는 다음을 사용하고 있습니다.
대부분 공유 서비스입니다.그 말인즉슨, 예전에도
시스템에 등록된 모든 테넌트가 해당 서비스를 이용할 수 있습니다.여기 풀 S3 전용 버킷이 있는데 이 버킷은 비어 있습니다.오픈서치 풀이 하나 있습니다.
서버리스 컬렉션.다시 말씀드리지만, 색인은 없습니다.에이전트가 이미 설치되어 있습니다.그러다가 새로운 베이직이 나오면
티어 테넌트가 온보딩되면 우리가 해야 할 일은 다음을 생성하는 것입니다.
해당 테넌트의 접두사생성해야 합니다.
OpenSearch 내부 또는 OpenSearch에서 색인을 생성한 다음 지식 베이스를 생성합니다.대부분의 내용을 알고 있기 때문에 더 빠를 수 있습니다.
해당 서비스에 있는 사람들은 이미 존재합니다.반면에 프리미엄 등급의 경우 비어있는 것으로 시작하죠?거긴 아무것도 없어요.테넌트 프리미엄 테넌트가 온보딩되면 전용 테넌트가 생성됩니다.
S3, 전용 미세 조정 모델.당사는 전용 지식 베이스와 전용 OpenSearch를 보유하고 있습니다.
서버리스 컬렉션.다음으로 살펴봐야 할 과제는
그게 바로 데이터 파티셔닝입니다.따라서 데이터 파티셔닝은
SaaS에서는 매우 중요하기 때문에 매우 중요합니다.우리는 많은 테넌트 데이터와 많은 고객 데이터를 다루고 있습니다.우리는 다음과 같은 사항을 시행하고자 합니다.
최대한 격리하세요.따라서 세입자 중 누구도 그래서는 안 됩니다.
다른 테넌트에게 접근할 수 있는 거죠.나중에 설명하기 위해 격리를 시행하는 방법을 살펴보겠습니다.정말, 첫 번째 단계입니다.
분리가 할 수 있는 방식으로 데이터를 논리적이고 물리적으로 분할하는 것입니다.
거기에 효율적으로 적용하세요.우리의 기본 등급인 우리는
공유 서비스를 사용하면 내부 격리가 이루어집니다.
이러한 공유 서비스.S3의 경우 각 테넌트에 전용 접두사가 있습니다.
OpenSearch의 경우 벡터 복원을 위한 서버리스는 전용 인덱스입니다.여기서 다행인 것은 지식 기반이 추상화되어 있어서 굳이 넣을 필요가 없다는 것입니다.
그건, 아시다시피, 풀에 넣는 거죠.그러니까 이미 저희 테넌트에게 배정된 거죠.따라서 모든 테넌트에는 고유한 테넌트가 있습니다.
전용 지식 베이스.프리미엄의 경우 전용 서비스가 제공되므로 훨씬 더 간단합니다.
리소스, 전용 버킷, 전용 오픈서치 서버리스
클러스터도 마찬가지입니다.지식 베이스는 전용입니다.
이 유형의 테넌트에게그럼 이제 제 전화가 올게요
고립에 대해 얘기해 주세요. - 고마워요, 메란.그럼 다음으로 이야기할 주제는
테넌트 격리입니다.테넌트 격리는 특정 테넌트가 테넌트 특정 리소스에만 액세스할 수 있도록 해야 한다는 의미입니다.여기서 할 일은 다음과 같습니다.
여기서 선택할 것은 기본 등급이고 프리미엄 등급은
아키텍처 영역을 강조해 보세요.
구현이 필요하죠.그런 다음 우리가 어떻게 하는지 자세히 알아보고 이야기해 보겠습니다.
구현할 수 있습니다.따라서 기본 계층부터 시작하세요.이미 보셨을 겁니다.
기본 계층 아키텍처, 해당 영역
테넌트를 구현하는 데 필요한 아키텍처
격리는 지식 기반입니다.그래서 우리는 지식을 창조하고 있습니다.
각 테넌트에 대한 기반을 마련한 다음 다음을 수행해야 합니다.
확실히 이 지식 베이스는 데이터만 가져오는 것인가요?
테넌트별 접두사가 붙고 공유 풀 컬렉션의 테넌트별 인덱스에서 데이터를 푸시하고 가져옵니다.다음으로 풀 컴퓨팅이 진행됩니다.이 풀 컴퓨팅은 공유됩니다.
여러 테넌트에서 이 컴퓨팅의 서비스가 여러 테넌트 간에 공유되므로
실행 역할을 직접 연결할 수는 없었습니다.모든 항목에 액세스할 수 있는 더 넓은 범위를 제공합니다.
테넌트 리소스.대신 해야 할 일은 기본적으로 리소스를 강화하는 것입니다.
다음과 같은 방식으로 서비스를 생성합니다.
런타임의 범위 자격 증명은 다음과 같습니다.
이 특정 테넌트는 해당 범위 자격 증명을 사용하여 테넌트별 리소스에 액세스합니다.잠시 후 이를 구현하는 방법에 대해 알아보겠습니다.그리고 풀 에이전트.다시 풀 에이전트가
테넌트 리소스와 함께따라서 여러 테넌트 간에 공유됩니다.따라서 다음 사항을 확인해야 합니다.
이 풀 에이전트는 다음과 같은 방식으로 강화됩니다.
런타임에 생성되는 특정 범위 자격 증명을 사용합니다.
해당 특정 테넌트의 다음 해당 범위를 사용합니다.
테넌트별 리소스와 상호 작용하기 위한 자격 증명다시 한 번 말씀드리지만, 잠깐
둘째, 이를 위한 테넌트 솔루션을 구현하는 방법을 이해하겠습니다.여기서 다른 각도는
여기서 또 다른 부분은 우리가 이 지식을 확실히 알아야 한다는 것입니다.
base는 데이터를 푸시하고 가져올 수만 있습니다.
테넌트별 인덱스.이를 수행하는 방법은 OpenSearch 서버리스 컬렉션에 정의된 데이터 액세스 정책을 활용하는 것입니다.이것을 좀 더 다음과 같이 생각해 보십시오.
오픈 서버리스 컬렉션.그 정책을 보세요, 뭐라고요?
보시면 아시겠지만 원칙이 하나 있습니다.그 원칙은 기본적으로 지식창고의 서비스 역할에 지나지 않습니다. 보시면
이를 통해 여러분은 이 지식을 알고 있다는 것을 알 수 있었습니다.
베이스는 오직 데이터를 푸시하고 가져올 수 있는 권한만 있습니다.
테넌트별 인덱스.이렇게 하면 테넌트별 인덱스를 확인할 수 있고 다음과 같이 할 수 있습니다.
지식베이스에 테넌트 격리를 적용하십시오.풀 컴퓨팅으로 넘어가자면
앞서 말씀드렸듯이, 다음 사항을 확인해야 합니다.
풀 컴퓨팅은 실시간으로 스코프를 생성합니다.
특정 테넌트와 관련된 자격 증명 및
해당 범위 자격 증명을 사용하여 테넌트와 상호 작용하십시오.
특정 리소스.알고, 방법을 이해해 봅시다.
그걸 구현할 수 있겠죠.예를 하나 들어볼게요.API 게이트웨이와의 상호작용.토큰.플레이스홀더 배치.백롤에서 정의하는 방법은 다음과 같습니다.이제 람다 권한 부여자가 하는 일은 내구성 토큰에서
테넌트 ID를 가져오고 컨트롤 플레인에 도달하여 지식 기반 ID를 가져옵니다.
특정 테넌트의온보딩할 때
테넌트, 관찰 여부가 확실하지 않을 때는 테넌트 관리 서비스라는 서비스가 있는데, 캡처와 비슷합니다.
테넌트별 메타데이터 또는 메타데이터는
온보딩 중에 생성됩니다.따라서 테넌트를 온보딩할 때 해당 특정 테넌트의 지식 기반 ID가 캡처되었습니다.이 경우, 아시다시피 테넌트 1입니다.자, 이제 다시 말씀드리죠.
람다 권한 부여자, 람다 권한 부여자
JW 토큰은 테넌트 ID를 가져오고 컨트롤 플레인으로 이동합니다.
지식 기반 ID를 가져온 다음 지식을 가져옵니다.
기본 ID, 이것은 백롤이며 서비스와 상호 작용합니다.
보안 토큰 서비스라고 합니다.기본적으로 API를 호출하여 이 두 가지를 파라미터로 전송하고 범위를 다시 가져오거나
특정 테넌트에만 적용되는 자격 증명
테넌트별 리소스에만 액세스할 수 있습니다.그리고 이러한 자격 증명은 백엔드 서비스로 전달되고 서비스는 해당 범위 자격 증명을 사용하여 백엔드 서비스와 상호 작용합니다.
테넌트별 리소스.이제 두 번 클릭해 보겠습니다.
람다 권한 부여 코드와 서비스 코드를 살펴보고 이에 대해 좀 더 자세히 살펴보겠습니다.따라서 보시면
람다 권한 부여자 코드, 람다 권한 부여자가 가장 먼저 하는 일은 내구성 토큰을 검증하는 것입니다.내구성 토큰에서
테넌트 ID를 가져온 다음 테넌트를 가져옵니다.
ID, 컨트롤 플레인에 API를 호출하여 다음을 수행합니다.
컨트롤 플레인에서 지식 기반 ID를 가져옵니다.그리고 해당 정보를 가져오면 assume role 메서드를 호출합니다.해당 assume role 메서드 내에서 특정 메서드의 정의를 보면
정의, 가장 먼저 하는 일은 기본적으로
API 호출을 하거나 보안 토큰을 호출하고 있습니다.
맡으려는 역할과 해당 역할에서 대체하려는 추가 파라미터를 전달하는 서비스입니다.이 경우에는 지식창고 ID입니다.일단 그렇게 하면 응답이
그 메서드를 호출했을 때 얻을 수 있는 것은
스코프 자격 증명.이 응답에서 특정 테넌트에만 해당하는 범위 자격 증명을 구문 분석하여 해당 테넌트에 대한 액세스 권한만 부여할 수 있습니다.
테넌트별 리소스.이제 다시 돌아오겠습니다.
람다 권한 부여자, 거기서 응답을 패키징해야 합니다. 알다시피, 성공적인 응답입니다.
또는 실패 응답, 그러니까 API 게이트웨이는
이 요청을 승인할 수 있습니다.해당 응답의 일부로 이러한 범위 자격 증명을 추가하고 해당 응답을 전달할 수 있습니다.
의 API 게이트웨이 및 API 게이트웨이로 돌아가 보겠습니다.
이 경우 요청을 승인하고 다음을 전달합니다.
백엔드 서비스에 대한 응답.그리고 백엔드 서비스로 넘어가면 백엔드 서비스 코드를 보면 가장 먼저 백엔드가
서비스 코드가 하는 일은 기본적으로 입력에서 이루어집니다.
이벤트 또는 입력 요청은 다음과 같습니다.
다음과 관련된 범위 자격 증명
해당 특정 테넌트.해당 범위 자격 증명을 사용하여 Boto3 클라이언트 (이 경우에는 Bedrock 클라이언트) 를 만들고 있습니다.이 Bedrock 클라이언트는 테넌트별 리소스 (이 경우 지식 기반) 에만 액세스 권한을 부여합니다.그리고 이 베드록을 활용하면
클라이언트, 지식 기반 리트리버라는 구조를 만드세요.기본적으로는 상호 작용할 수 있는 구조일 뿐입니다.
지식 베이스와 함께 말이죠.그리고 언제 보면 알 수 있겠죠.
여러분이 이 구조를 만들고 있는데, 우리는 Bedrock을 사용하고 있습니다.
이전 단계에서 특정 범위 자격 증명을 사용하여 생성한 클라이언트 보드입니다.
이 특정 테넌트.그런 다음 LLM을 호출할 때 이 모든 것을 종합합니다.
입력 프롬프트와 지식 기반 검색기를 전달함으로써 말이죠.여기서 몇 가지 일이 일어납니다.첫 번째는 입력입니다.
테넌트별 정보를 가져오기 위한 프롬프트가 Knowledge Base 검색기로 전송됩니다.
데이터, 입력 프롬프트, 테넌트별
데이터를 취합하고 다음과 상호 작용합니다.
LLM은 Bedrock을 통해 최종 테넌트별 응답을 얻습니다.이제 풀 에이전트로 넘어가겠습니다.다시 말씀드리지만, 여기서도 방금 말씀드린 것과 비슷한 접근법을 사용하겠습니다.
그리고 격리를 구현하세요.그 예를 들어보죠.다시 세입자라고 가정해 봅시다.
하나는 API 게이트웨이에 요청을 보내는 것입니다.
API 게이트웨이에서도 동일한 람다 권한 부여자를 본 적이 있을 것입니다.그리고 그 권한 부여자는 토큰의 유효성을 검사한 다음 이를 확보합니다.
IAM 역할은 지금까지 살펴본 것과 비슷합니다.
JW 토큰에서 다시 람다 권한 부여자가 테넌트 ID를 가져오고 컨트롤 플레인으로 이동합니다.
지식 기반 ID를 가져온 다음 지식 기반 ID와 역할을 다음을 통해 전달합니다.
보안 토큰 서비스를 사용하고 범위 자격 증명을 가져옵니다.그리고 해당 범위 자격 증명도
백엔드 서비스와 이 백엔드 서비스로 넘어갑니다. 이제 에이전트를 호출하면 범위를 통과하게 됩니다.
에이전트에 자격 증명을 보내면 이 에이전트는
해당 범위와 관련된 범위 자격 증명을 사용하십시오.
특정 테넌트는 테넌트별 리소스와 상호 작용합니다.이 경우에는 지식 베이스입니다.다시 말씀드리지만, 저는 그냥 보여드릴 뿐입니다.
테넌트별 리소스로서의 지식 기반 예시는 다음과 같습니다. 이 개념을 DynamoDB 테이블 또는 S3 버킷과 같은 다른 테넌트별 리소스에도 적용할 수 있습니다.기본적으로는 보강하는 방법이 될 수 있습니다.
이 IAM 역할은 해당 S3 버킷 또는 DynamoDB 테이블에 액세스할 수 있습니다.이제 두 번 클릭해 보겠습니다.
이 서비스 코드와 에이전트 코드를 보고 이 모든 것이 어떻게 합쳐지는지 이해해 보세요.따라서 서비스 코드를 보면 가장 먼저 서비스가 필요합니다.
코드는 기본적으로 테넌트별 코드를 가져오는 것입니다.
스코프 자격 증명.일단 테넌트별 정보가 제공되면
범위 자격 증명을 호출하면 다음을 호출합니다.
에이전트를 호출하기 위한 호출에이전트를 호출하면
세션 속성을 통해 범위 자격 증명을 전달합니다.범위 자격 증명과 함께 전달할 수 있는 추가 메타데이터도 전달하고 있다는 것을 알 수 있었습니다.
세션 어트리뷰트.이때 에이전트가 시작되고 에이전트 코드가 시작됩니다.첫 부분을 보시면, 기본적으로 어떤 것에서 나온 거예요?
세션 속성은 범위 자격 증명을 전달하거나 범위를 가져옵니다.
이 특정 테넌트에만 적용되는 자격 증명.또한 필요한 추가 메타데이터도 가져오고 있다는 사실도 확인할 수 있습니다.그리고 일단 얻어지면
범위, 자격 증명 및 스토리, 우리는 Bedrock 클라이언트를 만들고 있습니다.
테넌트별 리소스에만 액세스할 수 있는 범위 자격 증명을 사용합니다.이제 에이전트 코드는 다른 메서드의 호출을 시도합니다.
테넌트에게만 특정 리소스에 대한 액세스 권한을 부여하는 Bedrock 클라이언트를 사용합니다.이제 풀 에이전트를 격리해 보겠습니다.프리미엄 등급으로 넘어가셨을 때 다시 말씀드리지만, 이미 보셨을 겁니다.
프리미엄 티어 아키텍처.필요한 영역
테넌트 격리를 적용하려면 지식 기반이자 풀 사일로화된 컴퓨팅이 필요합니다.여기까지 왔는데, 왜냐하면 우리가
이 특정 분야를 위한 전용 컴퓨팅 만들기
테넌트 여러분, 격리 이야기는 어떤 의미에서는 매우 간단합니다. 전용 컴퓨팅이기 때문에 이 컴퓨팅에 실행 역할을 직접 연결할 수 있습니다.
이를 통해 테넌트 관련 리소스에만 액세스할 수 있습니다.마찬가지로, 다음과 같은 것이 있습니다.
이 특정 테넌트 전용 전담 상담원,
여기에 실행 역할을 추가할 수도 있습니다.
그러면 테넌트별 리소스에 액세스할 수 있습니다.이제 두 번 클릭해 보겠습니다.
이 세 가지 구성 요소에 대해 알아보고 어떻게 할 수 있는지 이해해 보세요.
테넌트 격리를 시행하세요.다시 말씀드리지만, 프리미엄 계층에서 보신 것처럼 지식 베이스의 경우 오픈 서버리스 컬렉션에서 전용 컬렉션을 만들고 있습니다.지식 베이스를 살펴보면, 지식 베이스의 경우
서비스 역할 및 서비스 역할을 첨부합니다.
컬렉션에 액세스한 다음 모델과 상호 작용하기자, 이제 만들고 계신 거예요.
확실히 이 지식창고는 오직 다음과만 상호작용하고 있습니다
전용 S3 버킷.전용 S3이기 때문에
버킷은 마치, 알다시피 버킷에 대한 직접 액세스 권한을 부여하는 것과 같습니다.그리고 다시 말씀드리지만,
OpenSearch 서버리스 컬렉션에서는 데이터 액세스 정책을 사용하는데, 데이터 액세스 정책을 살펴보면 가장 먼저 볼 수 있는 것이
원칙을 정의한 다음 다음을 살펴보면
여러분이 만들고 있는 권한 집합
이 지식창고는 다음과만 상호 작용하는지 확인하십시오.
이 전용 컬렉션, 이 경우에는이렇게 하시면 됩니다.
프리미엄 요금의 경우 테넌트 격리를 시행합니다.
지식베이스의 티어.사일로화된 컴퓨팅의 경우
예를 들어보죠.테넌트 3이 상호작용하고 있습니다
API 게이트웨이와 연동하세요.요청은 전용 서비스가 있는 이 전용 컴퓨팅으로 이동합니다.이 서비스는 전용 서비스이므로 거의 대부분 가능합니다.
실행 역할을 붙이고 실행 역할을 보면 실행 역할은
기본적으로 다음과 같은 특정 권한을 부여합니다.
이 특정 테넌트, 이 경우에는
이 권한을 사용하여 테넌트에 액세스 권한을 부여하면
이 서비스는 지식 기반과 상호 작용합니다.서비스 코드를 보면 알 수 있겠지만,
전용 서비스이기 때문에 거의 직접 할 수 있습니다.
를 통해 지식창고 ID를 여기에 삽입하세요.
환경 변수 또는 환경 변수.그러면
Boto3 클라이언트를 만드세요. 이 클라이언트는 베드락 클라이언트입니다.서비스가 직접 제공되기 때문에
실행에 첨부되었습니다.그리고 이걸 만들면
이 Bedrock 클라이언트는 권한을 얻게 될 것입니다.
그 실행 역할에서 말이죠.그러면 다음을 만들 수 있습니다.
이전 단계에서 만든 이 Bedrock 클라이언트를 사용한 지식 기반 리트리버.그런 다음 이 모든 것을 종합한 다음 LLM을 호출합니다.
입력 프롬프트와 지식 기반 검색기를 우회하는 거죠.사일로 에이전트의 경우 다시 테넌트 3이 API 게이트웨이와 상호 작용한다고 가정해 보겠습니다.
요청은 서비스로 전달되고 서비스는 에이전트를 호출합니다.이 경우에도 에이전트는
상담원 실행 역할을 에 직접 연결하면 됩니다.
에이전트는 테넌트별 리소스에 권한을 부여하며, 이는 에이전트가 테넌트별 리소스와 상호 작용하는 방식입니다.그리고 보시면
이 에이전트 코드의 코드는 아주 간단합니다.기본적으로 여러분은 서비스입니다.
코드는 기본적으로 에이전트를 호출하며 다음과 같은 경우
에이전트 코드를 보면 연결된 실행 역할에서 모든 권한을 가져오고 있습니다.따라서 그냥 실행하고 연결된 실행 역할에서 얻은 권한을 사용하기만 하면 됩니다.여기서 다루게 될 과제는 이러한 아키텍처의 테넌트당 비용을 어떻게 계산하느냐는 것입니다.테넌트당 비용을 계산하려면 먼저 다음을 수행해야 합니다.
몇 가지 사항을 이해하세요.생각해 볼 때
테넌트당 비용을 계산하려면 테넌트 컨텍스트를 사용하여 캡처 지표를 캡처해야 합니다.
특히 테넌트를 측정하려는 아키텍처 영역의 경우
리소스 소비.따라서 기본적으로 지표를 캡처한 다음 다음을 수행해야 합니다.
지표를 집계하세요.지표를 집계할 때 테넌트별로 해당 지표를 집계하고 각 테넌트의 사용량을 구합니다.일단 얻어지면
소비의 백분율을 곱하면
관련 비용을 구하기 위한 서비스의 총 비용.따라서 기본적으로 다음이 필요합니다.
컨텍스트 내에서 지표를 캡처하고 지표를 집계하는 것이죠.따라서 지표를 캡처할 때 일반적으로 제안하는 것은
아키텍처를 살펴보고 AWS 청구서에 가장 큰 영향을 미치는 아키텍처 영역을 선택해 보십시오.이 경우 대부분의 비용은 대규모 언어 모델과의 상호 작용에서 비롯됩니다.따라서 기본 사항을 살펴보면
티어 티어와 프리미엄 티어를 보면 아키텍처의 다양한 구성 요소들이 어떤 종류인지 알 수 있습니다.
LLM과 상호작용하는 것 처럼요.LLM이 번호를 기준으로 요금을 청구한다는 사실을 이미 알고 계실 수도 있습니다.
생성된 토큰, 입력 토큰 및 출력 토큰의 수
대규모 언어 모델과 상호 작용할 때그래서 제가 하려고 하는 것은
여기까지 가려면 기본적으로 캡처해야 합니다.
생성된 입력 토큰과 출력 토큰의 수
아키텍처의 다양한 구성 요소가 대규모 언어 모델과 상호 작용하는 경우여기서는 전체 내용을 살펴보도록 하겠습니다.
기본 등급과 프리미엄 등급을 요약해 보겠습니다.
다음과 상호 작용하는 다양한 구성 요소
대규모 언어 모델.그 중 하나입니다. 바로 컴퓨팅입니다.컴퓨터는 다음과 상호 작용합니다.
대규모 언어 모델은 주로 이 문제를 해결하기 위한 것입니다.
최종 테넌트별 응답잠시만 지나면 캡처 방법을 이해할 수 있을 것입니다.
대규모 언어 모델과 상호 작용할 때의 컴퓨팅 관련 메트릭입니다.그 다음은 지식 기반입니다.지식 기반은 대규모 언어 모델과 다시 상호 작용하여 주로 임베드를 생성합니다.그리고 더 나은 방향으로
둘째, 이러한 지표를 캡처하는 방법을 이해하겠습니다.그리고 상담원.보시다시피 상담원에게 작업을 배정하면 상담원이 상호작용할 수 있습니다.
대형 언어 모델을 사용하여 작업을 수행한 다음 잠시 후 이러한 메트릭을 캡처하는 방법을 이해할 수 있을 것입니다.일단 여러분들이 생각해볼 수 있는 건
이러한 지표를 캡처하면 일종의 가설이 나옵니다.
여기 소비의 일정 비율을 말씀드리자면, 그냥 저는
여기 수치를 드리자면, 전체 소비량의 이 비율을 계산하면
테넌트의 경우, 여기에 서비스 비용을 곱하면 됩니다.
이 경우 테넌트당 비용을 구하기 위한 기본
베드락을 사용하기 위해서요지표 캡처에 대해 이야기할 또 다른 영역은 스토리지입니다.특히 기본 계층에 적합합니다.기본 티어부터 여러 테넌트가 공유하는 컬렉션을 사용하고 있는 것을 보셨을 것입니다.각 테넌트에 대한 인덱스를 생성하세요.방법을 살펴보도록 하겠습니다.
공유 풀 컬렉션을 사용할 때 지표를 캡처할 수 있습니다.그리고 이를 통해 어떻게 소비율을 구할 수 있을까요?일단 이것들을 제거하면
아키텍처 (기본 계층 및 프리미엄 계층) 에서 주로 프리미엄 계층에서 제외된 유일한 구성 요소는 다음과 같습니다.
이러한 전용 리소스.이들은 전용입니다.
특정 테넌트와 관련된 리소스.이 경우에는
전용 리소스이므로 다른 접근 방식을 사용하여 테넌트당 비용을 계산할 수 있습니다.기본적으로 그렇게 할 수 있습니다.
테넌트 ID로 태그를 지정하세요.그런 다음 AWS 결제 및 비용 관리 서비스에서 제공하는 비용 및 사용 보고서를 사용하여 이러한 구성 요소의 비용을 거의 집계할 수 있습니다.
테넌트 ID별 전용 구성 요소, 기본적으로
태그와 테넌트 ID를 기준으로 합니다.그럼 이제 시작해 보겠습니다.
각 구성 요소를 자세히 살펴보고 대규모 언어 모델과 상호 작용하는 시점과 관련하여 메트릭을 어떻게 계산할 수 있는지, 어떻게 측정치를 캡처할 수 있는지 이해해 보세요.먼저, 컴퓨팅부터 시작하겠습니다.여러 개를 가정해 봅시다.
테넌트가 API 게이트웨이와 상호 작용하고 요청은 백엔드 서비스로 이동하며 이 서비스는 다음을 사용합니다.
Bedrock 및 Bedrock과 상호작용하기 위한 일종의 API입니다.
응답을 돌려줍니다.따라서 이 API와 상호작용할 때 사용할 수 있는 API는 다음과 같습니다.
컨버스 API를 사용하는 경우 해당 컨버스 API에서 돌아오는 서비스와 응답 간의 상호작용은
에 대해 생성된 입력 토큰과 출력 토큰의 수를 확인하세요.
그 특정한 상호작용.이제 할 수 있는 게 뭐가 있을까요?
할 수 있는 건, 알다시피, 이 서비스가 사용할 수 있는 것과 같죠.
일종의 도서관이죠.이 경우에는 그냥 보여드릴게요.
메트릭 매니저 라이브러리입니다.이것을 한 부분이라고 생각하시면 됩니다.
기본적으로 테넌트 컨텍스트와 출력 응답을 받은 다음 테넌트로부터 받는 코드입니다.
컨텍스트를 입력하면 테넌트 ID를 가져옵니다.그런 다음 응답에서 입력 개수를 가져옵니다.
토큰과 출력 토큰을 모아 CloudWatch 로그에 게시하려고 합니다.서비스의 코드를 보면 다음과 같습니다.
서비스가 기본적으로 가장 먼저 하는 일은 스코프 자격 증명을 가져오는 것입니다.
Bedrock 클라이언트를 만드세요.그리고 나서 그것은 다음을 생성합니다.
Bedrock 클라이언트가 있는 지식 기반 리트리버,
그런 다음 LLM을 호출하면 다음과 같은 작업을 수행할 수 있습니다.
커머스 API를 사용하여 LLM으로 호출하세요.일단 그렇게 하고 나면
응답을 기반으로 하면 다음과 같이 할 수 있습니다.
메트릭 매니저 라이브러리에서는, 알다시피, 제가 입력을 전달하고 있다는 것을 알 수 있습니다.
파라미터로서의 이벤트.거기서부터 결과를 얻게 되죠.
입력 테넌트 컨텍스트, 즉 테넌트 전체입니다.그리고 저도 통과할 생각입니다.
생성된 입력 토큰과 출력 토큰의 수, 즉 특정 토큰에서 나온 수
사용자가 수행한 응답 또는 사용자가 수행한 호출
이전 단계에서 한 것입니다.그리고 나서 녹음을 하게 되죠.
CloudWatch 로그에 있는 내용은 다음과 같습니다.여기서 10개를 캡처합니다.
입력 토큰의 수와 함께 전체 및
특정 상호 작용에 대해 생성된 출력 토큰.그리고 지식 베이스로 넘어가죠.지식 베이스의 경우, 먼저 방법을 이해하기 전에
지표를 파악하려면 무엇을 이해해야 하는지 알아야 합니다.
지식 기반이 대규모 언어 모델과 상호 작용하는 다양한 영역입니다.먼저, 데이터를 지식 베이스로 축소할 때
베드록과 상호작용하여 임베딩을 생성합니다.그리고 또 다른 사용 사례도
지식 기반과 상호 작용하는 경우 지식 기반은 다음과 상호 작용합니다.
대규모 언어 모델은 기본적으로 특정 언어인 경우
테넌트 요청이 들어옵니다.컴퓨팅이 상호 작용하는 경우
지식 베이스를 통해 테넌트별 정보 파악
데이터, 아시다시피 지식 기반이 대규모 언어와 상호 작용하는 시점입니다.
베드록을 통한 모델.여기서 해결해야 할 과제는
지식 기반과 기반 간의 상호 작용이 바로 가능하다는 것입니다.당신을 위한 방법은 없습니다.
메트릭을 캡처하기 위한 사용자 지정 코드를 삽입하기 위해서요이 챌린지의 한 가지 방법
Bedrock 수준에서 로깅을 활성화할 수 있습니다.로깅을 활성화하면 Bedrock 지식 베이스가 됩니다.(딱딱 거리는 소리)
스피커가 익사합니다.) 로그 메시지는 다음과 같습니다.그리고 그 로그 메시지 안에서
아시다시피 특정 상호작용에 사용된 입력 토큰의 수를 알 수 있었습니다.지식 기반이 다루고 있기 때문에
임베딩 모델의 경우, 아시다시피,
입력 토큰을 다룹니다.인아웃풋 토큰은 없습니다.네가 있어서 다행이야.
입력 토큰의 개수를 알고 있긴 하지만
문제는 테넌트 컨텍스트를 어떻게 연결하는가입니다.이제 해결할 수 있는 한 가지 방법이 있습니다.
이것은 마치 규칙을 정의할 때 일종의 규칙을 적용하는 것과 같습니다.
지식창고에 해당 서비스 역할을 정의하세요
테넌트 엔티티와 함께이 메시지를 보시면
또 다른 특성 (딱딱 소리를 내면 스피커가 익사함) 이 있는데 우리는 이 규칙을 사용합니다.
해당 서비스 역할에는 테넌트 ID가 추가되었습니다.자, 이제
지표를 집계하면 이 메시지를 전달하고 해당 ID에서 테넌트 ID를 가져오고 입력도 얻을 수 있습니다.
토큰을 모아 모으세요.그리고 에이전트로 넘어가죠.다시 말씀드리지만, 여러 테넌트가 여러분과 상호작용하고 있다고 가정해 봅시다.
서비스와 서비스는 모든 에이전트를 호출합니다.
여기에 작업을 배정하면 상담원이 상호작용하게 됩니다.
대규모 언어 모델을 사용하여 작업을 완료하세요.방법을 자세히 살펴보기 전에
지표를 파악하려면 몇 가지 사항을 이해해야 합니다.
상담원에 관해서요.에이전트는 작업이 완료될 때마다 작업을 수행하는 방식입니다.
상담원에게 배정되면 작업이 세분화되고
그런 다음 세 단계로 실행됩니다.이것이 바로 사전 처리입니다.
스테이지, 오케스트레이션 스테이지, 포스트 프로세싱 스테이지.각 단계에서 특정 페이로드 형식을 사용하여 대규모 언어 모델과 상호 작용한 다음 a를 사용하여 전송합니다.
특정 입력 페이로드 형식으로, 대규모 언어 모델에서 특정 페이로드 형식을 전송합니다.페이로드를 보시면 잠시 후에 보여드리겠습니다.
두 번째로, 입력 개수를 전달할 수 있어야 합니다.
토큰과 출력 토큰.자, 여기서 말씀드리자면,
서비스 역할에는 다음과 같은 상호작용이 필요합니다 (딱딱 소리를 내면 화자가 익사합니다).
상담원이 대형 모델을 사용할 때 사용하는 언어가 커요.여러분이 할 수 있는 방법은
서비스가 에이전트를 호출하면 추적이 활성화됩니다.추적이 활성화되면 에이전트는 계속해서 메시지를 전송합니다.
다음과 같이 추적 메시지를 서비스에 다시 전송합니다.
여기에 전달할 수 있습니다.그리고 그 수를 구해보세요.
입력 및 출력 토큰.이제 서비스를 예로 들어보죠.
에이전트가 생성한 트레이싱을 살펴볼 수 있습니다.사전 처리를 위해
스테이지를 보면 에이전트를 알고 있다는 것을 알 수 있을 것입니다.
이 형식으로 형식을 입력한 다음 a로 전송
대규모 언어 모델.그리고 여러분이 보셨을 응답은
모델 호출 출력은 다음과 같습니다.그리고 이것들을 보면
응답을 보시면 아시다시피 입력 및 출력 토큰의 개수가 많다는 것을 알 수 있습니다.단지 형식을 보여드릴 뿐입니다.
이 메시지들은 여기 있어요.따라서 오케스트레이션 단계를 보면 비슷한 형식을 볼 수 있습니다.보시다시피 모델 호출 출력에 입력 및 출력 토큰이 있다는 것을 알 수 있습니다.보시면
포스트 프로세싱 단계에서도 아시다시피 입력과 출력이 있는 모델 함축 출력 메시지가 있다는 것을 알 수 있습니다.자, 여기서 말씀드리자면, 서비스는 이 모델의 함축 출력 메시지를 전달하고 입력의 개수를 구할 수 있다는 것입니다.
토큰과 출력 토큰은 물론 서비스 역할에서도 서비스를 확보할 수 있습니다.
테넌트 컨텍스트의테넌트 컨텍스트에서
테넌트 ID를 가져와 함께 모아 기록할 수 있습니다.
이를 CloudWatch 로그에 기록합니다.이제 서비스 코드를 살펴보고 이를 구현하는 방법을 알아보겠습니다.따라서 서비스에서 서비스 코드가 먼저 하는 일은
기본적으로 에이전트를 호출하는 거죠.호출할 때
에이전트, 추적을 활성화하고 있는 것을 볼 수 있었습니다.추적을 활성화했으므로 에이전트는 계속해서 메시지를 보낼 것입니다.
추적 메시지를 백업하면 기본적으로
메시지의 흐름을 듣고 반복하세요
그 스트림을 통해서요.그리고 메트릭 매니저를 사용하면 기본적으로 그 메시지들을 전달하게 됩니다. 모델을 아시죠?
알림 출력 메시지뿐만 아니라 입력 이벤트에서도 테넌트를 얻을 수 있습니다.
컨텍스트를 확인하고 이를 종합하여 CloudWatch 로그에 기록합니다.이제 벡터 스토어로 넘어가겠습니다.자, 이제 구체적으로 설명하겠습니다.
어떻게 캡처할 수 있는지 안내해 드리겠습니다.
컬렉션이 공유되는 기본 계층에 대한 일종의 스토리지 메트릭입니다.
여러 테넌트에 걸쳐당신이 당신을 안다고 가정해 봅시다.
애플리케이션 플레인이 있어요.애플리케이션 플레인 내에서
풀 컬렉션이 있는데, 이 풀 컬렉션은 인덱스를 생성하는 여러 테넌트에서 공유됩니다.
각 테넌트당방법을 이해하기 전에
지표를 파악하려면 한 걸음 물러서야 합니다.
그리고 OpenSearch 서버리스 컬렉션이 사용량에 대해 어떻게 요금을 청구하는지 근본적으로 이해하세요.요금은 세 가지 방식으로 청구됩니다.하나는 컬렉션 아래에 저장되는 데이터의 양인 스토리지 비용입니다.인덱싱 비용, 양
특정 인덱스와 상호 작용할 때 소비되는 계산 단위 및
검색 및 쿼리 비용.그 금액입니다.
검색을 할 때는 경쟁의 필요를 소비해야 합니다.
그리고 그들의 데이터를 쿼리하기도 하죠.자, 이제 이들 각각에 대해
테넌트 인덱스의 경우 스토리지 비용 인덱싱 비용과 검색 및 쿼리 비용을 구해야 합니다.스토리지 비용에 대해서는 다음 인덱스를 살펴보면
이러한 인덱스 아래에는 해당 인덱스 아래에 저장된 데이터의 양을 직접 확인할 수 있습니다.아주 간단합니다.하지만 인덱싱의 경우
검색과 쿼리에 드는 비용이 조금 더 듭니다.
도전적이고 흥미로운 분야에서는 하나를 선택해야 하는 접근법을 고안해야 합니다.
해당 인덱스와 검색 및 쿼리 비용과 매우 유사한 메트릭입니다.즉, 인덱싱 비용의 예를 들어보죠.색인 비용에 대해서요.뭐
인덱싱 비용과 매우 유사한 지표를 선택할 수도 있는데, 다시 말하자면 데이터의 양입니다.
이러한 인덱스 아래에 저장됩니다.이 모든 것을 종합해 보자면,
제가 말하고자 하는 것은, 아시다시피 스토리지 비용과 인덱싱 비용에 대한 것입니다.
저장된 데이터의 양을 거의 사용할 수 있습니다.
인덱스 아래에는 테넌트 비용을 높이는 지표로 사용됩니다.그러니까 여러분이 그렇게 할 수 있는 방법은
기본적으로 OpenSearch Serverless 컬렉션에 도달하여 이러한 인덱스 아래에 저장된 데이터의 양을 가져와서 해당 정보를 CloudWatch 로그에 기록하는 독립 실행형 서비스를 구축할 수 있습니다.다시 한 번 말씀드리지만, 여기서 볼 수 있는 문제는
테넌트 컨텍스트를 알 수 있을까요?이 서비스는 독립형 서비스입니다.JW 토큰에 대한 액세스 권한이 없을 수 있으며, 이 경우 테넌트 컨텍스트를 가져오지 못할 수 있습니다.다시 말하지만, 규칙을 사용할 수 있습니다.
여기서 OpenSearch 서버리스를 정의할 때
컬렉션을 정의할 수 있고 인덱스 이름을 지정할 수 있습니다.
테넌트 ID로이제 이 독립 실행형 서비스를 OpenSearch에 적용할 수 있습니다.
서버리스 콜렉션을 통해 인덱스 이름에서 테넌트 ID를 가져오고 그 양도 구합니다.
데이터는 그 아래에 저장되어 있으며, 이를 모아 게시합니다.
이를 CloudWatch 로그에 저장합니다.이제 스토리지 및 인덱스 비용이 절감되었습니다.한 가지 빠뜨린 것이 하나 있습니다.
검색 및 쿼리 비용입니다.바로 그 부분이 그림으로 드러납니다.
여러 테넌트가 컴퓨터와 상호 작용하는 경우그리고 해당 컴퓨팅은 지식 베이스를 통해 OpenSearch Serverless 컬렉션과 상호 작용합니다.다시 한 번 말씀드리지만,
검색 및 쿼리 비용, 생각해 내야할 것은
검색 및 쿼리 비용과 매우 유사한 지표입니다.한 가지 예를 들자면 다음과 같습니다.
특정 쿼리의 실행 시간을 캡처할 수 있습니다.이를 지표로 사용하세요.
특정 쿼리 비용의 경우.이걸 사용하고 있고 기본적으로 캡처를 할 수 있는 작은 라이브러리를 만든다고 가정해 봅시다.
실행 쿼리를 한 다음 해당 쿼리의 실행 시간을 해당 정보로 전달합니다.또한 테넌트 컨텍스트도 포함됩니다.
이 지표를 선택하여 게시할 수 있는 지표 관리자에게 전달됩니다.여기서도 제가 간략하게 설명한 내용은 좀 더 세밀한 접근 방식입니다. 오픈 컬렉션과 서버리스 컬렉션과 관련하여 특정 테넌트의 스토리지 비용 메트릭을 계산하거나 캡처할 수 있는 방법에 대해 자세히 설명했습니다.하지만 실제로는, 아시다시피, 여러분의 의견을 바탕으로
요구 사항에 따라 좀 더 굵은 입자를 조정할 수 있습니다.
일종의 근사치를 사용할 수 있는 접근 방식
한 가지 지표를 선택하고 그 지표를 근사치로 사용하여 결과를 세분화하는 방식입니다.
테넌트 전체의 비용.이 경우처럼 다음과 같이 할 수 있습니다.
대부분 이러한 인덱스 아래에 저장된 데이터의 양을 사용하고 해당 메트릭을 사용하여 테넌트 전체의 비용을 줄일 수 있습니다.따라서 아키텍처의 이 단계에서는 CloudWatch 로그에 모든 지표가 캡처됩니다.
테넌트 컨텍스트와 함께.그래서 여러분이 해야 할 일은
지표를 집계하는 거죠.하이 페인트로 칠해 볼게요
어떻게 해야 하는지에 대한 높은 수준의 그림을 보여드리겠습니다.
지표를 집계하세요.그런 다음 해당 구성 요소를 두 번 클릭하면 좀 더 자세히 이해할 수 있을 것입니다.첫 번째로, 당신은
할 수 있는 건 기본적으로 CloudWatch를 사용하는 일종의 람다 함수를 만드는 것입니다.
CloudWatch 로그와 상호 작용하기 위한 인사이트 쿼리
테넌트를 구해서, 알다시피, 그 비율을 집계해 보세요.
팀 전체의 소비량.기본적으로 전체를 집계하세요.
생성된 입력 토큰과 출력 토큰의 수
각 테넌트에 대해 백분율을 구하십시오.
테넌트 전체의 소비량.일단 그걸 얻고 나면,
Athena 서비스를 사용하여 비용 및 사용 보고서를 보고 다음과 같은 정보를 얻을 수 있습니다.
총 서비스 비용.그러면 곱셈이 되겠죠.
이 총 서비스 비용을 합한 소비의 백분율은
테넌트당 비용을 산출하기 위함입니다.해당 정보를 일종의 DynamoDB 테이블에 저장할 것입니다.일단 그 정보를 얻으면
그러면 그 데이터를 시각화할 수 있죠.
그 데이터를 어떤 방식으로든 쪼개서 보세요.
알다시피, 예상할 수 있죠.이제 이 람다 함수의 코드를 살펴보죠. 람다가 집계된 함수입니다.
함수를 작성하고 이 로직을 구현하는 방법을 이해해 보세요.제가 먼저 말씀드린 것은 메트릭을 쿼리해야 한다는 것입니다.중요한 건, 여러분이 할 수 있는 일은
이 코드에서 볼 수 있듯이 CloudWatch를 사용하고 있습니다.
입력 토큰과 출력의 수를 가져오기 위한 인사이트 쿼리
테넌트 컨텍스트가 포함된 토큰기본적으로 테넌트 ID입니다.
클라우드워치 로그 전반에 걸쳐.기본적으로 다음 쿼리는
전체 테넌트에 대한 총 테넌트 입력 및 출력 토큰을 가져오려고 합니다.그러면 여러분은 마치 다음과 같습니다.
이 두 값을 나눠서 다음의 백분율을 구합니다.
테넌트 전체의 소비량.따라서 기본적으로 입력 토큰과 출력 토큰의 테넌트 속성 백분율을 구하려고 합니다.다음으로 해야 할 일은 기본적으로 서비스 비용을 구하는 것입니다.서비스 비용에 대해서는 앞서 말씀드린 것처럼
Athena를 사용하여 비용 및 사용 보고서와 상호 작용하여 서비스 비용을 확인할 수 있다고 말씀드렸습니다.이 경우에는 다음과 같이 실행할 수 있습니다.
아시다시피 Athena 쿼리입니다.그리고 한 번
이 Athena 쿼리를 실행하고 이제 결과를 바탕으로
할 수 있는 일은 통과시켜서 서비스 비용을 받는 것입니다.
사용을 위한 입력 토큰과 출력 토큰에 대해
특정 LLM 모델.이제 서비스 비용도 알 수 있고 비용도 알 수 있습니다.
소비의 백분율.다음으로 해야 할 일은 기본적으로 테넌트당 비용을 계산하는 것입니다.이를 위해 해야 할 일은
아까 말씀드렸듯이 이 둘을 곱하면 됩니다.이것이 바로 이 방법이 하는 일입니다.이 방법은 기본적으로
전체 서비스에 대한 테넌트 백분율 곱하기
입력 토큰과 출력 토큰을 구하려면 얼마인가요?
입력 토큰과 출력 토큰의 비용이 계산됩니다.
각 테넌트.그런 다음 이를 합쳐서 이 서비스의 총 비용을 구하는 것과 비슷합니다. 이 경우에는 기본적으로 베드록입니다.일단 그 총액을 계산하고 나면
서비스 비용은 일종의 DynamoDB 테이블에 저장하게 됩니다.이렇게 하면 테넌트당 비용을 계산할 수 있습니다.
아키텍처에 적합합니다.마지막으로 넘어가겠습니다.
아키텍처 관련 과제에 대해 알아보겠습니다.
오늘은 시끄러운 이웃입니다.이러한 상황을 완화하는 한 가지 방법
시끄러운 이웃 환경은 어떤 식으로든 가능케 하는 것입니다.
아시다시피 테넌트의 경우 API 레벨에서 스로틀링 경험을 할 수 있습니다.여기서는 소개해 보도록 하겠습니다.
어떻게 하면 스로틀링 경험을 구현할 수 있을까요?
테넌트 토큰 사용.기본 티어와 프리미엄 티어를 살펴보면 공통적인 아키텍처가 있는데, 이는 이것 말고는 아무것도 아닙니다.따라서 기본적으로 API가 있습니다.
게이트웨이, API 게이트웨이는 람다 권한 부여자를 사용합니다.
요청을 승인하고 해당 요청을 전달하려면
마이크로서비스로 돌아가면 마이크로서비스는
베드록과 상호작용하세요.이제 여러분이 할 수 있는 일은
API 게이트웨이에 대해 이미 잘 알고 계실 수도 있습니다.
레벨에서는 일종의 사용 계획을 활성화할 수 있는데, 이는 요청을 제한하는 것과 비슷합니다.그 외에도 무엇을 해야 할까요?
할 수 있는 일은 일종의 테넌트 토큰 사용 계획을 도입하는 것입니다.다시 말씀드리지만, 그냥 말씀드리자면
여기 가상의 숫자가 있네요. 하지만 여러분은 다른 숫자를 가질 수도 있습니다.
기본 등급의 사용 요금제와 프리미엄 등급의 사용 요금제가 다릅니다.이제 테넌트를 온보딩할 때 이 토큰 사용 계획과 해당 정보를 할당해야 합니다.
컨트롤 플레인에 있는 테넌트 관리 서비스에 다시 캡처됩니다.이제 필요한 것은 실시간으로 집계해야 하는 아키텍처입니다.
생성된 입력 토큰과 출력 토큰의 수
각 테넌트에 대해여기서는 아키텍처가 이미 존재한다고 가정해 보겠습니다.
이러한 메트릭을 캡처하고 이를 위해 할 수 있는 일은 다음과 같은 간단한 아키텍처를 구축하는 것입니다.
CloudWatch 로그를 쿼리하고 이를 시도하는 일종의 람다 함수는 집계를 시도합니다.
전체 입력 토큰과 출력 토큰의 수는 다음과 같습니다.
여러분의 테넌트가 그걸 퍼블리쉬하고 몇몇에 푸시하고
일종의 DynamoDB 테이블이죠.다시 말씀드리지만, 이 정보가 얼마나 실시간으로 필요한지에 따라 더 강력한 아키텍처를 구축하여 실시간 소비 또는 토큰 생성을 얻을 수 있습니다.그런 다음 API 게이트웨이에 요청이 들어오면 람다 권한 부여자가 이를 호출하고 람다 권한 부여자가 호출합니다.
테넌트 컨텍스트를 사용하거나 테넌트를 준비하면 다음을 수행할 수 있습니다.
컨트롤 플레인에 연락하세요.컨트롤 플레인에서 사용 계획을 가져올 수 있습니다.
특정 테넌트에 할당됩니다.그러면 실시간으로 할 수 있습니다.
이 테넌트 사용량 표를 눌러 현재 사용량을 확인하세요.
특정 테넌트의 값을 모두 비교해 보세요.
이 특정 요청을 허용할지 아니면 철회할지 여부를 결정합니다.다시 말하지만, API 게이트웨이 수준에서 캐싱을 활성화할 수 있습니다.캐싱을 활성화하면 이 로직이 실행되지 않을 수 있습니다.
모든 요청에 대해, 하지만 역시 요구 사항에 따라 요구 사항에 맞게 구성을 변경할 수 있습니다.이제 두 번 클릭하여 코드를 살펴보겠습니다.
사전 사용량 계산기와 람다
권한 부여자를 통해 이 내용을 좀 더 자세히 이해할 수 있습니다.따라서 테넌트 토큰 사용량 계산기에서 가장 먼저 하는 일은 기본적으로 CloudWatch 로그 쿼리와 집계 시도를 사용하여 집계하는 것입니다.
테넌트별 테넌트 사용량을 계산한 다음 해당 정보를 일종의 DynamoDB 테이블에 저장합니다.그런 다음 테넌트 ID를 사용하여 만든 Lambda 권한 부여자의 경우 컨트롤 플레인을 호출하여 할당된 토큰 사용량을 가져옵니다.
이 특정 테넌트에 대해서요.그런 다음 a를 호출합니다.
제한을 확인하는 메서드입니다.그 방법을 보시면, 가장 먼저 하는 일은 기본적으로 그 방법을 맞추는 것입니다.
현재 토큰 사용량을 가져오기 위한 테넌트 토큰 사용 표
해당 특정 테넌트용.그리고 기본적으로, 여러분은
할당된 토큰을 특정 테넌트와 비교하기
토큰 사용에 반대하여 이 특정 요청을 허용할지 또는 허용하지 않을지 결정합니다.그리고 마지막으로,
이 세션에서 얻은 몇 가지 요점을 요약해 보죠.소개해 드린 내용은 다음과 같습니다.
기본 등급과 프리미엄 등급의 두 가지 아키텍처가 있습니다.하지만 다시 한 번 말씀드리지만, 알아두셔야 할 점은
여기에는 AWS 서비스 할당량과 제한이 있습니다. 그런 것들을 살펴보고 서비스 할당량을 기반으로 자체 아키텍처를 구축해 보세요.여기서 간략히 설명하겠지만, 이 아키텍처를 구축할 때는
아키텍처와 이 아키텍처를 살펴보면서
우리는 모든 SaaS를 해결하려고 노력합니다.
아키텍처 문제를 통해 얻을 수 있는 수익
견고한 아키텍처.그러니 건물을 지을 때 그런 각도에서 생각해 보세요.
자신만의 아키텍처, 다양한 문제를 해결해 보세요.
요구 사항에 따라 달라지는 아키텍처 관련 문제, 이를 통해 견고한 아키텍처를 구축할 수 있습니다.그리고 다음과 같은 경우에는
SaaS 솔루션을 구축한다면 분명 시도해 볼 것입니다.
테넌트 기반 경험을 제공하기 위해 촬영하기 위해서입니다.
그러려면 계층화 전략을 활용하세요.앞서 설명했듯이 기본 등급과 프리미엄 등급을 정의하려고 합니다.이를 통해 저희는 여러분께 색다른 경험을 제공하고자 노력하고 있습니다.
여러분의 다양한 임차인들.그리고 나서 여러분이
테넌트 격리 및 데이터 파티셔닝을 구현하면
개념을 구현하는 방법은 비슷하지만 구현하는 방법은 다를 수 있습니다.예를 들어, 이 경우에는 오픈 서버리스 컬렉션을 사용합니다.테넌트 격리를 구현하는 방법을 안내해 드립니다.하지만 다시 말씀드리지만, 실제로는 다른 벡터 저장소를 사용할 수도 있고 다른 벡터 저장소를 사용할 수도 있습니다.
이를 구현하기 위한 도구지만 개념은 같지만 구현하는 방법은 동일하다는 것입니다.
다를 수도 있습니다.그러니 마음 속에 기억해 두세요.그런 다음 가능한 모든 곳에서 IAM을 활용하여 테넌트 격리를 구현하세요.그리고 다음과 같은 경우에는
메트릭을 캡처할 때는 항상, 항상 테넌트 컨텍스트로 메트릭을 캡처하여 집계할 수 있도록 하세요.
지표는 나중에 테넌트 전체에서 확인할 수 있습니다.다시 말씀드리지만, 일단 해당 정보를 얻으면 다른 방식으로 사용할 수 있습니다.예를 들어, 여러분은
저희 세션에서 지표를 캡처한 것을 볼 수 있습니다.
테넌트 컨텍스트를 사용하여 각 테넌트에 대해 생성된 입력 토큰 및 출력 토큰의 수.이를 사용하여 테넌트당 비용을 도출하고 동일한 메트릭을 사용하여 일종의 테넌트를 활성화할 수도 있습니다.
스로틀링 경험은 10개의 토큰 사용량을 기반으로 합니다.
API 게이트웨이 수준에서.그리고 이것은 GitHub 리포지토리입니다.
링크는 앞서 언급한 대부분의 코드가 있는 곳입니다.그리고 이것이 새로운 내용입니다.
저희가 만든 작업장.그리고 우리는 이것을 운영하고 있습니다.
수요일 아침에 워크숍이 있어요.이 워크숍의 아이디어는 SaaS 405입니다.관심이 있으시면 언제든지 워크숍에 참여하세요.정보를 잠시 멈출게요, 네.그리고 이것들은 몇 가지입니다.
제 팀원들이 진행하는 추가 세션들이죠.뭐, 만약 뭔가가 있다면
흥미를 유발한다면, 부담없이 이 세션에 참여하세요.다음은 그 중 일부입니다.
워크숍과 빌드 세션.마지막으로, 감사합니다.들러주셔서 감사합니다. 인내심을 갖고 기다려주세요.
그리고 여기서 우리의 강연을 들어보세요.그리고 정말 고마워요.
여기 계신 여러분들.그리고, 알다시피, 제발
설문지를 작성해 주세요.