- 네, 안녕하세요, 저는 마크 브루커예요.저는 아마존의 저명한 엔지니어입니다.보시다시피 데이터베이스 서비스에서 볼 수 있듯이 저는 주로 시간을 할애하지만 많은 시간을 할애하기도 합니다.
우리 AI 및 세대 AI 팀과 함께 말이죠.하지만 이번 강연은 이에 관한 것이 아닙니다.
그 어떤 부분도 직접적이죠.그 대신, 어려운 몇 가지 교훈에 대해 말씀드리자면
AWS에서 대규모 서비스와 소규모 서비스를 운영하면서 수년 동안 배웠습니다.아시다시피, 그 중 하나는
수술을 해본 사람으로서 알게 될 것들
서비스, 물건을 만들었기 때문에 흔히 배울 수 있는 것은
대부분 최악의 시절부터 말이죠.그래서 이 강연에 담긴 것은 몇몇 사람들로부터 얻은 교훈입니다.
스트레스가 많은 시간들, 때로는 실망스러웠던 시간들
우리 자신과 고객, 그리고 방법을 배웠습니다.
다시는 그런 짓을 하지 않기 위해서요.AWS에서 경력을 쌓으면서, 얼마 전 제가 얼마나 많은 사후 조사를 했는지 추산해 보려고 했어요.
업계 전반의 글을 읽어보세요.제가 예상할 수 있는 가장 좋은 추정치는 3명에서 4,000명 사이였습니다.그래서 꽤 많은
어려운 것들이 여기에 녹아들었죠.그럼 이 시간에 대해 얘기할게요
재시도 관련 문제 및 재시도로 인한 시스템 문제.특히 제가 많이 생각하는 문제들은
사람들은 주변의 모범 사례를 고려할 것입니다.
시스템에서 재시도가 발생합니다.서킷 브레이커에 대해 얘기할게요.그리고, 알다시피, 장점과 단점, 회로 같은 것들
차단기는 잘하고 그로 인해 발생하는 몇 가지 문제도 있습니다.회로 구현으로 인한 예상치 못한 다운타임
시스템의 차단기.이레이저 코딩과 몇 가지 다른 기술에 대해 말씀드리겠습니다.
테일 레이턴시를 줄이기 위해서죠.테일 레이턴시에 대해 생각해보고 테일 레이턴시를 모델링하고 시뮬레이션하기 위한 몇 가지 통계 기법도 있죠.그리고 안정 시스템 이론과 안정성과 준안정성에 대한 일종의 프레이밍에 대해 조금 이야기해 볼게요. 제가 정말 좋아하고 일목요연하게 생각해요.
우리의 멘탈 모델이 이런 것들에 대해 생각하는 데 도움이 되죠.그리고 마지막으로, 조금은 더 먹을게요
통계에 대한 호언장담입니다. 더 많은 사람들이 통계를 사용하는 것을 보고 싶지만 불필요하게 어렵게 만들고 있기 때문이죠.그럼 재시도를 시작해 보죠.자, 알다시피, 제 생각엔 모든 사람들이 이런 걸 봤을 때
분산 시스템 빌딩 101은, 아, 음, 저는
다시 시도할 거야, 그렇지?그게 좋으니까요.재시도하면 저장이 완료될 것입니다.
상황이 안 좋을 때 나야그들이 날 구해줄 거예요
오류가 생기거나 패킷이 손실될 때그리고 그것은 근본적으로 문제가 아닙니다.
잘못된 사고방식이죠.하지만 이 사고방식에는 뭔가 숨어 있는 게 있어요.
위험과 단점.이해를 돕기 위해 예제 시스템에 대해 이야기해 보겠습니다.자, 그럼 왼손은 뭐죠?
슬라이드의 한 부분에는 많은 고객들이 있습니다.이들은 보통 다음과 같이 생각할 수 있습니다.
웹사이트 클라이언트 맞죠?무작위로 들어오는 사람들이거나
완전히 독립적으로 말이죠.그리고 그들의 행동은 정말 대단하죠.
많은 사람들이 일종의 모범 사례를 고려하겠죠?마치 타임아웃을 구현하는 것 처럼요
그들이 우리 서버를 호출할 때서버에서 오류가 발생하거나 네트워크에서 오류가 발생하면 세 번의 재시도를 합니다.하지만 그들은 a를 읽었기 때문입니다.
이에 대한 많은 기사들은 지수적인 내용도 담고 있습니다.
백오프와 지터가 생기는 건 좋은 일이기 때문이죠.슬라이드 반대편에는 서버가 있습니다.그리고 아무것도 없어요.
서버에 대해 흥미로워요.항상 성공적이죠.
항상 고성능이지만 한 가지 종류가 있습니다.
흥미로운 물건이지요.즉, 반환되는 지연 시간은 선형적으로 좌우된다는 것입니다.
부하의 양에 따라 다릅니다.자, 완벽하진 않아요.
현실 세계의 모형이긴 하지만 무리는 아니죠
현실 세계의 모델.건물을 통해 알 수 있죠.
대규모 시스템은 다툼으로 인해
코디네이션 때문에, 스레드 때문에
잠금, 래칭, 온갖 문제 때문에 함께 작업해야 하는 상황
그 외에도 지연 시간이 길어지는 경향이 있습니다.
실제 시스템에서의 동시성은 일정하지 않습니다.자, 그럼 우리가 어떻게 됐냐고요?
이 시스템으로 우리가 제공할 수 있는 것은
부하가 엄청나죠.그리고 기준선 하중의 종류는 어느 정도일 것입니다.
감당할 수 있는 능력이죠.그런 다음 1초라는 짧은 과부하 스파이크를 추가할 것입니다. 시스템이 처리하기에는 너무 많은 부하가 걸려서 클라이언트가 제한 시간을 초과하기 시작할 정도로 지연 시간을 충분히 높일 수 있을 정도입니다.그런 다음 이 경우 시스템에 어떤 일이 발생하는지 알아보도록 하겠습니다.그럼 재시도를 하지 않는 초당 성공 횟수부터 살펴보죠?여기서 클라이언트의 재시도 동작을 비활성화했습니다.여기서 볼 수 있는 것은
우린 평범하게 잘 지내고 있다는 거죠. 왜냐하면 우리가 할 수 있는 일은
트래픽이 정상인데 트리거가 되지 않아요
아직 타임아웃이 끝났어요그리고 그 스파이크가 발생하면 클라이언트의 모든 타임아웃이 일어납니다.따라서 트래픽이 크게 증가했기 때문에 시스템 지연 시간도 크게 늘어났습니다.그리고 클라이언트의 관점에서 볼 때, 고객이 보는 것은
성공은 0으로 떨어졌습니다.그런 다음 이러한 초과 요청은 시스템을 통해 전달되고 시스템은 복구됩니다.다시 좋아집니다.우리 고객들은 다시 성공을 보기 시작합니다.그리고 앞으로도 계속 발전해 나갈 수 있기를 바랍니다.
이 그래프의 오른쪽에서는 계속해서 성공을 거두고 있습니다.그러니까 이게 안 좋은 거죠. 왜냐하면 고객들은
다운타임 기간, 즉 다운타임이 발생했습니다.
이는 우리가 목격한 트래픽 폭증보다 약 두 배 더 긴 시간입니다.하지만 좋은 점이기도 하죠. 아주 빠르게, 단 두 배 더 빠른 시간 안에 말이죠.
트래픽이 급증했을 때 우리는 완전히 회복할 수 있었습니다.
시스템이 완전히 복구되었습니다.앞서 말씀드린 세 번의 재시도를 시스템에 다시 추가해 보겠습니다.아, 아니요.지금은 전혀 회복이 안 됐어요.이건 정말 큰 문제예요.그리고 이건 큰 문제예요. 왜냐하면
아직 재시도하지 않았어요. 아직 출시하지 않았어요.
오버로드 기간에는 이러한 재시도가 더 좋습니다.하지만 시스템이 전혀 복구되지 않는 모드를 도입했습니다.클라이언트는 절대 회복을 볼 수 없습니다.그리고 그 고객들은 왜 그럴까요?
회복을 볼 수 없나요?왜냐하면 어떤 클라이언트가 들어와서 첫 번째 요청을 하면 요청이 급증하기 때문이죠.이제 모든 클라이언트의 시간이 초과되었습니다.그리고 모든 클라이언트의 시간이 초과되어 재시도가 시작되었습니다.그래서 우리가 한 일은
시스템을 모든 클라이언트가 들어오는 모드로 전환했습니다.
모든 클라이언트가 제한 시간을 초과하고 모든 클라이언트가 재시도합니다.
모든 클라이언트는 이리저리 타임아웃되고
원을 네 번 돌았어요따라서 재시도로 인해 서버가 현재 처리하고 있는 트래픽의 양을 생각해 보면 트래픽의 양은
처리 중인 서버가 4배 증가했습니다.그리고 이제 시스템은
제한 시간 내에 이 작업을 완료할 수 없습니다.그래서 우리는 회복탄력성을 구축했습니다.
예상했던 대로 클라이언트에 적용되는 메커니즘
끊이지 않는 다운타임을 초래한 상황을 개선하기 위해서죠.그래서 우리가 할 수 있는 유일한 방법은
시스템을 더 잘 작동시키려면 서버 용량을 더 추가해서 복구할 수 있게 하거나 클라이언트를 일시적으로 차단하고 과부하 기간을 걸러낸 다음 천천히 놔두는 것입니다.
클라이언트가 시스템에 다시 들어옵니다.이럴 수도 있고 이것도 마찬가지일 수 있습니다. 여러분 중 몇몇은 이렇게 들리실 수도 있습니다.
공상 과학 소설 맞죠?이봐, 정말 바보 같은 일이야
세계의 모델.이것이 바로 일부 대규모 정전의 근본 원인입니다.
업계 역사를 통틀어 대규모 시스템에 대해서요.경우에 따라 구체적으로 재시도를 하는 경우도 있지만, 시스템이 최악의 상황에 처했을 때 더 많은 작업을 수행하고, 협박에 시달릴 때는 더 많은 작업을 수행하게 하는 온갖 종류의 영향이 있을 수 있습니다.이것이 바로 여기서 벌어지고 있는 일입니다.저희 고객들이 말하길, 너무 과부하가 걸리고 느리다 보니 해야 할 일이 네 배나 더 많다고 하더군요.이 방법이 여러분에게 얼마나 잘 맞을까요?그래요, 만약 당신이 상사에게 가서 “좀 과로한 것 같아요, 맞아요, 잠깐 쉬고 싶어요.” 라고 말한다면아마, 알다시피, 며칠 정도 걸릴 수도 있겠죠.그리고 그는 말했죠. 아니요, 이제 네 배는 더 일할 수 있어요.네, 아마 그만둘 거예요.서버가 종료되지 않았어요.그냥 천천히 흔들릴 수밖에 없었어요.
무의미한 일을 통해서 말이죠.그래서 이것이 말해주는 것은 사실 두 가지 종류가 있다는 것입니다.
이러한 시스템에서 발생한 오류의 양상이죠.이중화 시스템에서 흔히 발생하는 일시적인 장애가 있습니다.네트워크에서 흔히 발생합니다.이는 개별적으로 실패한 요청입니다.개별 생리 기간입니다.
패킷 손실, 맞죠?그것들은 개별적인 것들이에요.
상관관계가 없는 방식으로 실패합니다.그리고 이러한 일시적인 장애 시에는 재시도가 큰 도움이 됩니다.실제로 가장 많은 성과를 거둘 수 있습니다.
일시적인 장애 사례는 클라이언트가 거의 볼 수 없는 경우를 제외하고는 거의 보이지 않습니다.
지연 시간이 약간 늘어났습니다.그리고 다음이 있습니다.
두 번째 종류의 실패는 체계적 실패입니다.그리고 이런 실패들은 수가 많을 때 발생합니다.
같은 원인으로 인한 실패 또는 시간 초과가 여러 번 발생합니다.부하로 인해 발생할 수 있습니다.자물쇠의 경합으로 인해 발생할 수 있습니다.소프트웨어로 인해 발생할 수 있습니다.
버그, 운영 문제 및 기타 모든 종류의 문제.그리고 그 기간 동안
이러한 시스템적 실패, 재시도는 행동에 심각한 해를 끼치고
시스템의 가용성.고려 중임에도 불구하고
이런 종류의 모범 사례죠.그리고 이것은 재시도 횟수를 계산합니다.
모든 레벨에서 말이죠, 그렇죠?네트워크 재시도일 수도 있어요. 아시다시피 SYN 패킷을 하나 더 보내세요.애플리케이션 수준의 재시도일 수 있습니다.아니면 그냥
웹사이트가 로드되지 않을 때 고객은 F5에서 통곡하는 것 같아요.그럼 이걸 어떻게 할 수 있을까요?해결책이 있을까요?그러고 보니, 네,
해결책이 있습니다.사실 엄청 많아요
다양한 솔루션, 다양한 알고리즘이 있습니다.하지만 여기 하나 있어요.
저는 특히 AWS에서 토큰이라는 이름을 갖고 있다는 점이 마음에 듭니다.
저희가 구축한 버킷 또는 적응형 재시도
지난 10여 년 동안 거의 모든 시스템이 사용되었습니다.이 적응형 재시도 알고리즘은 잠시 후에 설명하겠습니다.
재시도 알고리즘이 없으면 운영 중단이 조금 더 길어지고 과부하 기간이 길어집니다.
조금 더 길지만 용량을 추가할 필요 없이, 차지 않고도 시스템을 복구할 수 있습니다.
클라이언트 퇴장이라던지 뭐그럼 이 알고리즘은 어떻게 작동할까요?글쎄요, 우린 좀 최상위권에 있어요
통화를 시도해서 말이에요, 그렇죠?이건 그냥 재시도 알고리즘일 뿐이죠.아직 다 해볼까 고민하고 있진 않아요.그래서 클라이언트가 하는 일은 버킷 안을 들여다보는 거죠.
그러자 말하죠. 토큰이 있나요?알다시피, 재시도 해볼까요?
제 버킷에 토큰이 들어 있죠?이건 바구니 같아요
동전이든 뭐든 잔뜩.그리고 알다시피, 저도 그랬죠?
재시도 횟수 제한을 다 했나요?그러니까 그걸 좀 뽑아낼 수 있다면
버킷에서 동전을 꺼내고 재시도 비용을 지불하면 재시도를 합니다.그럴 수 없다면 포기하는 거죠.그리고 성공하면 할 수 있는 일은 바로 투자하는 것입니다.
양동이에 토큰 몇 개, 맞죠?그러니까 다시 시도하려면 버킷에서 1달러를 꺼내야 합니다.한 푼도 던지세요.
성공할 때마다그래서 아주 큰 문제가 생겼습니다.
아주 간단한 알고리즘, 아주 간단한 변경
재시도 루프가 작동하는 방식.하지만 실제로 들어오는 총 트래픽을 제한한다는 것이죠.
안정적인 클라이언트 세트에서 일반 부하의 101% 까지.최대 부하를 유발할 수 있는 세 번의 재시도 사례와 비교하면
일반적인 부하의 400% 맞죠?그러니까 아무 종류도 없이
회로 차단기의 경우, 여기서 수행한 작업은 재시도 중에 시스템이 수행할 수 있는 최대 작업량을 매우 효과적으로 제한한 것입니다.따라서 다음과 같이 비교해 볼 수 있습니다.
이 세 가지 해결책이 있습니다.재시도 필요 없어요. 정말 좋아요.
시스템적 실패에 대해서요그들은 물건을 만들지 않아요
설상가상으로, 정말 좋아요.그들은 어떤 도움도 주지 않습니다
일시적인 장애.그거 나쁘네요.일종의 스탠더드 쓰리 같은 거죠.
백오프와 지터가 있는 재시도는 시스템 오류에 취약합니다.사실 이렇게 하면 많은 결과를 얻을 수 있습니다.
시스템 장애 클래스는 훨씬 더 나빠집니다.일시적인 오류에 적합합니다.일시적인 장애가 훨씬 더 흔하기 때문이죠.
실제 시스템에서는 그렇죠?이런 일들은 매일 일어납니다.단일 서버가 있는 경우
장애, 패킷 손실, 시스템 재부팅 등 모든 일이 발생합니다.
인프라 내부는 다음과 같이 보입니다.
세 번 재시도해도 괜찮습니다.그래서 일종의 방법이 있습니다.
여기서 일어날 조직적인 일인데, 사실, 아니, 모르겠다고 말하실 겁니다.
이 모든 재시도를 하고 싶어요.누군가 말하겠죠. 음, 재시도를 켜면 오류 대시보드에 있던 작은 스파이크가 사라질 거예요.
저리 가세요. 분명 그럴 거예요.하지만 도착하면
이런 종류의 과부하 사례, 이런 드문 경우는
자주 등장하진 마세요. 여러분은 훨씬 더 오랫동안 다운될 시스템을 구축한 셈입니다.따라서 적응형 재시도는 불가능합니다.
이 문제를 완전히 해결해 주긴 하지만, 둘 다 꽤 훌륭한 해결책을 제공합니다.
시스템 장애가 있다고 해서 문제가 없어지지는 않지만 시스템이 제대로 작동할 수 있게 해줍니다.
정상 부하 상태에서 복구할 경우 거의 대부분 복구됩니다.당연한 건 아니죠.
하지만 괜찮은 자산이지요.그나저나 테스트하기도 더 쉬워요.그리고 일시적인 장애에도 좋습니다.사실 제 알고리즘 예제에서 오류율이 100% 미만이면 (죄송합니다) 1% 미만이면
정확히 같은 동작과 동일한 장점이죠.
일시적인 실패의 경우, 일종의 세 번의 재시도
순진한 알고리즘이라면 그랬을 겁니다.그러니까 재시도에서 이런 작은 변화가 생겼습니다.
알고리즘은 우리가 의도한 것의 전체 클래스를 피합니다.
준안정 동작을 호출할 수 있네요. 대단한 분들 덕분입니다.
연구 커뮤니티에서 시스템 안정성에 대해 연구해 보세요.많은 이야기를 할게요.
준안정성에 대해서는 이 강연 후반부에서 더 자세히 설명하겠습니다.아주 작은 알고리즘 변경으로 정말,
정말 큰 차이죠.우리는 이를 AWS SDK에 내장했습니다.Amazon의 내부 서비스 프레임워크에 이를 구축했습니다.이를 여러 부분으로 나누어 구축했습니다.
네트워크 스택의 일부입니다.그리고 많은 걸 찾았어요.
덕분에 안정성이 향상되었습니다.그리고 어떤 사람이 재시도 루프를 작성한다는 이야기를 들을 때마다 저는 i가 0에서 3과 같기 때문에 이 문서를 읽으라고 보냅니다.맞아요, 대규모 시스템을 구축하려면 이 내용을 이해해야 합니다.그러니까, 뭐, 기하급수적인 건 아니라는 말씀이신 거죠.
백오프로 이 문제가 해결되나요?사실, 아니에요, 그렇지 않아요
아니면 가끔씩만 그럴 수도 있습니다.그리고 그게 언제인지 이해하기 위해서요.
맞아요, 그렇지 않을 때는 얘기해 봐야겠어요, 여기 개 한 마리 더 있어요. 두 마리에 대해 얘기해야 돼요
서로 다른 클래스의 시스템이죠.서로 다른 두 종류의 시스템을 구분하는 것은 “Open Versus”라는 훌륭한 연구 논문에서 나온 것입니다.
클로즈드: 주의 사항.”확인해 보는 것이 좋습니다.
이 강연 후에 얘기해그리고 우리에겐 이 두 가지가 있습니다.
서로 다른 등급의 시스템이죠.하나는 기본적으로 무작위로 들어오는 요청 스트림이 있는 오픈 시스템이라고 불립니다.이는 웹사이트, 모바일 백엔드 등에서 매우 흔하게 볼 수 있는 현상입니다.
웹 서비스 맞죠?이건 네 거야, 네가 가지고 있는 거잖아
수천 명의 고객, 수만 명의 고객, 수백만 명의 고객
수십억 명의 고객이 웹사이트를 언제 로드할지 통제할 수 없습니다. 그들은 기본적으로 기분이 좋을 때마다 무작위로 로드합니다.또 다른 클래스는
시스템은 폐쇄형 시스템입니다.종류가 있는 시스템
고정된 작업자 집합, 아시다시피 시스템에서 일하는 사람들, 또는 시스템 내에서 작업을 수행하는 시스템으로 구성된 고정된 집합입니다.예를 들어 다섯 대의 머신으로 구성된 스트리밍 데이터 시스템을 상상해 볼 수 있습니다.
스트림에서 데이터를 가져오거나 스트림에서 작업 항목을 가져와서 작업을 수행한 다음
다음 작업 항목.여기서 정말 중요한 차이점은 오픈 시스템이라는 것입니다. 클라이언트의 속도가 느려지면
클라이언트를 백오프 상태로 만든다고 해서 상황이 바뀌는 것은 아닙니다.
다음 녀석이 올거야.따라서 이러한 클라이언트의 속도를 늦춘다고 해서 시스템의 부하가 줄어드는 것은 아닙니다.하지만 폐쇄형 시스템에서는
정반대의 일이 일어납니다.클라이언트의 속도를 늦추면 전체 속도가 줄어듭니다.
시스템 부하가 심하죠?그래서 아주 효과적이죠.
고객에게 “워, 워, 워, 워, 우와, 뒤로 물러나, 짐을 줄이세요”라고 말하세요.그래야 돈이 줄어들기 때문이죠.
시스템을 백오프시켜 시스템의 전체 부하를 줄입니다.따라서 이러한 차이점을 이해하고 어떤 종류인지 이해해야 합니다.
어떤 시스템을 구축했는지가 상품을 선택하는 열쇠입니다.
재시도 및 복원력 전략.현재 대부분의 시스템에는 이러한 두 가지 동작이 혼합되어 있습니다.일부 시스템도 있습니다.
완전히 개방되어 있습니다.웹 서버를 예로 들 수 있습니다.일부 시스템이 있습니다.
완전히 폐쇄된 것들이죠.하지만 시스템도 있습니다. 예를 들어 모든 시스템은
다양한 개방형 API를 포함하는 AWS의 컨트롤 플레인 API
행동, 새로운 작업이 들어오고 있는 폐쇄적 행동 (예: 고객이 앱을 운영하는 것과 같은)
클라우드 형성 템플릿 또는 API 흐름을 통한 실행.이런 하이브리드 시스템도 있습니다.그리고 모든 시스템은 어딘가에 있습니다.
이런 스펙트럼에서 말이죠.백오프는 매우 효과적입니다.
폐쇄형 시스템에서는 전략이고 개방형 시스템에서는 대부분 비효율적입니다.그나저나 지터는 언제나 좋은 아이디어죠.재시도를 할 거면 지터를 피해야 할 이유가 없다고 생각해요.지터란, n초 동안 자는 대신 0~2n초 사이의 임의의 숫자로 잠을 잔다는 것입니다.그러면 휴식을 취하는 데 도움이 되죠.
상관관계가 있는 행동을 없애버리세요.급증하는 부하를 감당하는 데 도움이 됩니다.
그리고 제 시간에 평평하게 만드세요.정말 몇 가지 해봤어요
수년에 걸친 시뮬레이션과 관련된 멋진 작업과
이러한 역동성에 대한 이해는 아마존 빌더에서 확인할 수 있습니다.
관심이 있다면 라이브러리를 이용하세요.작업을 진행해 보겠습니다. 두 번째 주제로 넘어가죠.회로 차단기는 어때?그래서 회로 차단기는
사람마다 조금씩 다르게 느껴지는 이상한 아이디어 중 하나입니다.
그것들이 무엇인지에 대한 정의.여러분도 알다시피, 전혀 다릅니다.
교과서, 웹 사이트, 참고 문헌은 회로 차단기를 정의할 수 있으며 많은 것들이 있습니다.
정의가 다릅니다.하지만 저한테는 이게 정말
언제 어디서 해야 할지 결정하는 주제는
처음으로 해봐요, 그렇죠?다 해볼까요?아니면 이걸 관찰해야 할까요?
이 다운스트림 시스템은 과부하가 걸리거나 건강에 안 좋은데 그냥 “와, 난 안 할 거야.” 라고 말하죠.
한 번 시도해 보세요, 그렇죠?그리고 그 역할을 이해하기 위해서요
시스템의 회로 차단기, 분리해야 할 것 같아요
시스템을 다른 두 개로 나누거나 회로 차단 작업을 다른 한 쌍의 구분으로 분리하세요.그 중 하나가 수확량을 줄이는 것이죠, 그렇죠?이것도 주제입니다.
몇 가지 고전적인 분산 시스템 논문에서 나온 단어입니다.여기서 의미하는 바는 불필요한 요소를 제거하는 것입니다.
가용성을 유지하기 위한 UI 요소와 같은 기능예를 들어 amazon.com을 방문하거나 AWS 콘솔을 방문하거나 대부분을 방문하면
요즘의 대형 웹 사이트에는 UI 요소가 있을 것입니다.
그건 일종의 선택 사항이고 차단하지 않는다는 것입니다.
이런 종류의 추가 정보 상자나 다른 기능을 불러올 수 있게 되면 웹 사이트를 불러오는 거죠.그리고 시스템에 과부하가 걸리거나 선택적일 때 기능을 줄인다는 이런 아이디어도
기능을 사용할 수 없는 것은 좋은 생각입니다.구할 수 있다면 맞죠?그리고 알다시피, 인간은 그런 경향이 있어요.
상당히 회복력이 있어야 하죠.좋아하는 웹사이트를 좋아한다고 해서 반드시 마음에 드는 것은 아닙니다.
위젯은 로드되지 않지만 완전히 깨지지는 않습니다.안타깝게도 API 클라이언트는
정반대죠?API 클라이언트를 보내면
API 필드의 2/3, 즉 90% 의 확률로 돌려보내면 그들은 정말 놀랄 것입니다.그리고 가끔은
전혀 예상하지 못했던 나쁜 방식으로 놀랄 거예요회로 차단기의 또 다른 경우는 부하를 거부하는 것이죠, 그렇죠?그리고 다운스트림 시스템을 지원하고 다운스트림을 구동하기 위해 업스트림 가용성을 희생하는 거죠.
시스템을 다시 성공으로 이끄세요.이건 사실 아주 흔한 일이죠.이게 아마 가장 흔하게 볼 수 있는 방법일 거예요.
분산 시스템 패턴.예를 들어, 이것은 다음 중 하나입니다.
TCP가 하는 일들이죠?TCP가 기본적으로 하는 일은 무엇인가요?
이면에는 과부하와 과부하 징후가 있는지 감시하는 기능이 있습니다.
대화하고 있는 링크는 다음과 같이 감지됩니다.
지연 시간 및 패킷 손실, 다음과 같은 경우 부하 감소
이러한 과부하 징후가 보입니다.이와 같은 종류의 패턴은 애플리케이션 수준에서 흔히 볼 수 있습니다.모든 분야에서 흔히 볼 수 있는 것이죠.
물리적 수준부터 시작하는 네트워크 프로토콜의 종류.이것도 좋은 생각입니다.하지만 리젝트에 효과적인 알고리즘은
하중을 가하는 알고리즘은 종종 하중을 받는 알고리즘과 다릅니다.
수확량을 줄이는 데 좋습니다.그리고 근본적으로 수질을 떨어뜨리죠.
고객에 대한 서비스, 그렇죠?그들은 관대하게 이렇게 말하죠. 음, 제 생각엔 이 시스템인 것 같아요.
부하가 너무 심해요. 속도를 늦추고 더 나쁜 시간을 보내서 우리 모두가 회복할 수 있도록 돕고 우리 모두가 공유할 수 있도록 도와줄 거예요
이 자원도 마찬가지입니다.따라서 이런 종류의 회로 차단기를 사용하면 시스템이 혼잡을 피하고 과도한 대기 시간을 피할 수 있습니다.
또는 높은 혼잡으로 인한 과도한 장애 발생 시 빠른 복구를 위해
울혈성 위축증, 그러니까 꽤 괜찮은 방법이죠.하지만 그들에겐
몇 가지 큰 단점이 있습니다.그 중 하나는 줄일 수 있다는 것입니다.
샤딩 시스템의 가용성.자, 여기 제 고객이 있다고 상상해 보세요.
서비스와 통신하는 회로 차단기를 달았죠.실패율이 10% 를 넘으면 회로 차단기를 작동시켜 요청 전송을 중단하겠다는 논리를 구현했습니다.그리고 이제 저는 이 샤드 시스템을 만들었습니다. 시스템을 해체하는 시스템이죠.
데이터를 여러 조각으로 나누는데 그 중 세 부분이
완벽하게 잘 작동하고 있는데 하나는 실패했습니다.이 경우 어떻게 되는 거죠?그럼, 제 의뢰인이
이걸 보고 말해보세요. 실패율이 25% 에 달해요.트래픽을 보내면 안 돼요
이 서비스에 전혀 도움이 됐어요그래서 우리가 기본적으로 가지고 있는 것은
이 알고리즘으로 25% 의 실패율을 100% 의 실패율로 바꿨습니다.그리고 그건 꽤 안 좋은 일이죠.그리고 이런 종류의 조각들은
시스템은 대규모 분산 시스템에서 매우 흔합니다.예를 들어, 다음과 같이 할 수 있습니다.
DynamoDB 담당자가 작성한 이 백서를 읽어 보십시오.이는 2022년 유세닉스 ATC ATC에서 있었던 일입니다.훌륭한 논문이 하나 있습니다.
이를 통해 아키텍처에 대해 아주 깊이 파고들 수 있고
DynamoDB의 설계 선택.그리고 DynamoDB는 정확히 하나입니다.
이러한 샤딩 시스템 중 하나입니다.그리고 이 모든 것들과 함께
DynamoDB, Aurora DSQL과 같은 샤딩된 데이터베이스의 종류.셔츠를 확인해 볼 수 있습니다.어제 출시한 Aurora DSQL은 회로 차단기가 단순하여 클라이언트 가용성이 떨어집니다.
이러한 시스템에서는 말이죠.또 다른 나쁜 사례가 있습니다.회로 차단기는 SOA 및 마이크로서비스 아키텍처에서 폭발 반경을 확장할 수 있습니다.여기 마이크로서비스 트리를 통해 API A, B, C, D를 제공하는 서비스가 있습니다. 각 API에는
몇 가지 의존성.그리고 여기서 살펴본 적이 있습니다.
API C의 의존성에만 문제가 있다는 것은 A가 작동하고, B가 작동하고, D가 작동한다는 것입니다.
그들은 여전히 행복합니다.하지만 순진한 서킷 브레이커
이 시스템 위에 있는 걸 보면, 글쎄요, 오류가 보이네요.각 API의 로드가 같으면 25% 의 실패를 볼 수 있습니다. 저는 물러서겠습니다.다시 말씀드리지만, 여기서 한 일은 전송을 중단했다는 것입니다.
API A로 향하는 트래픽은 완전히, 완전히 불필요하죠?따라서 회로 차단기를 사용할 경우 발생할 수 있는 위험이자 단점입니다.그러면 어떤 교훈을 얻을 수 있을까요?
여기서 벗어날 수 있을까요?저는 바이너리를 피하는 편이에요
온/오프 회로 차단기.이런 종류의 것들은 X 위를 넘어가면 멈춥니다.
Y로 돌아가면 아예 트래픽을 보내죠.
트래픽 전송을 시작하세요.동적 행동이 좋지 않아 이런 단점이 있습니다.
회로 차단기가 더 심해졌어요.저는 가산 증가 같은 알고리즘을 더 좋아해요.
TCP 내부에 있는 승산 감소 알고리즘으로, 자동으로 조정됩니다.
다운스트림 기능까지.이러한 알고리즘은 이해하고 추론하기가 약간 어렵지만 구현하기는 매우 쉽습니다.그리고 시뮬레이션과 테스트
실제로 도움이 되는 방식으로 구현했는지 여부를 파악할 수 있는 좋은 방법입니다.
시스템의 가용성.폭발 반경이 큰 회로 차단기를 피하십시오.단순한 오류율이나 지연 시간을 기준으로 하여 시스템의 많은 부분을 끄는 회로 차단기를 구축하지 마십시오. 끌 필요가 없는 장치도 꺼질 수 있기 때문입니다.그리고 마침내 성공적인 회로가 탄생했습니다.
차단기는 다음과 같은 내부 세부 정보를 알아야 할 수도 있습니다.
올바른 결정을 내리기 위한 다운스트림 서비스.여기 앉아서 이렇게 생각하고 계신다면, 아, 진짜처럼 들리네요.
일종의 겹겹이 위배되는 일인데, 그런 짓을 하는 게 좀 지겨워요.네, 그래야죠. 그리고 그건 별로예요.하지만 실제로는 시스템에 정말 도움이 될 수 있습니다.그래서 이건 꼭 해야 할 일이죠.
회로 차단기를 구현할 때 정말 깊이 생각해 보세요. 레이어링을 일부 망가뜨리는 것 같은 나쁜 일을 하는 건 아닌지 말이죠.
클라이언트에 서비스를 구현하면 클라이언트가 훨씬 더 나은 결정을 내리지 못할 수도 있습니다.그리고 앉아본 적이 있다면
집에서 폭풍우, 특히 폭풍우가 몰아칠 때 조명이 꺼지고, 깜박거리고, 다시 켜졌어요. 바로 이런 이유 때문이죠.
리클로저라고 불리는 것들이죠.배전 네트워크 내의 회로 차단기를 자동화했죠.그리고 그 유일한 방법은
정말 잘 작동하는 이유는 다운스트림의 토폴로지와 보호 대상에 대해 깊이 알고 있기 때문입니다.이것이 훌륭한 교훈입니다.
일부 물리적 인프라.좋아요, 다음으로 넘어가죠.
테일 레이턴시와 그 중 몇 가지에 대해 이야기해 보세요.
서비스의 테일 레이턴시에 대해 하고 싶을지도 모르겠네요.하지만 그 전에 어떤 것들이 있는지 먼저 합의해 보도록 하죠.
실제로 얘기하고 있는 건데요.다음은 누적값입니다.
실제 AWS 마이크로서비스의 지연 시간 밀도 플롯.익숙하지 않다면
누적 밀도 플롯에 대해 조금 설명해 보죠.
이걸 읽는 방법을 좀 알려드릴게요.따라서 x축에는 지연 시간이 있습니다.이것은 단지 시간일 뿐입니다.
클라이언트의 관점에서 대응하려면 서비스가 필요하다는 거죠.그리고 y축에는 이 시간 이하의 시간이 소요되는 요청의 비율이 표시됩니다.이런 종류의 도표의 멋진 점은 직접 할 수 있다는 것입니다.
관심 있는 백분위수에서 수평선을 가져와 어디에 있는지 찾아내서 백분위수를 읽어 보세요.
빨간색 선과 교차합니다.따라서 수평선을 취하면
0.5부터 선을 그어서 그 위에 그립니다.
빨간색 선에 도달하기 전까지는 중앙값입니다.
50번째 백분위수제가 가장 좋아하는 시각화하고 생각하는 방식이에요.
서비스의 지연 시간은 히스토그램보다 훨씬 더 많은데, 사실 읽기가 다소 어렵습니다.이것은 정보 밀도가 매우 높지만 서비스의 지연 시간을 나타내는 매우 직관적인 방법이기도 합니다.여기서 볼 수 있는 것은 이 서비스가 꽤 빠르다는 것입니다. 그렇죠?대부분의 경우 평균, 중간값이 반응합니다.
겨우 1밀리초 남짓한 시간에 말이죠.99.99의 백분위수에서는 가장 느리다는 뜻입니다.
10,000개의 요청 중 8 1/2밀리초로 응답합니다.꽤 빠르긴 한데 꼬리가 좀 있잖아요, 그렇죠?10,000번째 요청은
평균 요청보다 거의 8배 느립니다.그럼 이제 다음과 같은 동작에 대한 직관을 만들어 보겠습니다.
서비스의 꼬리.먼저 말씀드리자면, 이걸 부르면 어떨까요?
100번 연속으로 서비스를 제공하고, 한 번 호출하고, 응답을 기다리고, 두 번 호출하고, 응답을 기다립니다. 100번째 실행은 얼마나 걸릴까요?학교나 대학교에서 통계를 읽어 보신 분들은 적용할 수 있다고 하실 겁니다.
기대치의 선형성과 말하자면 평균은
예전보다 100배 더 많죠.백분위수는 더 어려워요.추론하기가 더 어려워요.이렇게 좋은 규칙은 없어요. 약간씩 있기 때문이죠.
분포가 좀 이상하네요.이건 정상이 아니에요. 로그도 아니에요
정상이야. 제대로 동작하지 않았어.그래서 우리는 해야 할 거예요.
다른 기법을 적용해 보세요.뭐가 뭔지 말해줄게
기술은 1분 후에 나옵니다. 먼저 답을 알려드릴게요.전화를 통해 우리가 보게 되는 것은
이 100번 연속해서 보면 평균과 중위수가 올라갔고, 평균은 정확히 100배 올라갔고, 중위수는 올라갔습니다.
거의 정확히 100배 올랐지만 p99.99는 겨우 24배만 올랐습니다.따라서 100번 호출할 때의 꼬리는 이 특정 분포에서 한 번 호출하는 것보다 약간 더 평평합니다.이것이 진정한 분포입니다.
웹사이트 지연 시간, 죄송합니다. 웹 서비스 지연 시간이죠.약간 직관적이지 않을 수도 있겠죠?생각하실 수도 있겠지만, 만약 제가 뭔가를 할 거라면
100번 연속으로, 분명 볼 수 있을 거야
이런 느린 요청들이 많아서 전반적으로 만족스러울 거예요.
물체의 꼬리는 가벼운 것보다는 무겁습니다.그리고 이게 가장 중요한 포인트가 되는 부분인데요
꼬리의 행동을 이해하기 위해 계산을 해보는 것이 중요하죠.이제 다른 질문을 해봅시다.이걸 100번 병렬로 하면 어떨까요?100개의 작업 단위가 아니라 완전히 독립적이기 때문에 모두 서비스 부서에 보내고 모두 돌려받고 모두 돌아올 때까지 기다리겠습니다.이게 이 배포판의 형태에 어떤 영향을 미칠 것 같나요?어떻게 생각해요?
100번째 기다림의 분포는 어떻게 될까요?글쎄요, 평균이 예전의 4배, 5배까지 올라간다는 게 밝혀졌습니다.p99는 아래까지만 올라갑니다.
예전의 12배.그리고 p99.99도 그 정도입니다.
전보다 12배 더 높습니다.다시 말씀드리지만, 우리가 가진 것은
다음은 꼬리가 더 가벼운 분포입니다.
더 무거운 것보다는 그렇죠?특이치가 더 적은 것 처럼요.이게 더 직관적인 것 같아요.제 생각에는 이게 제 것과 맞는 것 같아요.
직감이 사고하는 게 낫죠. 뭐, 많이 보내면
병렬로 나와서 가장 느린 것이 나올 때까지 기다리세요. 음, 아마도 가장 느린 것일지도 몰라요.
하나는 느릴 거예요. 하지만 저는 이 작업을 병렬로 하고 있으니 속도가 빠를 거예요.몰라요, 저한테는 직관적인 것 같아요.좋아요.그럼 첫 번째 이야기를 해볼까요?
꼬리를 평평하게 만드는 도구.요청을 두 번 보내고 첫 번째 요청을 사용할 거예요
두 개의 응답 중이것이 지연 시간 분포에 어떤 영향을 미칠 것이라고 생각하나요?이를 헤징이라고도 합니다.사실 세상에는 헤징이라고 하는 것이 두 가지 있습니다.하지만 이건 단순한 패턴이에요. 그냥 모든 걸 두 번 쏘아 버리겠다는 거죠.그리고 첫 번째 것이 돌아오면 두 번째 것은 잊어버리고 먼저 나온 것을 사용할 거예요.이게 우리에게 무슨 영향을 미치나요?
지연 시간 분포?글쎄요, 그다지 큰 문제는 아니죠.
평균과 중위수, 그렇죠?1밀리초 남짓으로 남았습니다.20~ 30% 정도 더 좋아졌어요.하지만 제가 더 나아졌어요.
네 나인 행동이 60% 나 됐는데, 꽤 중요한 거죠?예를 들어 이 서비스가 이상치 지연 시간이 걱정되는 서비스이고 클라이언트와 고객이 이상치 지연 시간을 정말 걱정한다면 66% 감소할 수 있습니다.
정말 좋은 일이네요.이제 기억하세요, 제가 하고 있는 중이에요
그 66% 를 받는 대가로 여기서 일을 두 배로 늘려요. 하지만 아마도 이거일 수도 있습니다.
66% 할인을 받을 수 있는 다른 방법들에 비하면 여전히 훨씬 저렴합니다.이것이 바로 비용입니다.
처리량은 두 배이고 요청 볼륨은 두 배입니다.어쩌면 대단한 일일지도 몰라요.별거 아닐 수도 있어요.시스템의 경제성에 대해 생각해보고, 꼬리를 평평하게 만드는 대가로 그게 그만한 가치가 있는지 생각해 볼 수 있는 건 오직 당신만이 할 수 있는 일이죠.그리고 제가 말씀드리자면, 저는
이 그래프에서 p99.99까지 올라간 것은 1만 명 중 한 명뿐입니다.하지만 유형 지연 시간이 백만 분의 1과 같이 훨씬 더 높은 이상치가 있는 경우에는 이 방법이 훨씬 더 효과적일 수 있습니다.이러한 결과를 거의 모두 만들 수 있습니다.
고객에게는 보이지 않죠. 이건 정말 좋은 특성이죠.두 번째 도구는 다음과 같습니다.우린 변할 거예요.원하지 않는다고 말할게요
매번 두 배씩 내야죠.우린 돈만 낼 거예요
시간을 두 배로 늘려요그래서 요청을 하나 보낼게요.곧 다시 돌아오지 않을 경우, 곧 다시 정의하자면, 다시 요청을 보내서 다음 중 하나를 사용하겠습니다.
그들이 먼저 돌아옵니다.이제 우리는 이렇게 생각할 수도 있겠죠. 이봐, 이거 정말 잘 될 거야, 그렇죠?교통량을 두 배로 늘리는 것을 막을 수 있을 거예요.이런 느린 것들은 비교적 드물게 일어날 거예요, 그렇죠?임계값을 90% 로 설정하면 10% 의 확률만 발생할 수 있습니다.그리고 우리는 여전히
꼬리를 납작하게 만들고 멀리 떨어진 이상값을 제거할 수 있어야 합니다.멋진 테크닉, 좋은 물건이네요.결과는 다음과 같습니다.
그런 것 같네요.다시 말씀드리지만, 아무 효과가 없었어요.
평균과 중위수에 대해 말씀드리자면, 아직은
이들에게 요청을 하나 보낸다는 거죠.그리고 우리는 일어났습니다.
90번째 백분위수까지 올라갔고 이미
바깥의 것들을 평평하게 만들었죠.거래소에서도 마찬가지고요.
10% 의 추가 트래픽에 대해 저희는 비용을 줄였습니다.
99.99백분위수를 54% 까지 올렸습니다.정말 멋지네요.훌륭하고 좋은 기술이에요.어서 실행해 봅시다.글쎄요, 아닐 수도 있습니다.여기서 문제가 되는 건
다시 말씀드리지만 안정성과 준안정성에 대해 말씀드리겠습니다.
실패 모드 맞죠?만약 너라면 어떻게 될 거야?
결국엔 이 기법을 쓰세요. 특히 이 기법의 비적응형 버전을 사용하면 서비스가 느려질까요?
어떤 이유에서든 다운되죠.마치 약간이라도
대화를 시작했을 때 너무 과부하가 걸렸어요무슨 이유에서든 느려질 거예요그리고 갑자기 대신
10% 추가 요청을 보내면 트래픽이 두 배로 늘어납니다.이제 그렇게 하라고 하셨잖아요
너무 과로한 서비스, 아니, 우리에게 일을 맡기세요.
훨씬 더 과부하가 걸려요내려가세요, 다시 올라오지 마세요, 그렇죠?그리고 우린 차지 않아요
서비스가 다운되면 그냥
우리 모두에게 역효과를 가져다주죠.그래서 저는 이 기법을 별로 안 좋아해요.그리고 저는 이런 방식 때문에 이 기법을 별로 좋아하지 않아요.대단해 보이긴 하지만
언뜻 보면 매력적입니다.이제 이 문제를 해결할 수 없습니다.
토큰 버킷 접근법과 같은 토큰 버킷 사용
예전에는 재시도를 수정했는데, 이로 인해 좀 더 복잡해졌습니다.
전체 시스템에 적용했지만 이러한 준안정 장애 모드 중 최악의 경우를 피할 수 있었습니다.여기 또 다른 보조 도구인 이레이저 코딩이 있습니다.임의의 API로는 이 작업을 수행할 수 없지만 스토리지에서는 할 수 있습니다.
시스템과 캐시에서.그리고 이레이저 코딩에 대해서는 자세히 다루지는 않겠지만 정말 대단합니다.
흥미로운 수학 분야인데, N을 보낼 수 있게 해줘요.
요청을 시스템으로 내보내고 응답을 취합합니다.
예를 들어 첫 k부터
6개를 보낼 수 있는 방식으로 시스템을 설계하세요.
네 개의 요청이 있는 시스템에 요청을 보내면 올바른 결과를 모을 수 있습니다.이것은 유비쿼터스입니다.
스토리지 시스템의 패턴.어디에나 있는 패턴입니다.
일종의 캐시 시스템.오래 전부터 존재해왔죠.하지만 활용도가 낮은 것 같아요.
분산 시스템, 특히 분산 시스템에서
변경할 수 없는 데이터 캐시.그래서 여기 비용은 없습니다.
요청률의 곱셈이죠?N개의 요청을 보내고 있기 때문이죠.따라서 비용이 많이 드는지 아닌지는 사용자 여부에 따라 달라집니다.
요청 속도 제한인가요, 처리량 제한인가요?N은 대역폭의 k배 이상이고 추가 스토리지의 k배보다 N입니다. 다양한 인코딩을 저장해야 하기 때문입니다.
각 데이터 조각들이죠.하지만 이는 지속적인 작업입니다.왜냐하면 여러분은 할 수 있기 때문이죠.
N과 k를 임의로 제어할 수 있는 유일한 규칙은 k가 할 수 없다는 것입니다. 아시다시피
N보다 작거나 같거나, 노브를 돌릴 수 있기 때문에 경제성과 성능에 맞춰 임의로 조정할 수 있습니다.
시스템의 목표.그리고 정말, 엄청 효과적이죠, 그렇죠?한 짓을 하는 대가로
약간의 추가 작업이 필요하면 임의로 적은 양의 작업도 할 수 있습니다. 꼬리 부분까지 내려갈 수 있죠.그리고 우리가 보냈기 때문에 꼬리 부분을 아래로 내릴 수 있습니다.
요청이 여섯개나 된다고 하던데그리고 가장 느린 두 가지 이유는, 그럴 필요가 없다는 거죠.
잠시만 기다리세요, 그렇죠?그래서 이것은 AWS의 여러 곳에서 사용하는 기술입니다.말씀드렸듯이 어디에나 있습니다.
스토리지 시스템에서 말이죠.하지만 제가 설치하면서 정말 즐거웠던 부분 중 하나는 컨테이너 적재 작업이었습니다.
AWS Lambda의 시스템.이것은 우리가 작성한 논문입니다.
작년 유즈닉스 ATC에 대해서요.여기서는 컨테이너를 추가한 방법에 대해 자세히 설명합니다.
Lambda를 지원하고 콜드 스타트 지연 시간을 늘리지 않고도 40배 더 큰 아티팩트를 지원할 수 있는 데이터 플레인을 구축했습니다.정말 재미있게 작업할 수 있는 시스템입니다.우리가 했던 핵심 방법 중 하나는 시스템을 구축하는 것이었습니다.
계층형 캐시의 삭제 코딩을 기반으로 하는데, 이는 꼬리를 평평하게 만드는 데 정말 도움이 됩니다.그래서 AWS Lambda의 컨테이너 데이터 플레인에 삭제 코딩을 구축한 결과 그 중요성이 드러났습니다.
테일 레이턴시의 이점을 그래프에서 보여드렸습니다.하지만 실제로 본 것도 몇 가지 있습니다.
쿨 레질리언스 혜택은 다음과 같은 또 다른 이점입니다.
이런 기법들이 많이 있습니다.둘 다 전송 방식이죠.
요청 기법과 삭제 코딩 기법, 심지어 요청을 보낼 수도 있습니다.
오래 기다린 기법 끝에이를 통해 한 대의 서버나 한 구성 요소가 작동하지 않을 경우 시스템의 복원력이 훨씬 향상됩니다.그에 따른 이점은 비교적 간단한 클라이언트 측 알고리즘 변경에 대한 대가로 이미 배포를 완료했다는 것입니다.
스토리가 훨씬 쉬워졌어요.얼마나 빨리 찾아야 하는지에 대한 운영 스토리를 만들어 주셨습니다.
그리고 불량 서버에 대한 대응도 훨씬 쉬워졌죠?문제가 되기까지는 아직 시간이 많이 남았으니까요.
고객이 볼 수 있습니다.대규모 운영을 할 때 정말 어려운 점 중 하나는
고가용성 서비스를 운영할 수 있을까요?
배포와 같은 작업스토리지 플릿이 있는 경우
그냥 샤딩됐어요. 배포가 정말 어려워요.배포는 정말 어렵습니다. 왜냐하면 제가 직접 해야하기 때문이죠.
새 소프트웨어를 설치하는 동안 스토리지 서버가 다운되는 시간이 몇 밀리초에서 몇 분까지 걸릴 수 있습니다.하지만 제가 삭제 코딩을 할 수 있다면, 잘 모르겠어요.
최적화가 필요해요. 다운된 동안에는 잠시 다운될 수 있지만 제 클라이언트는 필요한 결과를 얻을 수 있을 테니까요.
시스템의 다른 곳에서요.저도 이레이저 코딩을 좋아해요.
왜냐하면 계속 해야 하는 일이니까요.성공 사례와 실패 사례에서 같은 양의 작업을 수행합니다.만약 여러분이 계속 주의를 기울여 왔다면, 뭐, 그건 일종의
이 강연의 주제가 맞죠?더 이상 하고 싶지 않으세요?
실패 사례를 대비해서 작업하세요.너도 똑같이 하고 싶어
성공하거나 실패했을 때 항상 해야 하는 작업량.그리고 할 수 있다면 꼭 해봐야 할 일이죠.
장애 시 작업량이 줄어들죠.Lambda는 매우 간단한 4/5 코드를 사용합니다.즉, 다섯 개를 전송한다는 뜻입니다.
요청은 처음 네 개를 사용합니다.이 코드는 패리티와 비슷한 단순한 코드라는 것이 밝혀졌습니다.하지만 모두의 필요에 맞는 삭제 코드가 있습니다.
시스템 및 규모에 상관 없습니다.상대적으로 계산 비용이 저렴합니다.그래서 멋진 도구죠.이에 대해 많은 이야기를 나눴습니다.
이 강연에서는 준안정성에 대해 이렇게 생각할 수도 있습니다.
이 단어가 뭐죠?그나저나 무슨 말인지 알죠?그럼 부하가 걸린 시스템의 동작에 대해 조금 얘기해 보죠.이 슬라이드는 여러분이 보고 있는 슬라이드입니다. 여러분은 상사에게 당신이 보고 있는 것을 보여주고 있는 것입니다.
시스템 연구 논문, 지금 보시는 것처럼
그 성능을 보여주는 시스템 공급업체는
오른쪽으로 올라갑니다.부하를 늘리면 더 많은 성공을 거둘 수 있습니다.부하를 늘리면 더 많은 성공을 거둘 수 있습니다.우리 모두는 우리 시스템이 좋기를 바랍니다.
사실 이런 식으로 행동하세요.더 많은 부하를 가하면
더 많은 성공 등등.하지만 현실은
그런 건 아니에요.거의 현실은
모든 분산 시스템, 그리고 제 생각에는 말 그대로 전부가
단일 기계 시스템이란 게 의미가 있어요.
부하를 더 추가하면 성공률이 떨어집니다.더 많은 경합을 이끌어낼 수 있습니다.인터페이스에서 패킷 손실이 발생합니다.캐시를 스래싱 인할 수 있습니다.스케줄러의 스래싱을 유도합니다.너무 많은 스레드를 구동합니다.부하를 더 추가하면 시스템의 작업 성공률이 낮아지는 경우가 있습니다.그리고 이 시점부터 문제가 생기기 시작합니다.왜냐하면 지금 우리가 원하는 것은 이런 상황이 전혀 마음에 들지 않습니다. 하지만 여기서 우리가 원하는 것은 그 시점에 이르렀을 때 부하를 줄이면 길을 잘 따라가죠. 일종의 오르막길로 되돌아가서 더 많은 성공을 거둘 수 있다는 거죠.
짐은 다시 내려갑니다.하지만 세 번의 재시도로 시스템을 중단시킨 첫 번째 슬라이드에서 보았듯이, 안타깝게도 많은 종류의 시스템에서는 이런 일이 일어나지 않습니다.안타깝게도 어떤 일이 일어날까요
대신 부하가 올라가는데 그 다음엔 해야 하는 거죠.
시스템이 복구되기 전에 부하를 줄이세요.그 간단한 재시도에서
제가 보여드린 슬라이드는 클라이언트를 데려와야 합니다.
로드 시 시스템이 복구되기 전에 원래 성공했던 성능의 30% 까지 떨어뜨릴 수 있습니다.다시 말씀드리지만, 우리는 그것을 모를 수도 있고 보지 못할 수도 있습니다.
일반적인 그래프에서도 볼 수 있겠지만, 대다수의 시스템이 이런 행동을 하고 있지요?줄여야 할 부분이 있다면
부하가 예전보다 낮고 최적 부하보다 낮아 시스템이 정상 작동 상태로 복구될 수 있습니다.그럼 그 모습은 다음과 같습니다. 그렇죠?우린 정상적으로 수술하고 있어요
위아래로, 위아래로.이것이 우리의 일상 업무입니다.항상 이 모드로 뛰고 싶어요.그러면 시스템이 포화상태에 빠지는 시점이 오겠죠?모든 통화가 바쁘고, 캐시가 최적으로 꽉 찼다는 식이죠.이제 시작하실 차례입니다.
실패율이 증가하고, 지연 시간이 늘어나고, 성공률이 떨어지기 시작하는 것을 볼 수 있습니다.그런 다음 a를 입력합니다.
더 많은 작업, 더 많은 오퍼링 로드, 클라이언트의 더 많은 요청이 이루어지는 진정한 포화 모드
진행 상황이 줄어듭니다.다시 말씀드리지만, 캐시의 스래싱, 스케줄러의 스래싱, 너무 많은 스레드, 네트워크 인터페이스에서의 패킷 손실, 포화된 스토리지 디바이스, 맞죠?패턴은 매우 다양합니다. 시스템도 다양하고, 현상도 다양합니다.
같은 행동으로 이어지죠.이제 이 문제에 빠져들게 되었죠.
나쁜 다운스테이트죠.첫 번째 슬라이드에서 살펴본 것처럼 재시도가 현재 보류되고 있다는 것을 종종 보게 될 것입니다.
포화, 스래싱, 경합, 잠금 경합, 래치 경합 상태인 시스템이 시스템을 유지하고 있습니다.
채도 모드에서.그런 다음 부하를 줄여야 합니다.
재시도 횟수가 줄어들고 성공이 돌아오기 전에 시스템이 복구될 수 있습니다.
일반적인 동작과 같습니다.다시 말씀드리지만, 제 생각엔 어떤 사람들에게는 공상 과학 소설처럼 들릴 것 같지만, 아마도 이게 가장 많을 것입니다.
제가 보아온 유비쿼터스 패턴은 오랫동안 정전이 일어난 뒤에서 볼 수 있었습니다.
대규모 시스템.이게 어떻게 된 건지 모르겠어요.알겠어요.모르겠어요.왜 이런 걸 받는 건지 모르겠어요, 미안해요여기 미끄럼 문제가 좀 있어요여기서 무슨 일이 벌어지고 있는지 모르겠어요.아무튼.그래서 열린 공간도
이 그래프 안에는 제가 메타안정성이라고 부르는 것이 나와 있습니다.시스템의 과부하 특성인 경우, 시스템을 다음과 같이 구동하면
그래프 안에 과부하 후 복구 시 열린 영역이 있으면 메타테이블 (metastable) 이 나타납니다.
시스템에 동작이 일어나면 오래 걸리고 고통스러우며 스스로 회복하지 못할 위험이 있습니다.
부하 관련 정전.그리고 거의 모든 시스템이 일종의 모범 사례를 따르고 있습니다.
재시도 구현, 특히 다음과 같은 경우
재시도는 적응적이지 않습니다. 이런 종류의 동작도 있습니다.가장 많은 방법 중 하나입니다.
생각해 보면 이해해야 할 중요한 사항
시스템의 탄력성.자, 이제 조금 더 살펴보죠.
이 숫자의 출처가 어디인지, 어떻게 하면 시스템의 동작을 더 잘 이해할 수 있는지와 같은 조금 다른 주제를 다루겠습니다.행동을 이해하는 데 제가 가장 좋아하는 기법
시스템은 시뮬레이션입니다.저는 아주 간단하게 글을 쓰는 걸 좋아해요.
작은 이벤트 기반 시뮬레이터는 주로 R 또는 Python과 같이 다양한 언어를 사용하며 다양한 언어를 사용합니다.
시스템 동작 영역.동적 동작에 대한 제 직감은
시스템은 사실 꽤 형편없는데 아직 배우지 못했어요.
그걸 아주 잘 믿으라는 거요.직감이 더 좋아질 수도 있습니다.그랬으면 좋겠어요.그래서 시뮬레이션은 제가 탐구할 수 있게 해주는 도구라는 걸 알게 되었어요.
시스템의 동작.몇 가지 예를 들어보죠.그럼 이 그래프의 출처는 어디일까요?제가 어디서, 어떻게 했냐면
66% 낮게 계산했는데요?뭐, 제가 할 수 있는 한 가지 방법이 있어요
뭐 그런 식으로 해봤는데, 전 몰라요
뭐, 파라메트릭 통계.분포를 맞출 수도 있었을 텐데
이 지연 곡선에 말이죠.계산을 많이 할 수도 있었죠.우리는 아주 강력한 기술을 모두 사용했어요.이런 자의적 분포의 경우, 제 능력도 초월하고 제가 아는 것도 초월하는 일이죠.하지만 훨씬 쉬운 방법이 있습니다.그리고 그것은 a를 사용하는 것입니다.
시뮬레이션 방법 맞죠?그 진짜를 어디서 가져갈 수 있죠?
데이터는 실제 CDF를 가져와서 모니터링 인프라와 옵저버빌리티 인프라에서 실제 지연 시간 샘플을 가져옵니다.분포나 그 어떤 것에도 맞추려는 시도는 하지 않아도 됩니다.상자에서 꺼내 바로 사용할 수 있습니다.그래서 제가 여기서 한 것은 데이터 샘플 다섯 개를 골라낸 것입니다.방금 엄청난 양을 다 가져갔어요
서비스에서 가져온 데이터 샘플.무작위로 다섯 개를 골랐어요.그리고 저는 네 번째로 좋은 것을 골랐어요.그걸 반복해서 해봤고
몇 번이고 반복해서 결과를 기록했습니다.그 결과 출력 CDF를 기록했습니다.따라서 분포를 맞추는 것과 같은 것은 전혀 없습니다.
이런 식으로 제가 할 수 있었던 것은 실제 지연 시간 측정치를 사용하여 시스템의 실제 동작을 계산하는 것이었습니다.지연 시간이 로그 정상이거나 지연 시간이 뭐냐고 가정할 필요는 없겠죠?실제 측정치를 사용할 수 있어요.엄청 강력해요.
아주 간단한 기법이죠.이건 말 그대로
세 줄의 파이썬.따라서 그럴 필요가 없습니다.
분포를 선택하고, 분포를 맞추고, 구현하려면
적합도 검정.그리고 저는 그 방법들에 반대하지 않아요, 그렇죠?그들한테는 아무 문제가 없어요.하지만 그들은 여러분에게 필요한 것을 요구합니다.
몇 가지 가정을 해 보세요. 그러려면 안타깝게도 대부분의 기술이 필요합니다.
소프트웨어 엔지니어, 디자인, 기억나지 않아요.알다시피, 아마도
대학 때 이런 걸 배웠지만 사용할 수는 없잖아요.그래서 안타깝게도 제 생각에는
산업으로서 우리가 해낸 것은 마치 이런 상황에 빠진 것 같았다는 것입니다.
저희가 말씀드렸듯이, 음, 어떻게 해야할지 기억이 안 나네요.
그 통계 도구를 사용하세요.그냥 통계가 좀 무서워서 그냥 아니에요
이런 것들을 측정하고 생각해 볼 거예요.제 생각엔 이런 종류의 것 같아요.
시뮬레이션 방법은 정말 좋은 방법이에요. 간단한 덧셈과
동작을 이해하기 위한 곱셈 등등
같은 수준의 상징적 정교함을 요구하지 않아도 우리 시스템의 성능이 더 좋아집니다.다시 말씀드리지만, 아시다시피, 어디에
이 그래프의 출처가 맞나요?제가 어떻게 이해했을까요?
이 시스템의 동작은요?글쎄요, 다시 한 번 제가 썼습니다.
간단한 시스템 시뮬레이션.이것은 마치 파이썬의 한 조각과 같습니다.이것은 약 100줄, 약 50줄의 명령과 시스템을 직접 모델링하는 약 100줄의 코드로 이루어져 있습니다.마치 객체 지향적인 서버 객체와 같습니다.
그리고 몇몇 클라이언트 객체들은 서로 요청을 보냅니다.그리고 이것의 정말 멋진 점은 검토하기가 매우 쉽다는 것입니다. 그렇죠?정말 간단한 일들을 할 수 있는 아주 간단한 코드죠.팀의 어떤 엔지니어에게든 보낼 수 있습니다. 그러면 엔지니어들은 기꺼이 검토하고 이해할 수 있습니다.그리고 나서 제가 말씀드릴 수 있는 것은, 이런 것들을 조정할 수 있고, 재시도를 추가할 수 있다는 것입니다.
적응형 재시도를 추가할 수 있습니다. 몇 개만 바꿔서 세 번 재시도하는 대신 두 번 시도할 수 있어요.
이 코드 몇 줄.이렇게 하면 엄청난 금액을 절약할 수 있습니다.
시스템 설계자로서 시간을 할애할 수 있어요. 제 시스템의 파라미터와 행동 공간을 탐색할 수 있으니까요.
시스템은 매우 역동적입니다.이런 종류의 시뮬레이션
기법은 위장되어 있습니다.그리고 너무 위장되어 있어서
사람들은 그걸 보고 말하죠. 음, 그건 진짜인 것 같지 않아요.또 다른 예를 들어보죠.
제가 시뮬레이션을 좋아하는 분야죠.Nudge라는 훌륭한 논문인데, 어떤 식으로든
선착순 대기열 시스템의 테일 레이턴시 개선.알고리즘은 다루지 않을게요.아주 재밌는 논문이네요. 어떤 내용이 있으시다면 꼭 읽어 보세요.
구축하려는 시스템의 대기열 또는 작업 대기열 시스템.하지만 제 질문에 대해 말씀드리자면
제 머릿속엔, 글쎄요, 제가 읽은 이 기법은
시스템 논문이 저널에 실렸는데, 그게 정말 저에게 도움이 될까요?
시스템, 그리고 고객, 아니면 제가 자리를 떠날까요?
코드를 잔뜩 작성했는데 배포해도 개선이 보이지 않나요?글쎄요, 저는 그렇게 하고 싶지 않아요.프로덕션 코드를 작성하려면 시간이 걸려요.코드 배포는 위험하고 시간도 많이 걸립니다.상황이 더 나빠지면 어떡하지?
그럼 난, 알다시피, 안 좋은 하루를 보내고 난
제 고객들을 실망시키세요.그리고 아무도 그걸 원하지 않아요.다시 한 번 말씀드리지만, 아주 단순한 종류의 객체 지향 구조를 만들어 보겠습니다.
제 시스템에서의 시스템 시뮬레이션, 제가 할 수 있는 일, 그리고 코드도 알아냈어요.
관심이 있으시다면 GitHub에 올려두세요. 제가 할 수 있는 일은 제 매개변수로 말하자면
시스템, 실제 지연 시간, 클라이언트 동작 및 요청 크기의 실제 분포를 고려하면 시스템에 도움이 될까요?그리고 제가 배운 것은
제가 시뮬레이션을 해봤는데 사실, 맞아요.네, 정말 그래요.정말 도움이 돼요
꼬리를 납작하게 만들어주는 여러 가지 방법이 있죠.그러니 그만한 가치가 있을 거예요
제 시스템에 맞게 구현하고 있어요.그리고 이게 한 시간도 안 걸렸어요.
이 코드를 작성하기 위해서요.아시다시피, 새 대기열을 만드는 작업을 몇 주 동안 지휘했었죠.
우리 시스템의 규율.만약 대답이 '아니오'였다면, 이건 도움이 안 될 거예요. 우리가 살릴 수 있었을 거예요.
몇 주 걸렸어요정말 멋지네요.정량적으로 정확한 답을 얻을 수 있습니다.
답변이 훨씬 더 빨라졌습니다.그리고 운 좋게도 이보다 더 빠른 방법이 있습니다.
요즘에는 그렇게 할 수 있는 방법이 있죠.바로 AI 세대입니다.모두가 그렇게 얘기하고 있잖아요.제가 가지고 있는 것 중 하나는
아주 잘 작동한다는 걸 배웠어요. 이런 글을 쓰는 거예요.
시뮬레이션에 대한 설명을 작성하여 다음과 같은 모델에 전달하세요.
Amazon Bedrock에서 Sonnet 3.5를 설치해서 저를 위해 시뮬레이션을 작성해 주세요.전체 프로그램은 여기까지입니다.
제가 쓴 글이요.쓰는데 30초 걸렸어요.그래프가 생성되었죠.
이번 주 다른 강연을 위해 슬라이드에 담아두었는데요.이제 저를 데려갔을 거예요
아마 30분, 한 시간 정도 글을 쓰고
이 작업을 수행하는 코드를 디버그해서 제 그래프를 예쁘게 만들고 어떤 라이브러리가 적절한 종류의 그래프를 그리기 위해 R을 사용하는지 기억하세요.하지만 이게 전부 30초 걸렸어요. 만약 제가 그랬다면 아마 1분 정도 걸렸을 거예요.
타이핑 속도가 엄청 느렸어요.그래서 시간도 많이 절약되었고 지금까지는 경험하지 못했던 시뮬레이션을 사용하여 시스템의 동작을 탐색할 수 있었습니다.
전에는 탐색하기가 귀찮았어요.이런 건 정말 신나는 일이에요.
제너레이티브 AI에 대해 말씀드리자면, 제너레이티브 AI를 통해 할 수 있을까요?
이런 것들을, 과거보다 훨씬 빠르고 저렴하게 배울 수 있는 것들이죠.몇 가지 요점을 말씀드리죠.다시 강연으로 돌아가서 제가 어떻게 생각하는지 볼게요.
여러분 모두 배우셨으면 좋겠습니다.그래서 우리는 여기서 재시도를 시작했습니다.지터는 좋습니다.우리는 항상 초조해해야 합니다.다시 말씀드리지만, 지터, 무작위성을 더하라는 거죠.무작위성은 시스템에 적합합니다.스파이크를 없애는 데 도움이 됩니다.재시도는 준안정 장애 또는 티핑 포인트 실패를 야기할 수 있는데, 이러한 실패로 인해 시스템이 다시 가동되지 않는 방식으로 장애가 발생할 수 있습니다. 기하급수적 백오프를 이용한 재시도와 같은 모범 사례처럼 말이죠.AWS SDK에서 사용하는 것과 같은 토큰 버킷 알고리즘을 사용하면 클라이언트 측 코드 몇 줄만으로 대부분의 시스템에서 이러한 장애 모드를 완전히 방지할 수 있습니다.이 기능은 AWS SDK에 내장되어 있으며, AWS SDK에서 어떻게 구현하는지 확인할 수 있습니다.또 다른 교훈은 백오프는 특별히 중요하지 않다는 것입니다.
오픈 시스템에서는 효과적입니다.따라서 클라이언트 수가 많은 시스템이죠.
무작위로 도착하는 것 같은데요.폐쇄형 시스템에서는 효과적이죠.하지만 만약 여러분이 건물을 짓고 있다면
웹 사이트와 같은 개방형 시스템에서 클라이언트를 백오프하는 것은 과부하에 전혀 도움이 되지 않을 것입니다.회로 차단기는 매우 강력한 도구입니다. UI 기능을 줄이거나 기타 선택 사항인 수확량을 줄일 수 있는 도구입니다.
시스템의 기능.그리고 고객이 관대하게 행동할 수 있도록 하기 위해서죠.
다운스트림 시스템으로 보내고 과부하가 걸렸다는 것을 알면서도 추가 트래픽을 전송하지 않습니다.하지만 조심하세요. 특히
샤드 시스템과 딥 서킷 서비스 아키텍처에서 말이죠.푸싱 서킷 브레이커
해당 아키텍처에 대해 자세히 알아보거나 아키텍처에 대해 좀 더 자세히 설명해 보겠습니다.
클라이언트에 정말 익숙하시다면 효과적인 방법이 될 수 있습니다.
이런 문제들을 피하기 위해서죠. 하지만 나름의 단점이 있기 때문이죠.꼬리.훨씬 더 많아요
헤징 같은 기법들, 그냥 두 번 전화하는 것 처럼요.
이레이저 코딩처럼요. 시스템이 더 많은 작업을 할 수 있게 해주고, 꼬리를 더 납작하게 만들고,
이상치 지연 시간을 줄일 수 있습니다.저는 기법을 선호하는 편이에요.
꾸준한 작업을 하는 사람들이죠.그들은 행복한 경우와 슬픈 경우에 같은 양의 일을 합니다.그래서 삭제 코딩을 항상 두 번 하는 방법이 특히 효과적이라고 생각해요.앞서 말씀드린 것처럼 재시도를 통해 추가 작업을 제한할 수 있는 토큰 버킷을 사용할 수 있습니다.하지만 그만큼 금액이 어느 정도 있다는 뜻입니다.
추가 작업이 필요하죠.그리고 이레이저 코딩도 훌륭하죠.이 시스템 기법이 더 있었으면 좋겠네요.
사람들이 알고 사용했었죠.제가 말씀드렸듯이, 이 제품은 필수품이었어요.
50년 동안 스토리지 시스템을 사용해왔습니다.하지만 널리 사용되지는 않습니다.
분산 캐시에 있는 데에는 몇 가지 타당한 이유가 있습니다. 제 생각에는 대부분
인식이 부족해서요.저는 시뮬레이션이 정말 강력한 수학적 도구라고 생각해요. 대부분의 사람들의 정신 모델에 딱 들어맞는 도구라고 생각해요.
프로그래머들은 아주 잘하죠.사람들이 정말 많아요.
이런 종류의 페이지를 리뷰하는 것을 누가 불편하게 생각하겠습니까?
상징적인 통계인데 아마 느껴야 할 것 같습니다.
그걸 검토하는 게 불편해요. 누가 정말로 그렇게 하겠어요?
같은 종류의 답을 얻을 수 있는 작은 시뮬레이션을 검토하는 데 만족하고 매우 유능합니다.더 복잡한 건 반대하지 않아요.
그나저나 시뮬레이션과 시뮬레이션 프레임워크.제 생각엔 그냥 사람들이
이런 것들을 너무 일찍 찾아내서, 이봐, 내가 만약 시뮬레이션을 하려면 최첨단 분산형 시스템을 사용해야 할 것 같다는 생각이 드는 경향이 있어요.
시뮬레이션 프레임워크.이런 것들은 정말 대단합니다.
강력하고 훌륭하지만 대부분의 시스템에는 필요하지 않습니다.
네가 해야 할 일이야.시뮬레이션은 코드처럼 보이고, 코드처럼 느껴지고, 코드 냄새가 나고, 코드처럼 검토하고, 코드처럼 테스트하지만 실제로는 강력합니다.
자세히 알아보는 수학.위장된 수학이죠.더 많은 시뮬레이션을 작성해야 합니다.시뮬레이션을 더 써봐야겠어요.이 강연에서 한 가지 교훈을 얻으셨다면, 다시 돌아가서 시뮬레이션을 작성해 보셔야 한다는 것입니다.
시스템의 동작, 클라이언트의 행동,
서버의 동작, 그리고 나중에 언젠가는 길고 고통스러운 운영 중단을 줄일 수 있는 방법을 발견할 수도 있습니다.음, 정말 고마워요
오늘 함께 해주셔서 감사합니다.뭔가 있었으면 좋겠어요
흥미로웠던 강연을 통해 얻으셨고, 여러분도 직접 적용해 볼 수 있습니다.
복원력을 높이고 특히 피할 수 있는 시스템과 아키텍처
최악의 운영 중단을 야기하는 티핑 포인트 장애.정말 고마워요.(관중들의 박수)