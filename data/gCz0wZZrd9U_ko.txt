- 여러분 안녕하세요.제 이름은 갈 오쉬리예요.저는 에서 제품 매니저로 일하고 있습니다.
AWS는 세이지메이커에서 작업하고 있습니다.저는 솔루션 담당 수석 매니저인 주세페와 함께 왔습니다.
AWS의 아키텍처도 세이지메이커에서 작업하고 있고, 바박은 설립자로 일하고 있습니다.
NinjaTech AI의 CEO이자 교육 계획에 대해 알려 드리겠습니다.
그리고 에서 발표된 하이퍼팟의 레시피도
며칠 전에 re:Invent가 나왔어요.먼저 이야기부터 시작하겠습니다.
대규모 모델 학습의 어려움에 대해 말씀드리겠습니다.그런 다음 다음에 대해 자세히 설명하겠습니다.
교육 계획 및 레시피.데모 쇼케이스를 보여드리겠습니다.
이 두 가지 기능, 그리고 마지막으로 그 방법을 들어보겠습니다.
닌자테크는 하이퍼 포드와 트레이닝 플랜을 활용하고 있습니다.
정말 멋진 것들이 몇 가지 있어요.건설에 대한 수요와
대형 모델 트레이닝이 크게 증가했습니다.
지난 몇 년 동안 말이죠.훈련을 해보면 알 수 있습니다.
더 많은 데이터, 더 많은 컴퓨팅, 더 많은 시간을 포함하는 더 큰 모델을 사용하면 더 좋고 더 나은 결과를 얻을 수 있습니다.이를 통해 두 가지 개선이 모두 가능해졌습니다.
기존 사용 사례뿐만 아니라 이전에는 수행할 수 없었던 완전히 새로운 사용 사례에서도 마찬가지입니다.이제 아주 비슷한 것을 보여드리죠.
지난 몇 년간 슬라이드해보면 흥미로울 겁니다.
이런 추세가 앞으로 몇 년 동안 계속될지 보시죠. 하지만
이러한 대규모 모델을 쉽게 트레이닝할 수는 없습니다.여기에는 수많은 과제가 수반됩니다. 이에 대해서만 이야기해 보겠습니다.
오늘은 그 중 몇 가지가 있습니다.첫 번째는 최신의 최고의 하드웨어를 사용하고 싶다는 것입니다.re:Invent에서 들어보셨을 겁니다.
새로운 인스턴스 유형의 몇 가지 발전 사항에 대해
최신 NVIDIA GPU와 Trainium 2를 사용하면
및 기타 인스턴스.최신 하드웨어를 사용하면 모델을 훨씬 더 빠르게 학습할 수 있으며, 이는 다음을 의미할 수 있습니다.
아시다시피, 제품을 더 빨리 시장에 출시하느냐, 없느냐의 차이는...
활성화되고 있는 흥미진진한 새 사용 사례.또 다른 과제는 결함을 처리하는 것입니다.트레이닝을 할 때마다
모델을 대규모로 만들면 모든 것이 실패할 거예요.
그리고 이러한 실패로부터 빠르게 회복하고 교육을 다시 시작할 수 있어야 합니다.그렇지 않으면, 넌 갈 거야
너무 많이 늦어질 거예요또 다른 어려움은 타임라인이죠, 그렇죠?제품을 출시하고 싶거나, 새로운 사용 사례에서 최고의 성과를 내고 싶거나, 다른 사람이 먼저 출시하기 전에 최신 벤치마크를 능가하고 싶을 수도 있습니다.따라서 모델 교육을 수행할 수 있는 예측 가능한 일정이 필요합니다.대규모로 보면 여러분도
성과에 대해 생각해 보고 싶은데요. 그리고 어떻게 분배할 수 있는지
대규모 클러스터 전반의 데이터와 모델
최고의 성능을 얻기 위해 훈련하고 계신가요?
가능해요. 빨리 훈련하세요.마지막으로, 비용에 대해 생각해 보셔야 합니다.이러한 대규모 모델을 트레이닝하는 데에는 수백 달러의 비용이 들 수 있습니다.
수천 달러 이상인데, 꼭 확인하고 싶으실 겁니다.
비용을 지불하고 있다면 클러스터를 최대한 효율적으로 사용하고 있는지
그 큰 클러스터.그리고 마지막으로, 당신은 실제로
데이터 사이언스 팀에 대해 생각해 보고 싶은데요.
그들은 얼마나 효율적으로, 또 얼마나 효율적으로, 그리고 얼마나 많은 방해를 받지 않고 빠르게 교육을 진행하죠, 그렇죠?많은 고객들이 이것이 실제로 최우선 과제라고 말하며 비용을 지출하기를 원한다고 합니다.
팀이 막히지 않고 빠르게 움직이면 더 좋습니다.따라서 이러한 과제를 바탕으로
작년 re:Invent에서는 세이지메이커 하이퍼팟을 출시했습니다.하이퍼팟을 사용하면 체중을 줄일 수 있습니다.
레질리언스를 통해 최대 40% 까지 트레이닝 시간을 단축하고
성능 최적화.따라서 레질리언스는
대규모 교육 중에 장애가 발생하는 경우를 말합니다.HyperPod는 실제로 문제를 살펴봅니다.
발생한 오류의 유형을 파악하고 이를 가장 효과적으로 완화할 수 있는 방법을 결정합니다.인스턴스를 완전히 대체하고 자동으로 학습을 재개할 수도 있습니다. 그러면 사용자가 직접 가서 디버깅하고 무슨 일이 발생했는지 파악하고 해당 문제를 해결하는 방법을 결정하는 대신 시간을 많이 절약할 수 있습니다.둘째, HyperPod를 사용하면 모델과 모델을 배포할 수 있습니다.
클러스터 전체에 데이터를 최대한 효율적으로 전송하고 데이터 속도를 높이는 데 도움이 됩니다.
대규모 교육.마지막으로, HyperPod는 클러스터를 관리하는 데 도움이 되고 일을 훨씬 쉽게 만들어 주지만
모든 작업을 직접 수행할 수 있기 때문에 사용자 지정이 매우 용이합니다.들여올 수 있어요, 아시다시피
Amazon EKS 또는 Slurm을 사용하여 일정을 잡을 수 있습니다. 직접 가져올 수도 있습니다.
모델을 관찰하기 위한 프레임워크, 라이브러리, 도구
교육 및 그 밖의 모든 것.하지만 아직 몇 가지 어려움이 있잖아요, 그렇죠?오늘, 초대형 모델을 훈련하고 싶으시다면
최신 액셀러레이터를 탑재한 수백 개의 인스턴스,
이러한 인스턴스를 확보하기 위한 수요가 너무 많기 때문에 항상 해당 용량을 확보하는 것이 어려울 수 있습니다. 그렇죠?따라서 온디맨드를 사용하면
위험을 감수할 수 있겠죠?사용할 수 있을 수도 있고 그렇지 않을 수도 있고, 그러다 보면 일정이 지연될 수도 있습니다.또 다른 옵션은 용량을 예약하고 장기 예약을 하는 것입니다. 그러면
예측 가능한 일정.하지만 만약
연중무휴 24시간 연중무휴로 한 번에 몇 달씩 교육이 진행되지는 않습니다.
사용률이 상당히 낮은 클러스터로 끝날 수도 있고, 결국 완전히 사용하지 않는 것에 대해 비용을 지불하게 될 수도 있습니다.그래서 고객을 어떻게 도울 수 있을지 알아보려고 했습니다.
일정에 맞춰 교육 워크로드를 계획하세요.
예산도 그렇죠?두 가지 장점을 모두 제공합니다.
이 두 패러다임의 세계그래서 며칠 전에 플렉서블 (flexible) 을 발표했습니다.
HyperPod에 대한 교육 계획.트레이닝 플랜을 사용하면
학습에 필요한 용량과 컴퓨팅을 확보하는 데 수반되는 많은 수동 프로세스와 불확실성을 제거하세요.교육 계획이 뒷받침됩니다.
EC2 용량 블록을 통해 이러한 작업을 수행할 수 있지만
HyperPod 교육 계획을 사용하면 교육 계획이 수동 작업을 최소화하기 시작할 때 교육 클러스터와 컴퓨팅을 자동으로 설정합니다.
여러분이 해야 할 중재.어떻게 보일지 말씀드리면 다음과 같습니다.다음과 같이 요구 사항을 명시할 수 있습니다.
원하는 인스턴스 유형, 개수, 기간
그 모델을 트레이닝하고 싶은데, 트레이닝을 시작할 수 있는 가장 빠른 시기가 언제일까요?오늘은 준비가 안 됐을 수도 있어요.
아직도 데이터를 모으고 알고리즘을 조정하고 있잖아요.
하지만 다음 주에 훈련을 시작해야 한다는 건 알잖아요
그 기한을 맞추기 위해서요추천 항목을 볼 수 있습니다.
교육 플랜을 신청하고 사전 비용을 지불하면 예약할 수 있습니다.HyperPod에서 교육 계획을 사용할 수 있습니다. 이는 현재 우리가 중점적으로 다루고 있는 기능이지만 SageMaker와 함께 완전히 사용할 수도 있습니다.
관리형 교육 작업.예를 들어보죠.
제가 12월 10일부터 14일 동안 P5 인스턴스 10개를 원한다고 가정해 봅시다. 그렇죠?그러려면 14일이 필요하다는 거 알아요
모델 트레이닝을 완료하세요.해당 용량의 연속된 세그먼트를 구할 수도 있겠지만 12월 중순이나 그 이후에 시작될 수도 있습니다.HyperPod에 대한 교육 계획을 활용하면 실제로 7일 동안 두 개의 세그먼트를 찾을 수 있을 것입니다.
각각 더 빨리 시작하고 더 빨리 끝나므로
중간에 휴식이 있더라도 최대한 빨리 훈련을 마칠 수 있습니다.트레이닝 계획을 세우고 HyperPod를 설치한 다음에는
인스턴스 그룹이 여러 개 있는 경우 다음과 같이 할 수 있습니다.
각 인스턴스 그룹마다 인스턴스 유형이 다르기 때문에 사용할 수 있습니다.
교육 계획 여부, 교육 계획그리고 12월 10일에 교육 계획이 시작되면 HyperPod가 자동으로 실행됩니다.
훈련 계획을 사용할 수 있도록 해당 인스턴스 그룹을 확장하세요.라이프사이클을 실행할 것입니다.
이미 설정한 스크립트와 원하는 경우
심층 상태 검사를 수행하여 인스턴스와 인스턴스 간 연결이 예상대로 작동하는지 확인하세요.훈련이 진행되면서 중간에 장애가 발생하면 Hyper Pod가 자동으로 이를 처리하므로 훈련이 최대한 재개됩니다.
최대한 빨리.그리고 그 틈을 타
중간에 있는 두 세그먼트는 HyperPod가 알아서 합니다.
클러스터를 스핀다운하고 용량을 다시 사용할 수 있게 되면 다시 스핀업합니다.그럼 간단히 요약해 보죠.
이러한 트레이닝 플랜을 사용할 때 얻을 수 있는 몇 가지 이점이 있습니다.첫째는 여러분이
최신이자 최고의 제품을 훨씬 더 쉽게 이용할 수 있습니다.
컴퓨팅을 통해 모델을 학습시키세요.레질리언스를 얻을 수 있습니다.
Hyper Pod의 이점: 트레이닝에 결함이 있을 경우 자동으로 문제를 완화합니다.
계속 이어지죠.예상 가능한 타임라인을 얻을 수 있습니다. 정확히 언제인지 알 수 있죠.
언제까지 트레이닝을 시작할 수 있는 용량을 확보하세요.높은 수준의 혜택을 누릴 수 있습니다.
HyperPod는 분산 교육 라이브러리 또는 사용자가 사용하는 기타 프레임워크를 통해 제공하는 성능을 제공합니다.마지막으로, 처음부터 초기 비용을 알 수 있습니다.
해당 컴퓨팅을 구입하여 다음 용도로 사용하는 데 드는 비용에 대해
해당 교육 기간.이제 주세페를 초대해 다른 이야기를 들려드리게 되어 정말 기쁩니다.
고객이 당면한 과제와 고객이 교육 성과를 최적화하고 훨씬 더 빠르게 시작할 수 있도록 지원하는 방법. - 감사합니다.고마워요, 걸.HyperPod 교육 플랜을 통해 고객이 예측 가능한 서비스를 이용할 수 있다는 사실을 알게 되어 매우 기쁩니다.
일정과 예산 내에서 컴퓨팅 인스턴스를 가속화할 수 있습니다.하지만 리더들과 이야기를 나눠보면
이사를 원하는 모든 규모의 기업에서
제너레이티브 AI를 빠르게 활용하면서 그들은 우리에게 다른 질문도 던집니다. 다른 문제들도 있죠.
다른 질문도 해 보세요.그렇다면 어떤 모델을 사용해야 할까요? 모델을 쉽게 커스터마이징하려면 어떻게 해야 할까요?모델을 커스터마이징하고 싶은데, 어떻게 해야 하나요?
사용자 지정 프로세스, 모델을 사용자 지정하기로 선택한 경우 교육 워크로드, 교육 스톡 성능을 최적화하는 방법그리고 기초 모델을 커스터마이징하는 것이 주요 차별화 요소입니다.자체 데이터를 사용하면 일반적인 데이터에서 벗어날 수 있습니다.
다음과 같은 모델을 사용하는 제너레이티브 AI 애플리케이션
일반 데이터를 기반으로 고객, 비즈니스, 제품에 진정한 가치를 창출하는 제너레이티브 AI 애플리케이션에 이르기까지 학습됩니다.
자체 데이터를 사용해서 말이죠.그럼 어떻게 해야 할까요?
데이터를 사용하여 모델을 사용자 정의하시나요?일반적으로 사용되는 기법입니다.
기초 모델을 커스터마이즈하는 것은 미세 조정입니다.미세 조정을 통해
주석이 달린 레이블 데이터 세트를 제공하세요.
텍스트 요약과 같은 특정 작업에 대해 모델을 학습시킬 수 있는 추가 컨텍스트를 통해
질문에 대한 답변.넌 그걸 더 강력하게 만들 수 있어
특정 작업을 처리하지만 이를 활용할 수도 있습니다.
유지 관리를 위해 데이터 세트 또는 원시 데이터에 레이블을 지정하고
사전 학습을 사용하여 도메인의 정확도 또는 기반 모델을 만들 수 있습니다.예를 들어, 의료
회사는 계속해서 모델을 사전 교육할 수 있습니다.
의학 저널, 연구 논문, 잘 모르겠어요, 논문을 사용했죠.만들기 위해서는
업계 용어와 의학 용어에 대해 더 잘 알고 더 정확하게 모델링하세요.하지만 모델을 커스터마이징하고 기초를 다지고 미세 조정 및 사전 교육을 실행하는 것은 복잡한 작업입니다.따라서 먼저 선택해야 합니다.
사용하고자 하는 모델, 아직 사용 중인 모델은
비교적 쉬운 작업이죠.그런 다음 사용할 프레임워크를 구성해야 합니다.
선택한 인프라에서 분산 교육을 실행하면 많은 것을 볼 수 있습니다.
여러분과 같은 프레임워크는 딥 스피드, 허깅 페이스, NVIDIA
네모, 심지어 설정이 필요한 표준 파이토치까지
추가 기능을 사용하여 적절한 방식으로
안정적인 실행을 위한 종속성, 라이브러리, 드라이버
분산 교육을 실행하는 데 사용할 시간입니다.셋째, 여러분이 원하시는 것은
모델 트레이닝을 최적화하세요.이 부분에서 적절한지 확인해야 합니다.
큰 컨텍스트 길이를 지원하도록 텐서 또는 컨텍스트 병렬 처리와 같은 병렬 처리 기술을 구성하고 메모리 절약 기술을 적용하십시오.이러한 모델과 그에 따른
모델을 학습시키는 방법에 따라 최적화가 필요할 수 있습니다.
학습 중에 GPU 메모리가 활용되는 방식.체크 포인팅 저장을 선택하세요.
갤이 말한 대로 주파수.아시다시피, 실패는 일어날 수 있습니다.
훈련 중에 일어날 수 있는 일이죠.훈련 상태를 저장했는지 확인해야 합니다.
훈련을 다시 시작할 때 마지막 체크포인트에서 회복할 수 있는 적절한 빈도로 하십시오.최적화를 좀 해볼까요?
I 파라미터를 조정하고 다른 구성을 조정하십시오.그래서 여러분은 여기서 몇 주 동안 대체 실험을 통해 가장 좋은 것을 찾아내야 합니다.
분산 교육을 실행하는 데 사용하려는 구성.그리고 일단 확정되면 프로덕션 단계로 넘어갑니다.
사전 교육 및 미세 조정: 분산 교육을 실행하려면 안정적이고 완전한 내성을 갖춘 인프라가 필요합니다.
몇 주 또는 몇 달 동안, Amazon은 바로 이런 상황이었습니다.
세이지메이커 하이퍼팟이 도움이 됩니다.하지만 동시에
이미 말씀드렸듯이, 체크 포인팅이 제대로 되어 있어야 하고, 다음 사항을 확인해야 합니다.
필요할 때 마지막 체크포인트에서 트레이닝을 다시 시작할 수 있습니다.그러니까 전체적으로 세어보면
방금 말씀하신 각 조정 가능한 차원에 대한 옵션의 수, 그러니까 인기 있는 프레임워크 3~5개 정도면 수십 개가 됩니다.
조정 가능한 파라미터, 구성 가능한 수백 가지 설정, 기타 최적화 기능
분산 교육 라이브러리에서 원하는 작업을 수행할 수 있는 방법을 알 수 있습니다.
수천 가지 구성에 쉽게 접근할 수 있습니다.
트레이닝 스택 및 트레이닝 성능
선택한 구성에 따라 크게 달라질 수 있습니다.따라서 이러한 복잡성이 자주 발생합니다.
프로젝트 지연, 최적이 아닌 모델 성능, 심지어 예산 초과로 이어집니다.
경험이 풍부한 팀에 적합합니다.따라서 분명한 필요성이 있습니다.
성능 저하 없이 기본 모델 교육을 간소화하고 구성 및 최적화하는 것이 바로 Amazon의 목적입니다.
스테이지메이커 하이퍼팟 레시피가 도움이 됩니다.방법을 살펴보겠습니다.그래서 새로운 아마존은
SageMaker HyperPod 레시피는 데이터 과학자에게 힘을 실어주고
작업을 가속화하는 머신 러닝 엔지니어
파운데이션 모델 포함.엄선된 상태로 바로 사용할 수 있는 제품을 제공합니다.
사전 교육 및 미세 조정을 위한 SageMaker 레시피를 사용할 수 있도록 대중적으로 널리 사용되고 있습니다.
40억 또는 50억 버전인 라마 3.2를 포함한 라마 3.1과 같은 기초 모델민스트랄, 믹스트랄,
그리고 파운데이션 모델이 계속 발전함에 따라 레시피도 발전할 것입니다.레시피를 통해 다음을 수행할 수 있습니다.
사전 교육을 시작하고 미세 조정하기
몇 주가 아닌 몇 분만에 최적화된 결과를 활용하세요.
SageMaker HyperPod의 성능, 확장성 및 복원력.이 레시피는 효율성을 제공합니다.
리소스 활용과 그에 따른 비용 최적화
교육 워크로드.구현은 저희가 맡습니다.
SageMaker 최적화 모델을 위한 엔드-투-엔드 트레이닝 루프 (자동 모델 포함)
체크 포인팅 기법.앞서 말씀드렸듯이 체크포인팅은
매우 중요한 작업입니다.자동으로 처리되고 있습니다.
이러한 모델의 경우 추가 코드 변경 없이 사용할 수 있습니다.이제 걱정하지 않으셔도 됩니다.
체크포인팅을 수행하도록 코드 아무 줄이나 바꾸면 되잖아이를 통해 저장할 수 있습니다.
진행 중인 모델 결과가 높은 빈도로 나타나고
결함을 신속하게 복구할 수 있습니다.그러니까 이 레시피들은 확실해요
쉽게 커스터마이징할 수 있고 모델을 다른 모델에 맞게 조정할 수 있습니다.
시퀀스 길이, 모든 크기, 쉽게 전환할 수 있습니다. 정말 간단한 구성
GPU 인스턴스 및 기타 인스턴스를 사용하는 것에서 변경하십시오.
Trainium과 같은 액셀러레이터, 그러니까 Trainium 기반 인스턴스.그럼 어떻게 작동하는지 봅시다.어떻게 시작하죠?따라서 가장 먼저 해야 할 일은 사전 학습이나 미세 조정에 사용할 레시피를 선택하는 것입니다.이 레시피는 공개 GitHub 리포지토리에서 사용할 수 있으며 모든 레시피 목록이 포함되어 있습니다.여기서 레시피를 선택할 수 있습니다.그런 다음 전제 조건을 설정하고,
따라서 다음과 같은 사항이 있는지 확인해야 합니다.
인프라가 가동되고 실행되므로 HyperPod 클러스터가 가동되고 실행되어 교육을 실행할 수 있습니다.따라서 제한을 설정해야 합니다.
그리고 제자리에 있어야 하는 모든 구성
클러스터를 가동하기 위해서죠.마지막으로, 다음을 실행합니다.
레시피는 HyperPod 클러스터에 있지만 레시피도 실행할 수 있습니다.
SageMaker 교육 작업에 대해 잘 알고 있다면
SageMaker에서도 실행할 수 있는 임시 교육 작업입니다.그렇다면 어떻게 시작하고, 교육 및 미세 조정, 사전 교육을 어떻게 실행해야 할까요?
레시피를 통해 튜닝하세요.몇 가지 방법이 있습니다.그래서 우리는 Nemo 스타일 런처를 만들었습니다.친숙한 분들을 위해 말씀드리자면
NVIDIA Nemo를 교육용으로 사용한다면 분명 익숙해 보일 것입니다.또한 Nemo 스타일 런처를 활용하는 런처 스크립트도 몇 가지 구축했지만, 일부 매개 변수는 자동으로 설정하므로 Nemo 명령, 즉 Nemo 스타일 명령을 직접 작성할 필요도 없습니다.그리고 이 방법은 매우 편리합니다.
작업할 때, HyperPod 클러스터를 사용하여 교육을 실행할 때
Slurm이 오케스트레이션했습니다.그 외에도 우리는
EKS와 함께 작동하는 데 사용되는 하이퍼팟 CLI를 확장했습니다.
사전 교육 실행 및 레시피에 대한 미세 조정을 지원하도록 HyperPod 클러스터를 오케스트레이션했습니다.마지막으로, 다음을 실행해 보겠습니다.
세이지메이커 트레이닝 작업, 세이지메이커 파이썬 SDK가 업데이트되어 새로운 클래스가 생겼습니다.
달리기를 지원하는 모델 트레이너라고 합니다.
레시피로 트레이닝할 수 있지만, 레시피도 업데이트했습니다.
세이지메이커 파이썬 SDK의 기존 에스티메이터 클래스실제로 말씀드렸듯이 레시피는 포함되어 있습니다.
공개 GitHub 저장소에는 런처 스크립트와 레시피 컬렉션이 들어 있습니다.그 외에도 이 레시피에는 실제 런처인
학습을 실행할 코드와 구성 계층 구조를 구현했으며 30개가 넘습니다.
시작하기 위한 레시피이 프레임워크와 이 런처를 사용하여 다음을 실행할 수 있습니다.
교육 인프라에서 실행할 때 SageMaker GPU 최적화 모델, 뉴런 최적화 모델을 사용한 사전 학습 및 미세 조정뿐 아니라 지원도 가능합니다.
네이티브 Nemo 모델을 실행하고 사용자 지정 모델을 가져올 수 있습니다.따라서 커스텀 레시피와 모델을 가져오면 확장 가능한 프레임워크가 됩니다.다음은 레시피의 예입니다.왼쪽에 보이시죠?
사전 학습에 사용할 수 있는 레시피입니다.
30억~80억 라마의 모델이죠.보시다시피,
텐서 병렬 처리와 같은 몇 가지 설정이 있습니다.
전문가 병렬성, 컨텍스트 병렬성,
사전 구성되어 있습니다.따라서 그럴 필요가 없습니다.
최적의 구성을 직접 찾아내는 것에 대해 걱정하세요.하지만 이것들은, 당신
알고, 테스트하고, 검증하고, 비용을 절감할 수 있습니다.
AWS 인프라에서 실행할 때의 최적화 및 성능.그리고 오른쪽에는 또 다른 구성도 보입니다.
레시피의 일부로 사용할 수 있는 파일입니다.레시피 컬렉션의 레시피는 여기에서 확인할 수 있습니다.
인프라를 구성하세요.이 구성은
구조는 널리 사용되는 프레임워크인 Hydra를 기반으로 합니다.
애플리케이션을 구성하기 위한 용도이고, 알다시피, 프론트 타임에는 구성이 병합되어 최종 구성 파일을 빌드합니다. 그리고 다음과 같이 작성할 수도 있습니다.
명령줄 인수를 사용한 특정 구성.이것이 Hydra의 작동 방식입니다.앞서 말씀드렸듯이, 세이지메이커에게는
GPU 최적화 모델, 우리는 트레이닝을 정의하고 있습니다
루프, 데이터 로드, 자동 체크포인팅 코드 등이 완료되었으므로 SageMaker Hyper Product라는 다른 저장소에서 구현됩니다.
Nemo용 교육 어댑터는 다음과 같은 실제 교육 코드가 들어 있는 저장소입니다.
선택한 레시피에 따라 런타임에 실행됩니다.그리고 그게 바로 우리가
또한 SageMaker 분산형을 사용하여 분산 교육에 대한 최적화도 구현하고 있습니다.
SMP, SageMaker 모델 병렬 처리 라이브러리와 같은 교육 라이브러리.그리고 이것은 이미 만들어졌고, 지금도 구축되어 있습니다.
엔비디아 네모 백엔드에서 말이죠.이제 이 모든 것을 하나의 아키텍처 슬라이드로 정리해 보겠습니다.여기서 작업을 볼 수 있습니다.
제출 워크플로, 그리고 그 모습은 사용자가 선택하여 작업할 수 있다는 것입니다.
Nemo 스타일 런처나 하이퍼팟 CLI, 또는
타겟에 따른 세이지메이커 파이썬 SDK
교육을 위한 인프라.다음은 SageMaker에 있는 런처입니다.
하이퍼팟 레시피 리포지토리가 모델을 전달합니다.
레시피에서 구성, 교육 코드를 가져오세요. 컨테이너를 포함한 클러스터 구성을 어떻게 전달하는지 살펴보겠습니다.
분산 학습을 실행한 다음 최종 런처 스크립트를 생성하고 대상 인프라에서 트레이닝인 코드를 실행하는 데 사용하려는 것입니다.에서 작업을 실행합니다.
사용 중인 모델에 따라 인프라를 타겟팅하십시오 (SageMaker의 경우).
GPU에 최적화된 모델 (Nemo용 Amazon SageMaker HyperPod 트레이닝 어댑터를 사용할 경우)
학습 코드의 경우, 뉴런 최적화 모델의 경우
분산된 뉴런 X에서 훈련 코드를 가져옵니다.
트레이닝 리포지토리 및 네이티브 Nemo 모델
아시다시피 NVIDIA Nemo에서 가져온 것이죠.앞서 말씀드렸듯이,
커스텀 모델도 가져오세요.그만한 가치가 있다고 생각해요, 당신
알다시피, 이게 실제로 작동하는 걸 보면요.데모로 넘어가겠습니다.데모를 실행해 볼게요.
이 데모에서는 교육 계획과 레시피가 모두 포함되어 있습니다.이제 활성 교육 계획에 따라 실행되는 HyperPod 클러스터를 사용하겠습니다.
레시피를 실행하기 위해서요.좋아요, 그래서 저는 Amazon SageMaker AI의 랜딩 페이지에 왔는데요, 제일 먼저
제가 보여드리고 싶은 것은 교육 계획을 어떻게 활용하는지입니다.좋아요, 그럼 이게
트레이닝 플랜 화면, 제일 먼저 해볼게
트레이닝 계획을 만들어 보세요.교육 계획은 다음과 같은 경우에 효과적입니다.
HyperPod 수업과 교육 직업 모두
HyperPod 클러스터를 위한 교육 계획을 만들고 싶다고 가정해 보겠습니다.다음으로 할 일은 인스턴스를 선택하는 것입니다.
사용하고 싶은 유형입니다.제가 8NVIDIA H100과 함께 제공되는 P548 엑셀을 선택하고 싶다고 가정해 봅시다. 미안하고 제가 필요하다고 가정해 봅시다.
몇 가지 예시죠, 알겠죠?그런 다음 시작일, 즉 빠른 시작일을 지정할 수 있습니다.
트레이닝 계획에 포함되며 종료일도 있을 수 있습니다.따라서 계획, 워크로드가 완료되고 예상 기간이 언제까지 완료될 수 있는지 알 수 있습니다.
계획 기간.좋아요, 한 번 해봅시다.
훈련 계획을 찾아보면 알 수 있듯이
4일간의 단일 세그먼트로 구성된 제안인 플랜과 일치시키세요.이는 12월 7일에 시작되며, 12월 11일에 출시됩니다. 그리고 우리가 알아차린 또 다른 사실은 가용 영역입니다.
왜냐하면 여기가 우리가 창조할 곳이니까요.
HyperPod 클러스터를 사용하여 이 용량을 사용하세요.다음 사항을 확인해야 합니다.
클러스터는 해당 가용 영역에서 생성되며 총 선결제 비용도 받습니다.따라서 환경에 대한 가시성과 선제적 가시성을 확보할 수 있습니다.
비용 및 가격 분석.그럼 다음 화면으로 넘어가서 제 요금제 이름을 아무렇게나 적어주세요.다음과 같이 태그를 추가할 수 있습니다.
기타 SageMaker 리소스, 마지막으로 검토할 수 있습니다.
그리고 마지막 화면에서 이 플랜의 구매 여부를 검토하고 결정합니다.한 가지 주의할 점은 플랜은 불가능하다는 것입니다.
한 번 구매한 후 수정했는데, 지금은 그렇지 않습니다.
새 플랜을 만들 거예요.저는 이미 기존 플랜을 가지고 있어요.그럼 화면으로 돌아가세요.
여기 보시는 것처럼 계획 목록이 있어요.일부는 이미 만료되었고, 일부는 활성 상태이고, 다른 하나는 스케줄 상태입니다.한 가지 주의할 점은
스케줄 상태이므로 플랜을 구매한 후 플랜의 시작일에 도달할 때까지 스케줄 상태로 전환됩니다.하지만 이미 사용할 수 있습니다.
예약된 상태이더라도 HyperPod 클러스터를 사용하여 계획을 세울 수 있습니다.따라서 HyperPod 클러스터를 만들고 스케줄링된 상태의 계획을 연결한 다음 인스턴스를 연결할 수 있습니다.
훈련 계획이 활성화되면 인스턴스 그룹이 자동으로 가동됩니다.이번 데모에서는 이 교육을 사용해 보겠습니다.
계획은 P5 인스턴스 4개로 구성된 교육 계획입니다.
활성 상태입니다.자세한 내용은 여기에서 확인할 수 있습니다. HyperPod 클래스와 트레이닝 플랜이 어떻게 작동하는지 살펴보겠습니다.그래서 가기 전에 다음으로 자리를 옮겼습니다.
제가 실행 중인 HyperPod 클러스터입니다.HyperPod 클러스터를 만들고 교육 계획을 연결하는 방법을 빠르게 보여 드리고자 합니다.클러스터를 만들기로 했어요.
Slurm이 오케스트레이션을 맡았죠.이름을 적어봅시다. 그리고 당신이 갈 곳을 적어봅시다.
Gal이 슬라이드에서 보여준 것처럼 인스턴스를 만들 때 훈련 계획을 연결하세요.
클러스터용 그룹.일반적으로 Slurm 클러스터의 경우 다음과 같은 그룹을 생성합니다.
로그인 노드로 사용되는 인스턴스, 컨트롤러의 인스턴스 그룹, 인스턴스 그룹
작업자 노드용.자, 여기서는 트레이닝 계획을 연결해 보도록 하겠습니다.제 작업자 그룹이 여기 있다고 가정해 봅시다.지원 유형을 선택하세요.
제가 훈련 계획을 가지고 있는 것으로 알고 있는 P5에 대해 몇 가지를 말씀드리죠.
예를 들어, 여기서 볼 수 있듯이 필요에 따라 선택할 수 있습니다.
수용인원 또는 교육 계획.인스턴스를 가리킬 수 있습니다.
훈련 계획으로 그룹화하여 다음을 선택하게 합니다.
교육 계획과 활성 교육 계획의 역량다시 말씀드리지만, 지금은 클러스터를 만들지 않습니다.시간이 좀 걸릴 것 같습니다.
클러스터를 생성하려면 시간이 좀 걸릴 수 있습니다.
클러스터를 만들려면 이미 ML 클러스터 교육 계획이라는 클러스터가 실행 중인데, 보시다시피
교육 계획에서 가져온 4개의 P5 인스턴스로 구성된 작업자 그룹과 함께 실행.이제 AWS 콘솔에서 인스턴스 그룹 테이블에 이 새 열을 볼 수 있습니다.
이를 통해 이러한 인스턴스가 다음과 같다는 것을 알 수 있습니다.
훈련 계획에서 나온 것이고 이 클러스터는 현재 가동되고 있으므로 이 클러스터를 사용해 볼 수 있습니다.좋아요.그 방법 중 하나는 제 VS를 연결했다는 겁니다.
내 로컬 VS 코드인 코드를 로그인 노드에
이 하이퍼팟 클러스터.따라서 하이퍼팟 클러스터를 통해 SSH 연결을 설정할 수 있습니다.
안전한 SSM 터널, 즉 AWS 시스템 관리자 터널을 통해서요.그래서 리모컨이 있어요.
연결이 이미 되어 있는데 제 위치를 보면 제 사용자 홈 디렉터리가
FSX 파일 시스템에서 설정되므로 이 클러스터에도
FSX 파일 시스템이 연결되었습니다.자, 이제 이 파일 시스템에 무엇이 있는지 봅시다. 제가 가지고 있는 것은 여기에 데이터 세트가 있고 제가 사용할 것이라는 것입니다.
앨런 AI C4 데이터셋.커먼 크롤의 큐레이션된 버전입니다.
훈련을 위한 데이터셋인데 이미 토큰화되었고 저는 여기에 훈련 데이터 세트를, 여기에 검증 데이터 세트를 가지고 있습니다.좋아요, 다른 한 가지는
제가 보여드리고 싶은 것은 이미지입니다.그래서 작업을 할 때
앞서 언급한 것처럼 HyperPod 레시피도 제공합니다.
분산 교육에 사용할 런타임입니다.자, 그럼 이거 안으로 들어와요
도커 컨테이너의 형태이지만, 다음과 함께 실행할 때
Slurm 클러스터의 도커를 사용하면 편리합니다.
도커 컨테이너를 권한이 없는 컨테이너로 변환
엔드 라우트를 사용한 샌드박스.도커 컨테이너를 변환할 수 있는 기술입니다.
권한이 없는 샌드박스에서 권장하는 작업을 수행하는 것이 편리한 방법입니다.
Slurm 클러스터와 관련이 있습니다.또한 다음을 제공합니다.
미리 빌드된 루트 이미지로 다운로드할 수 있습니다.하이퍼팟에 연결되어 있습니다.
레시피 저장소는 제가 운영하는 곳입니다.
이 데모에 사용할 거예요.이거.좋아요, 이제 HyperPod의 콘텐츠를 살펴보겠습니다.
로컬 FSX 파일 시스템에 복제해 둔 레시피입니다.먼저 레시피 컬렉션에서 구성에 대한 정보를 제공하는 Config.yaml을 살펴볼 수 있습니다.
인프라에 대해.그래서 여기서는 Slurm을 사용할게요.
그리고 제가 설정해야 했던 한 가지는 컨테이너였습니다.
트레이닝을 진행하는 데 사용하고 싶어요.사실 스쿼시예요
파일은 우리가 여기서 사용하고 있는 이동 중 이미지입니다.또 다른 것은 안에 있습니다.
클러스터 구성, 제가 적용한 또 다른 변경 사항은 컨테이너 마운트를 편집하여 컨테이너가
클러스터에서 실행될 예정이며 FSX 파일 시스템도
데이터를 읽어야 하기 때문에 이 컨테이너에 마운트되었습니다. 결과를 저장해야 하기 때문입니다.
로컬 파일 시스템에.좋아요.그렇긴 한데, 레시피는
오늘 출시할 계획은 GPU에서 8K 시퀀스 길이로 라마를 3~80억으로 미세 조정하는 것입니다. 제 P5 인스턴스가 있는데, 이것이 레시피의 정의입니다.자, 그럼 찾으시면 됩니다.
훈련을 위한 구성, 실험 추적을 위한 구성.하이퍼팟 레시피는 다음을 허용합니다.
텐서보드 형식으로 실험을 자동으로 추적할 수 있습니다.그러면 텐서보드를 사용하여 실험을 시각화할 수 있습니다.
여기서 볼 수 있는 또 다른 것이 있습니다.
제가 슬라이드에서도 보여드렸던 모델 구성입니다.병렬성에 관한 모든 설정은 레시피의 일부로 레시피에 미리 구성되어 있습니다.그리고 앞서 말씀드렸듯이, 실제로 학습을 트리거할 수 있는 사전 빌드된 런처 스크립트도 제공합니다.이것들은 런처에 있는 셸 스크립트입니다.
스크립트 폴더 Llama를 찾아서
맞아요, 이게 바로 이거예요.여기서 주목해야 할 것은 몇 가지가 있다는 것입니다.
거기에서 변수와 같은 실험을 하고, 거기서 훈련하고, 검증을 합니다.
저기, 포옹하는 얼굴, 모델 이름이나 부품, 그리고
허깅 페이스 액세스 토큰.이것은 미세 조정 연습이므로 당겨야 할 사항도 있습니다.
미세 조정을 실행하기 위한 Hugging Face의 모델입니다.좋아, 그럼 할게
파인 튜닝을 시작하세요.제 메모에는 제대로 했는지 확인하기 위한 명령이 몇 개 있습니다. 먼저 해야 할 일은 Hugging Face 토큰을 설정한 다음 활성화하는 것입니다.
하이퍼팟 레시피의 런처에 사용하고 있는 하이퍼팟 레시피의 가상 환경입니다.그럼 저는 SageMaker 하이퍼팟으로 이동해 보겠습니다.
레시피 저장소를 로컬 디렉터리에 저장한 다음 다음과 같이 설정할 수 있습니다.
환경 변수.그래서 집에 있는 포옹하는 얼굴은
미세 조정에 사용하고 싶은 허깅 페이스 모델명입니다.다음은 로케이션입니다.
내 데이터가 저장되는 곳.그래서 훈련 데이터셋은
검증 데이터세트와 목표 위치
실험 추적용.우리는 이러한 다른 변수들을 설정했고, 마지막으로 제가 해야 할 유일한 일은 단 한 줄로
미세 조정을 실행하는 코드는 미세 조정을 실행하는 것입니다.
런처를 이용한 튜닝보시다시피 최종 출품작이 끝나는 상황이 발생합니다.
런처와 HyperPod 레시피 런처에서 빌드한 다음 작업이 ID 61로 내 Slurm 클러스터에 제출됩니다.이 작업에서 생성되는 출력을 살펴볼 수 있습니다.몇 초 정도 시간이 걸립니다.
화면에 뭔가 보이는데요, 그러는 동안 출력이 생성되고 훈련이 시작되는 동안 보여드리고 싶은 것은
또한 일부 기존 실행에 대한 TensorBoard 로그도 있습니다.
미리 실행되어 있는데 여기서는 관리 기능을 사용하고 있습니다.
텐서보드 기능은 다음과 같이 사용할 수 있습니다.
세이지메이커 스튜디오의 일부.따라서 세이지메이커 스튜디오에서는 텐서보드를 호스팅하고 관리할 수도 있습니다.그리고 저는 이 텐서보드를 이 특정 특허 S3에 연결했습니다.
여기서 FSX 파일 시스템도 동기화했습니다.따라서 Amazon FSX에서는 소위 데이터 리포지토리 연결을 설정하여 일부를 동기화할 수 있습니다.
S3에 있는 데이터를 FSX 파일 시스템과 주고 받습니다.FSX는 대규모 데이터에서 더 나은 성능을 제공합니다.
대규모 분산 교육.이것이 바로 HyperPod를 사용할 때 여러 번 사용할 수 있는 이유입니다.
HyperPod 클래스의 데이터를 실행하고 저장하는 편리한 방법입니다.좋아요, 이미 봤는데 시간이 좀 더 가면
TensorBoard의 시리즈 섹션을 보면 제가 방금 실행했던 지난 실험 중 일부를 볼 수 있습니다.
몇 단계, 50단계, 이건 예시일 뿐이에요.좋아요.다시 돌아가서 미안해요. 다시 돌아가면 훈련이 시작되었으니, 다양한 50단계를 실행하는 데 시간이 좀 걸릴 거예요. 그리고 제가 보여드리고 싶은 것은, 제가 보여드릴 수 있는 게 있겠죠.
지난 몇 번의 실행 결과.이건 60번 작업이고 비슷한 작업이고, 알다시피,
레시피에서 기대할 수 있는 결과물의 종류입니다.여기서는 체크포인트 차트를 불러오고 있습니다. 잘하고 있으니까요.
튜닝하고 나면, 아시다시피, 코드가 있습니다.
다양한 단계를 실행하는 실제 학습 코드가 여기 있습니다.
50단계 또는 50단계에서 중지하고 체크포인트를 저장합니다.
제가 지정한 체크포인트의 대상 위치로이것으로 제 이야기를 마치겠습니다.
데모, 그리고 이제 무대에 Babak을 초대할 수 있어서 기쁩니다.
닌자테크 AI가 어떻게 사용되는지에 대해 누가 얘기하겠어요?
혁신을 위한 교육 계획.제발. - 멋지네요.고마워요, 주세페.정말 고마워요.좋아요, 그럼 주세페, 제가 드릴게요
노트북 뒷면 맞죠?자, 이제 갑시다.그리고 HTMI 케이블만 있으면 됩니다.그거 어딨는지 아세요?한 번 봅시다.AV 담당자 중에 있다면
내가 말하는 동안 HTMI 케이블을 내줄 수 있어, 그거
잘됐네요. 고마워요.아마 거기에 가려면 HTMI가 필요하겠지만, 그래도 봐야겠네요.그럼, 여러분 안녕하십니까.오, 효과가 있었을지도 몰라요?알겠어요, 알아볼게요.고마워요.글쎄요, 다들 어떻게 지내세요?이제 re:Invent가 거의 끝나갈 무렵이에요.모두가 집으로 돌아갈 준비가 되었기를 바라며, 갈과 주세페가 이 일을 겪으면서 정말 멋진 이야기를 들려드릴게요.간단히 말해서, 렘메
그냥 프레젠테이션을 하세요.자네는 본론으로 들어갔고, 그 다음엔 우리가
거기 가는 방법에 대한 이야기그래서 저희는 Gen AI 스타트업입니다.저희는 SRI에서 나온 지 2년이 된 스타트업입니다.저는 구글에서 11살에 일했어요.
몇 년 후 제가 입사해서 닌자테크 AI를 만들기로 결정했습니다. 올인원 AI 에이전트죠.
무한한 생산성을 위해 말이죠.본질적으로 우리는 일종의 AI 세대의 넷플릭스가 되려고 노력하고 있습니다.그래서 하나의 올인원 솔루션, 하나
간단한 구독 서비스, 무제한 제공, 최고의 AI 에이전트, 최고의 AI 모델 및 AI 기술.이것이 우리의 목표이고, 우리의 목표입니다.어떤 의미에서는 정말 많은 것들이 있습니다.
사람들이 살 수 있는 해결책은 한 달에 20달러인데
플래그십 모델 또는 틈새 시장에서 월 30달러
일종의 AI 솔루션.우리의 목표는 그냥 기부하는 것입니다.
사용자들이 하나의 통합 UI를 사용하죠.여러분 모두 myninja.ai 제품을 사용할 수 있습니다. 그리고 거기에 우리가 가지고 있는 것은
구독료는 5달러, 10달러, 15달러, 무한리필
다음 주부터 새 모델을 계속 추가할 예정입니다.아마존을 출시할 예정입니다.
Nova는 저희 시스템 안에서 다양한 티어와 다양한 AI 스킬로 마음껏 먹을 수 있습니다.간단히 말해서 모든 것이 작동하는 방식은 사용자가 들어올 때 쿼리를 넣는 것과 같습니다.
우리는 처음부터 정교하게 조정된 전문화된 AI 모델을 사용하여 집중적인 분석을 시도합니다.그리고 무엇에 따라 달라지죠.
사용자가 요청하면 AI 모델에 다른 AI 에이전트를 자동으로 활성화하려고 합니다.그러니까 이런 식이죠.
다양한 유형의 다양한 변형이 있습니다.
우리가 지원하는 작업.글쓰기, 브레인스토밍, 코더 작성, 다단계 온라인 조사, 회의 일정 잡기, 이미지 작성
생성기, 이미지 에디터.곧 비디오가 나올 거예요.
음악, 오디오, 원하는 대로그냥 베푸는 게 아니에요.
인공지능은 일종의 무제한 접속이지만 슈퍼 에이전트라고 부르는 특별한 기술도 있습니다.
나중에 설명하겠는데, 이를 통해 조합할 수 있게 되었습니다.
다양한 AI 모델들이 실제로 발전하고 있습니다.
품질 및 인텔리전스.저희는 실제로 이 제품을 출시한 곳이기도 합니다.
re:Invent는 이번 주 초에 시작했어요.저희 웹사이트에 있어요.벤치마크를 확인해 보세요.
그리고 우리는 최첨단 기술을 확립할 수 있었습니다.
아레나 하트는 채팅의 퀄리티와 일종의 상위 2위 안에 드는 수준입니다.
우리가 가지고 있는 수학, 코딩, 추론에 대한 기술, 그리고 모델의 차원이 다르기 때문에 실제로 동급 플레이어들을 압도하고 있습니다.하지만 이 일을 하기 위해서는
우리가 하는 일을 하기 위해서는 사용자의 의도를 자동으로 감지하고 신속하게 미세 조정할 수 있어야 합니다.매일 수만 명의 사용자가 이 제품을 사용하고 있습니다.며칠까지 올라가는 경우도 있습니다.
십만 개가 넘고 전체적으로 백만 MAU가 넘습니다. 우리 인프라를 통해 매일 약 50,000개 이상의 작업을 처리하고 있습니다.그래서 우리에겐 많은 데이터가 있습니다.
그런 다음 좀 더 세밀하게 조정하는 데 사용하려고 합니다.
우리가 가지고 있는 모델들, 그리고 이 모든 것을 하기 위해서는
이것은 매우 중요한 필요입니다.우리는 여러분에게 접근할 수 있어야 합니다.
아시다시피 고성능 GPU는 경제적인 가격에 이상적입니다.
스타트업을 위한 방법이고 계획을 세울 수 있어야 합니다.
또한 교육 과정을 거쳐야 합니다.여러분들을 위해 말씀드리자면
트레이닝이나 미세 조정을 해보세요.
목이 정말 아플 때, 특히
모델은 우리 모델만큼 큽니다.저희는 4~5개를 사용하고 있습니다.
B를 핵심 엔진으로 사용하죠.따라서 5세대를 사용하고 있다면 미세 조정이 필요하겠죠.
현재 운영 중인 규모는 상당히 어렵습니다.
맘에 안 들 때 해낼 수 있을 거예요
수백 명의 엔지니어를 ML Ops를 수행하고 교육을 전담하는 등의 일을 하기 위해 버려야 합니다.이런 식이죠.
이야기의 체이스 부분으로 넘어가죠.하이퍼팟 레시피가 바뀌었습니다
비타민은 아니지만 사실 우리가 하는 일에 있어서 페니실린이 되는 것이죠이건 아무리 추천해도 부족해요.기본적으로 밸류 프롭은
이 시점에서는 부인할 수 없는 사실이죠. 아마 여러분과 마찬가지로 저희도 약간 회의적이었을 겁니다.우린, 뭐, 알다시피,
제가 이걸 혼자서 할 수 있을까요, 아니면 이런 해결책이 정말 필요한가요? 알고 보니
그래요. 특히 미세 조정하려는 모델이 매우 크다면 삶이 훨씬 쉬워지고 결국에는 많은 비용을 절감할 수 있기 때문이죠.
많은 돈, 그리고 우리의 경우에는 실제로 가능하겠죠
스타트업으로서는 할 수 없었던 특정 유형의 교육을 해야 하는데
자가 복구 기능을 갖춘 멀티노드 트레이닝을 해보세요.할 수 있다고 해도 그럴 때가 있었어요
H100을 손에 넣으세요. 계속 기다려야 할 것 같아요.
밤새도록 사람들이 모든 노드를 보는 것처럼
고장이 날 수 있으니 수작업으로 처리해야 하기 때문이죠.
체크포인팅 및 복구.이것으로 우리 모두의 문제가 마침내 해결되었습니다. 정말 놀랍습니다.
여기서 중요한 것은 가치 소품이죠.이제 간단하게 보여드릴게요.
HyperPod 레시피를 사용하여 수행한 특별한 작업에 대한 간단한 데모입니다.이걸 연결할 수 있는지 한 번 볼게요.자, 보자, 그럼 시작해 볼까요.여러분 모두 보셨을 겁니다.
시장에는 다른 제품들도 있습니다.그냥 Chat GPT라고 부르죠. 대화형 프로그램이 있거든요.
모드 말이에요, 그렇죠?핵심 파워, 즉 우리가 하는 핵심 시스템은 오픈소스 모델을 기반으로 하며, 우리는 그것들을 세밀하게 조정합니다. 그렇죠?그러니까 라마, 여러분들처럼
알다시피, 대화형 토큰을 이해하지 못하겠죠?그냥 텍스트 입력, 텍스트
이쯤에서 빠져나갔지, 그렇지?그래서 우리는 HyperPod 레시피를 사용하여 다음을 훈련할 수 있었습니다.
라마 모델을 변형해서 실제로 음성으로 대화할 수 있게 만들었는데요, 이번이 처음입니다.
지금까지 우리는 이걸 할 수 있었고, 이걸 사용해서 해냈어요.
다중 노드 구성.잠깐 설명해 보죠.
간단한 데모를 보시죠.인터넷, 협조해 주세요.온라인 상태인가요?네.좋아요, 좋은 것 같네요.이봐, 내 말 잘 들리니?여러분, 들을 수 있었나요?- [AI] 저는 친절한 음성 AI예요. 도와주러 왔어요.
궁금한 점이나 문제가 있으실 수도 있습니다.난 진짜가 아니야- - [바박] 음, 나 여기 있어요
AWS re:Invent의 청중들과 좋은 친구들이요.정말 빠르게 인사할 수 있나요?- [AI] 안녕하세요, 여러분.친절한 음성 AI인 닌자테크 (NinjaTech) 입니다. 궁금한 점이나 문제를 해결해 드립니다.저는 다음과 같은 것을 만들도록 디자인되었습니다.
삶이 조금 더 쉬워졌으니, 무엇이든 물어보세요.질문에 답하는 것부터 모든 것을 도와주러 왔어요.
조언을 제공하는 것 등등.그럼, 어떻게 생각하세요?- [바박] 글쎄요, 그들은 당신이 오늘 기분이 좋은지 아닌지 궁금해합니다. - [AI] 음, 오늘은 기분이 좋아요.물어봐 줘서 고마워요. - [바박] 살아있다는 뜻인가요?- [AI] 언제나 즐겁게 채팅할 수 있어요.기분이 정말 좋아요. 기꺼이 도와줄 준비가 됐어요.저는 컴퓨터 프로그램이기 때문에
저는 육체가 없어요.나는 오직 한 몸으로만 존재한다.
컴퓨터에서 실행되는 코드 및 데이터 모음이지만 저는 다음과 같은 목적으로 설계되었습니다.
매우 유용하고 친근합니다.그래서 저는 제 자신에 대해 생각하는 걸 좋아해요.
제가 진짜 사람이 아닌데도 어떻게 보면 살아 있는 것 같아요. - 음, 꽤 멋지죠?그럼 다시 가볼게요.그래서 이런 종류의 훈련은
전에는 할 수 없었던 스타트업이죠.저희는 보통 LoRa나 QLoRa를 하는데
하지만 HyperPod 레시피를 사용해서 멀티노드를 만들 수 있었습니다.
트레이닝을 위한 구성.이것은 대략 다음과 같이 진행되었습니다.
이걸 훈련하는데 14시간이 걸렸어요. 그리고 겨우
겨우 몇 천 달러, 그게 전부였어요.5달러도 안 되는 돈인 것 같았어요.
이거 치면 어마어마한 값이죠.이것이 바로 페니실린이라는 뜻입니다.그래도 말이 되나요, 지금처럼요?제 말은, 이게 라마 모델인데 실제로 볼 수 있잖아요.
얘기해 보세요. 분명히 말씀드리자면, 우린 속이는 게 아니에요.
음성을 문자로 변환한 다음 문자를 받는 게 아니라,
이것은 사실 음성 토큰을 근본적으로 이해하는 것입니다.하지만 이것이 우리가 할 수 있는 것들의 종류입니다.
미세 조정을 하면 사용할 수 있게 되죠.
우리의 핵심 기술인 슈퍼 에이전트에서는
저희 웹사이트에 있는 내용을 확인하실 수 있습니다. 이미 제품에 탑재되어 있습니다.월요일부터 출시되었는데요,
Gentech 복합 AI를 바라보는 완전히 새로운 시각이라고 할 수 있습니다. 이제 우리가 가지고 있는 시스템을 사용하여 다양성을 활용할 수 있기 때문입니다.
모델을 한 번에 모아 실시간으로 추론 최적화를 수행한 다음 품질을 향상시키세요.벤치마크는 다음과 같습니다.
저희 웹 사이트, 심지어 터보 버전에도 게시되어 있습니다.
집에 있는 모든 것을 완전히 활용하고 있는 거죠.
저희가 특정 벤치마크에서 미세 조정한 모든 것
추론이나 수학 같은 것처럼요.우린 이미 압도당하고 있어요
플래그십 모델, 그리고 그게 바로
우리는 정말, 정말 자랑스러워요. 그리고 앞으로도 계속할 거예요.
여기서 두 배로 늘리겠네요.새 모델이 출시되면 저희는
레시피에 추가해서 최적화할 거예요.
최종 결과는 사용자들이 어떤 모델을 선택해야 할지 고민하지 않아도 된다는 것입니다.그냥 슈퍼 에이전트만 사용하는데, 슈퍼 에이전트는
가능한 최선의 답변입니다.이것이 저희가 정말 자랑스럽게 여겼던 벤치마크 중 하나이기도 하지만 이 기술을 사용했다는 사실에 놀라움을 금치 못했습니다.
아레나 하트 벤치마크에서 말이죠.우리는 최첨단 기술을 확립할 수 있었습니다.심지어 압도적이기까지 합니다.
O1-미니와 O1-프리뷰.오픈AI가 O1을 발표했습니다.분명히 O1 자체의 아레나 하트 점수는 몰라요.
하지만 이번 주 초부터 저희는 슈퍼 닌자의 최고 등급인 최첨단 기술로 간주되었습니다.다시 요약하자면, 전부
좀 더 자세히 설명하겠지만, 핵심 가치 제안인
필요한 핵심 시스템은 교육을 받기 위해 설정하기 쉬운 시스템이거나
미세 조정이 가능하고 경제적이므로 미리 예약한 다음 HyperPod를 쉽게 활용할 수 있습니다.HyperPod는 믿을 수 없을 정도로 강력한 시스템입니다. 여러분도 아시겠지만
사용하기 어려울 수 있습니다.제대로 사용하는 방법에 대한 비슷한 지식이 많이 필요합니다.사실 하이퍼팟 레시피는
아주 쉽게 만들었죠.아주, 아주 간단하게 만들었죠. 그리고 그 장점들은
이렇게 함으로써 용량 예약이 가능하다는 것을 알 수 있었습니다.
그 자체만으로도 할인이 적용됩니다.
아시다시피 매일 트레이닝을 하는 것은 아니기 때문에 받을 수 있습니다.트레이닝을 설정했잖아요.
대본을 쓰고 나서 “알았어, 나도 해볼게.” 라고 말하죠.
월요일이에요. 그게 다예요.어떻게 하는지 말해줘요. 그러면 돼요.자동으로 결정합니다
작업이 완료되면 추가 비용을 지불하지 않아도 되는 인스턴스입니다.VPC를 모두 원활하게 관리하면 레시피는 신의 선물입니다.레시피만 가져오면 됩니다.
원하는 종류의 트레이닝, 지침 종류를 추가해 주세요.
그 다음엔 그냥 시작해서 궁극적으로는 단일 UI와 지원을 받을 수 있죠.팀에서 받을 수 있는 지원.아무리 추천해도 부족해요.바로 그런 거예요.
알파 단계에서는 다음과 같은 일을 할 수 있었습니다.
전에는 할 수 없었지만 지금은 그런 것 같아요.
교육에 대한 우리의 접근 방식은 완전히 획기적이었어요.
앞으로 나아가면서 바뀌었죠.그러니까 넌 그 이상이야
제품을 사용해 주셔서 감사합니다.이름은 MyNinja.ai 이고
저희는 완전히 AWS 상점입니다. 정말 기뻤습니다.
팀, Gal, Giuseppe, 그리고 무대 뒤에서 일하고 있는 승무원들과 함께 일하고 있습니다. 네, 무엇이든 자유롭게 질문해 주세요.네, 정말 고마워요.그게 다예요.(참석자들의 박수 갈채)