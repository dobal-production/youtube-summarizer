- 제 이름은 데니스 바탈로프이고 시애틀에 거주하고 있습니다.저는 AI/ML 분야의 세계적인 기술 리더입니다. 이 말은 사실 제가 이 분야의 작업을 조직하는 데 도움을 준다는 뜻이죠.
수백 명의 AI/ML 전문가들이 나와서 고객의 구축을 돕고 있습니다.
AWS 기반 AI/ML 애플리케이션.또한 지난 몇 년 동안 저는 선도적인 역할을 해왔습니다.
현장 책임감 있는 AI.제너레이티브 AI가 무대에 오르기 전에도 이 점은 분명했습니다.
과학의 관점, 공학적 관점, 그리고 일반적으로 무엇을, 어떻게 하는지에 대한 이해 모두에서 추가적인 작업이 필요한 분야입니다.
이 주제에 접근하기 위해서요.현재 저는 다음과 같은 팀을 이끌고 있습니다.
책임감 있는 AI를 과학 모델의 주요 고려 사항 중 하나로 삼고 있습니다.
평가 등등.저 개인적으로도 그랬어요
ISO 및 유럽 등가 감각 및 다리 표준화에 참여
책임감 있는 AI에 대한 노력.그래서 설명 가능성 기준, 투명성 편향 등에 기여했습니다.그래서 오늘은 맷 프레이 (Matt Frey) 를 만났는데, 그는 의 디렉터입니다.
Cisco의 소프트웨어 엔지니어링이요.그리고 나중에 그는 무대에 올라 강연을 할 것입니다.
Cisco가 걸어온 책임감 있는 AI 여정.좋아요, 그럼 시작해 볼까요.분명히 제너레이티브 AI는 엄청난 잠재력을 보여줬습니다.이는 머신러닝 기능의 단계적 변화입니다.하지만 아직 많은 것들이 있습니다.
새로운 위험과 도전.기존의 일부 사례와 비슷합니다.
일부는 아직 존재하며 그 중 일부에 대해서도 이야기하겠습니다.하지만 확실히 제너레이티브 AI에는 새로운 문제가 많이 있습니다.그 중 일부는 사실 환각에 관한 것들이죠.사진들이 대중화되는 걸 정말 많이 봤는데, 알다시피, 정확한 숫자가 나오지 않았을지도 몰라요.
손가락 등등.그리고 분명히 있었죠
그 측면에서 상당한 개선이 이루어졌죠.하지만 우리는 여전히 한 가지를 보고 있습니다.
수치가 맞더라도 가끔 문제가 발생합니다.보셨을 수도 있습니다.
인터넷에서 유포되는 것도 그러한 예 중 하나입니다.그렇다면 우리가 정말로 모든 것을 다 가지고 있는 이유는 무엇일까요?
이러한 제너레이티브 AI 문제와 품질은 그 중 하나일 뿐입니다.하지만 기존 ML과 제너레이티브 AI의 중요한 차이점 중 하나는 모델,
기반 모델은 광범위하며 다음을 허용합니다.
다양한 사용 사례.물론 다른 차이점은 이제 문자 그대로 할 수 있다는 것입니다.
기성품 모델을 꺼내 많은 사람들에게 적용해 보세요.
다양한 사용 사례.반면 ML의 경우 한 가지 예를 들어보겠습니다.
소비자 대출과 마찬가지로 특수 교육 데이터가 있으면 다음과 같은 모델을 만들 수 있습니다.
이 한 가지 작업만 수행하면 많은 효과를 볼 수 있습니다.
관련된 위험을 이해하거나 이해하기가 더 쉽습니다.물론 위험도 많습니다.뉴스에서 많은 것을 봤어요.다시 말씀드리지만, 잠깐 말씀드리자면, 예를 들어 변호사들은 판례법을 찾아보는 경우가 많습니다.그리고 사용하기도 아주 쉽습니다.
이런 생성 도구들.하지만 물론 다시 말씀드리지만
환각이 일어납니다.그리고 정말 놀라워요
한 번도 일어난 게 아니라 사실 여러 번 일어난 일이에요.사실 이건 좀 다릅니다.
누군가 똑같은 일을 해서 가짜 사건을 만들려고 한 경우죠.그리고 가끔은 상황이 그렇지 않을 때도 있습니다.
환각에 관한 것일 수도 있지만 전체적인 퀄리티에 관한 것일 수도 있습니다.왜냐하면 챗봇이 정책을 잘못 해석하고 있는 거잖아요, 그렇죠?그러면 사용자가 쉽게 추측을 하거나 실수를 저지르기 쉽습니다.물론 비용이 많이 들 수도 있습니다.그리고 좀 더 최근에 나온
일종의 AI 또는 AI를 필사한 것입니다.
의학 요약을 필사한 것이죠.여기에 환각 증상이 나타난다면 의료진이 기록을 검토하는 과정에서 잠재적으로 상당히 위험할 수도 있다는 것을 상상할 수 있습니다.
이전 상호작용에서 비롯된 것이죠.아시다시피, 우리 중 일부는 이러한 것들을 필터링할 수 있습니다.
아주 빠르게 진행되죠. 왜냐면 이런 필사본들이니까요.
실수는 명백할 수 있습니다.하지만 가끔씩, 사실
걸러내기가 꽤 어려울 수 있습니다.
실수가 생길 수도 있고요.하지만 몇 가지 응용 분야가 있습니다.
환각은 사실 아주 환영받는 곳이죠.이것도 그 중 하나였죠.분명히 이 부분에서 환각이 꽤 환영받는 곳이죠.하지만 좋아요, 얘기 좀 해볼까요?
제너레이티브 AI와 관련된 이러한 새로운 위험과 과제에 대해 말씀드리겠습니다.사나움에 대해 이야기한 적이 있는데, 환각에 관한 것이기 때문이죠.
사실적 정확성, 좀 더 높은 수준이죠.
출력의 품질.에 대해 더 자세히 이야기하겠습니다.
지적 재산권 및 데이터 프라이버시, 하지만 독성
안전은 또 다른 문제입니다.정말 새로워요
왜냐하면 이제 생성되는 언어에는 정말, 아시다시피, 증오심 섞인 말들이 담겨있을 수 있으니까요.
어떤 개인이나 집단을 위협하고, 모욕하고, 일종의 모욕감을 주는 것이죠, 그렇죠?따라서 근본적으로 이를 바로잡는 것이 매우 중요하죠.하지만 정확한 사용 사례에 따라 일부를 허용할 수도 있는 흥미로운 상황도 있습니다. 그렇죠?예를 들어 다음과 같은 경우
어떤 사람의 말을 인용한 건지, 아니면 100년 전에 쓰여진 책의 한 구절일 수도 있는데 다른 언어를 사용할 수도 있습니다. 그리고 이건 사실이에요.
바로 이거였어요.그리고 특정한 예시나 특정한 상황에서도 이런 일이 가능해야 합니다.그리고 물론 여러분도
뭐, 아시다시피 별일 없는 질문이라고 생각하실 수도 있는 다른 질문들도 있습니다.
이 챗봇의 범위를 말씀드리죠.거부 주제에 대해 알아보겠습니다.
예를 들어, 나중에.그게 전부입니다.좋아요, 책임감 있는 AI,
이런 얘기는 많이 들으시겠지만 가끔은 명확하지 않을 때도 있습니다.
정확히 뭐예요, 그렇죠?어떻게 정의할 수 있을까요?아시다시피, 조직마다 정의가 약간씩 다를 수 있습니다.우리가 이 문제를 바라보는 방식은 여러 가지 상호 관련된 문제이며, 종종 서로 연관되어 있습니다.하지만 이 여덟 가지 기둥에는
제어 가능성, 개인 정보 보호 및 보안, 안전
독성, 편향성, 공정성에 대해 얘기했잖아요?진실성과 견고성, 설명 가능성, 투명성, 거버넌스.지속 가능성이 목록에 없다는 것을 눈치채셨을 수도 있는데, 그 이유는
보통은 AWS 전반의 관심사로 별개로 취급되지만, 종종 책임감 있는 고려 사항으로 묶이기도 합니다.그래서 제 의도는
여기서 이러한 핵심 요소 중 일부를 실제로 살펴보고 구체적인 도구와 기술에 대해 이야기하고자 합니다.
이 문제를 해결할 수 있습니다.먼저 AI 위험과 그 위험의 평가에 대해 말씀드리겠습니다.많은 규제가 나오고 있기 때문이죠, 그렇죠?확실히 보시면
예를 들어, EU AI법은 위험을 먼저 따지죠, 그렇죠?금지된 것인지 알아봅시다.위험도가 높나요?위험도가 낮은 시스템인가요?그래서 그게 정말 중요하죠.
그 역량을 키우거나 그 역량을 키우는 것
조직 내에서 말이죠.아시다시피, 이상적으로는 프로젝트 구축을 시작하기 전에 위험을 실제로 평가하는 것이 좋습니다.그래서 저희는 고객을 돕기 시작했습니다. 특히 이미 잘 운영되고 있는 고객과는 다른 상황에서도 말이죠.
위험 관리 프로세스, 아니면 잘 모르실 수도 있습니다.
AI를 위해 이 작업을 수행하는 방법.자문을 받기 시작했죠.
고객들이 그 방법을 알려줬습니다.몇 차례 워크숍을 진행했습니다.사실 오늘 오후에
궁전이 아니라 카이사르 포럼에서는 오후 4시에 반복되는 세션이 있습니다. 여기서 초크 토크를 통해 이런 종류의 위험 평가 과정을 가상의 위험 평가 과정에 대해 논의할 수 있습니다.
애플리케이션 및 사용 사례.하지만 한 가지 살펴보는 방법은
어디선가 시작해야겠네요, 그렇죠?그리고 보통 여러분이 하는 일은 모든 것을 파악하는 것입니다.
AI 시스템의 이해관계자.그러면 무엇이 다른지 알아낼 수 있습니다.
심각도 수준이 의미하는 거죠?사용 사례에 적합합니다.그리고 다음과 같은 가능성이 있습니다.
유해 사건의 발생 및 이러한 사고의 심각성
유해 사건, 맞죠?그래서 이런 해로운 것들을 구상하고 열거하기 시작하죠.
일어날 수 있는 사건들.아마 거기서 다양한 사람들을 데려오고 싶을 수도 있겠죠.
이 믹스에는 다양한 관점이 담겨 있습니다.그리고 툴링은 실제로
어떤 식으로든 이러한 상황이 발생할 가능성을 평가하는 데 도움이 됩니다.예를 들어, 독성 점수 등등.그래서 작년에 우리는 위험 평가에 대해 처음으로 초크 토크를 했었죠.블로그 게시물을 올렸습니다.다시 말씀드리지만, 계속하겠습니다.
이런 점에서 고객을 돕는 것은 일을 시작하는 중요한 방법임에 틀림없습니다. 멋지네요.그럼 시작해 보죠.
공정성, 편견, 공정성.사실 제가 가장 좋아하는 주제인데, 사실 쉽게 말할 수 있었어요.
아마 몇 시간 동안 이 문제에 대해 얘기했을 거예요.하지만 이제 제가 말씀드리고 싶은 것은 기존의 방식처럼 편향을 평가하거나 편향을 찾아내는 것처럼요.
머신러닝 설정 또는 의사결정 시스템, 어떤 면에서는
올바른 데이터를 사용할 수 있다면 이는 기술적으로 해결된 문제입니다.실제로 Amazon SageMaker Clativey를 통해 편향 감지 기능을 사용할 수 있었습니다.
라이브러리는 꽤 오랫동안 사용되고 있습니다.아시다시피 편향성에 대한 21가지 메트릭을 지원합니다.그리고 이 지표들이 무엇을 의미하는지 설명하는 백서도 있습니다.아시다시피, 이 라이브러리는 실제로 SageMaker에 통합되어 있습니다. 하지만 사실상
오픈소스 라이브러리입니다.따라서 어떻게 작동하는지 알아보고 싶다면 노트북에서 실행할 수 있습니다.여기서 어려운 점 중 하나는 제가 21가지 측정항목을 말씀드렸는데요.글쎄요, 왜 그렇게 많죠?흥미로운 사실은 단 한 명도 없다는 것입니다.
공정성에 대한 정의.한 명도 없어요
공정성의 기준.실제로 몇 가지가 있습니다.그리고 당면 과제는
보통 기술 분야가 아니라, 사실 편한 자세에서 말이죠.
결정을 내리고 '내가 추구하는 중이다'라고 말하면서
공정성에 대한 이런 정의요.그렇게 함으로써 여러분은
다른 기준에 따르면 사실 불공평해지는 거죠?그리고 편안해야 해요.
그런 선택을 할 때, 왜냐하면,
거기선 공짜 점심은 없어요. 선택을 해야 할 것 같아요.이런 경우가 종종 있습니다.
정확성과 정확성 사이에는 절충점이 있습니다.
공정성도 마찬가지죠, 그렇죠?생각해 보셔야 할 부분이죠.그래서 일단 어떤 공정성 기준을 정하면 될까요?
최적화를 하고 있다면, 그 다음에는 무엇을 위한 것인지 알 수 있습니다.
편향 메트릭은 적절합니다. 모델을 실제로 한 번 사용해 데이터를 사전 학습하기 위한 것이든 상관 없습니다.
이미 훈련을 받았다는 식이죠.그래서 우리는 출판했습니다.
이 블로그 게시물은 사람들이 결정을 내리는 데 도움이 되도록 하기 위한 것입니다. 예를 들어 최적화하려는 특정 공정성 기준을 고려하여 선택해야 하는 기본 지표는 무엇입니까?하지만 앞서 말씀드린 것처럼 기술 측면에서 이 문제가 해결되었다고 말씀드렸지만, 다른 많은 것들이 있습니다.
여기에 추가로 고려할 사항이 있습니다.예를 들어, 많은
공정성 지표는 기본적으로 그룹 공정성 지표입니다. 즉,
일부 인구통계학적 관점에서 그룹 공정성을 최적화하는 거죠?그렇게 함으로써 실제로
그룹에게는 공평하지만 그 그룹의 한 구성원, 특정 구성원 한 명에게는 불공평합니다.
그룹, 좀 이상하네요.사실 대부분의 법률은
여러분도 알다시피, 여러분들은 그렇지 않은 방식으로 공식화되었죠.
다양한 속성에 따라 사람을 차별할 수 있잖아요, 그렇죠?한 가지 어려움이 있습니다. 하지만 여러분이 원하는 것은 아닙니다.
어떤 사람들에겐 불공평한 일이 될 수도 있겠지만, 그건 여러분이 생각해 보셔야 할 부분입니다.그리고 또 다른 한가지는
심슨의 패러독스 같은 다양한 문제들도 있지만, 기다릴 필요는 없겠죠?왜냐하면 이런 문제들이 발전하는 것을 방해하기 때문이죠, 그렇죠?어디선가 시작해서 무엇을 얻고 있는지 확인해보세요. 그리고 거기서부터 진전을 이루게 되죠.한 가지 흥미로운 질문은 이 모든 것들이 어떻게 연관되어 있는가입니다.
제너레이티브 AI와 관련이 있죠?왜냐하면 제가 얘기한 적이 있으니까요.
의사 결정 시스템, 그리고 아시다시피, 아, 뭐
또 다른 문제는 예를 들어 편향을 측정하려면 무엇을 알아야 한다는 것입니다.
특정 개인의 인구통계학적 특성은 다음과 같을 수 있습니다.따라서 여러분이 쫓는 것이 인종이라면, 대부분의 경우
본인에 대한 해당 정보는 수집할 수 없습니다.
사용자, 고객, 맞죠?그러니까 그런 데이터가 없을 뿐이죠.그리고 그 정보의 일부를 어떻게 귀속시킬지 아니면 그 데이터를 제대로 얻을 수 있는지를 알아내려면 그게 문제의 일부죠?사실, 저희는
예를 들어, EU AI 법에는 이미 몇 가지 조항이 있습니다.
이러한 정보의 수집을 구체적으로 허용하는 조항입니다.
그냥 측정 목적의 민감한 속성 맞죠?물론 그런 다른 용도로는 사용할 수 없습니다.그리고, 좋아요, 다시 돌아가죠.
제너레이티브 AI 사례에 대해 말씀드리자면, 제가 한 가지
여기서 강조하고 싶은 것은 챗봇의 언어에 대한 우리의 관심만큼이나 중요하죠?기분을 상하게 하지 않는 것 같아요.
어떤 식으로든 우리 말이에요, 그렇죠?이는 분명히 기본적인 요구 사항입니다.하지만 제가 보고 싶은 건
업계는 좀 더 성과 중심의 방향으로 나아가고 있습니다.
공정성을 위한 평가.이런 제너레이티브 시스템에서도 똑같은 방식으로 가능하죠.왜냐하면, 제가 알다시피, 제가 알고 싶은건 제
시스템이 결정을 내리는 데 있어서 어쩐지 편향적이죠, 그렇죠?이 사람이 환불을 받았나요?
그들이 원했던 거잖아요, 그렇죠?그 사람이 대출 승인을 받았나요?그게 결과죠, 그렇죠?그리고 이건 아직 결정일 뿐이에요
이를 측정할 수 있고 시스템의 상태를 파악할 수 있습니다.
여기에 맞춰서 하는 거죠.아무튼, 너무 감동적이야
설명 가능성과 함께 또 다른 흥미로운 주제입니다.역사적으로 볼 때, 좋아요. 그러지 않는 게 아주 중요하죠.
이것을 투명성과 혼동하세요. 왜냐하면 설명 가능성이란 이 머신러닝이 어떻게 되는지에 관한 것이기 때문입니다.
모델이 실제로 그 결과물에 도달했잖아요, 그렇죠?AI 시스템이 특정 기반 모델이나 특정 알고리즘에 기반을 두고 있다는 사실을 이해하는 것과는 대조적으로, 그것을 이해하는 것과는 대조적으로 말이죠.다시 말씀드리지만,
전통적인 머신 러닝의 표준 접근 방식은 항상 모델에 구애받지 않았습니다.내부 모델이 무엇이든 상관없기 때문에 편리합니다.혼란을 일으키려고 하는 거잖아
입력을 조금만 더하면 출력이 얼마나 되는지 알 수 있을 겁니다.
그 결과 영향을 받았죠.이 경우 다음을 수행할 수 있습니다.
이 불투명한 시스템이 어떻게 돌아가는지에 대한 멘탈 모델을 만들어 보세요.
실제로 어떻게 행동하는지 알아차리고 행동하는 거죠.
섭동은 출력에 영향을 미칩니다.이제 나중에 예를 들어보겠습니다.하지만 한 가지 예를 들어보죠.
어떻게 계산됐는지 보여주는 스크린샷을 보여드릴게요.
세이지메이커 캔버스에서 가져왔어요.하지만 다시 말씀드리지만, 이 설명 기능은 세이지메이커 클래리파이에도 내장되어 있습니다.그리고 여기 대장암이 5년 이상 생존할 수 있다는 표준 척도라는 모델이 있습니다.그리고 우리는 높은 수준의 모형을 볼 수 있습니다. 일종의 범세계적 설명 가능성이죠.
암의 요약 단계가 가장 중요한 특성이기 때문에 특징 기인이라는 거죠, 그렇죠?그렇다면 진단 연령은
다음 문제 등등.심지어 연령별 분포를 보면 다음과 같이 말할 수 있습니다.
안타까운 현실은 나이가 들수록
x축으로 보면 5년 이상 생존할 확률이 낮아집니다.그러면 다음과 같이 됩니다.
오른쪽 하단에 80~90대가 있습니다.물론 그 다음에는 그 설명의 타당성을 검토할 수도 있습니다.
개별 예측.이 경우에는 예측 버튼이 있습니다.당신인지는 모르겠지만
보세요, 하지만 맨 위에 있어요.그리고 아마 그것도 보실 수 있겠죠.
이 특정 환자의 경우, 결정을 내리는 주된 이유는 사실 요약 단계가 아니라 연령 또는 연령일 수 있습니다.
다른 거 맞죠?그러니까 일종의
전통적인 머신 러닝.하지만 이 접근 방식은
또한 일반적인 사용 사례 중 하나인 분류에 생성 시스템을 사용하는 상황도 해결하세요.GenAI 시스템으로 분류하는 것이 더 나은 기술인 것처럼 말이죠.그래서 그 중 하나가 그럴 수도 있겠죠.
텍스트 분류가 될 수 있겠죠.분석을 예로 들 수 있습니다.
이러한 고객 리뷰에 대한 감성, 맞죠?거기서 할 수 있는 게 뭐가 있을까요?
개별 단어나 문장 또는 문장인가요?
당신의 특징이 맞나요?그래서 입력 내용을 교란시키려고 할 수도 있겠죠. 이런 기능들 중 몇 가지를 없애고 여전히 동작하는지 확인해보세요.
결과 리뷰를 긍정적인지 부정적인지 분류하세요. 그렇죠?이렇게 할 수 있죠.
예를 들어, 이 부분은 초록색이나 어두운 색으로 표시됩니다.
초록색은 결정을 내리는 빨간색에 비해 한 방향으로 결정을 내리는데 더 도움이 됩니다.
다른 방향으로 향하세요.흥미롭게도, 여러분은 할 수 있습니다.
이미지를 분류할 때도 같은 작업을 하세요.사실 이것은 아주 잘 알려진 기사이거나 허스키와 늑대를 구별하는 모델을 만든 논문입니다.그리고 그 모델은 잘 작동하지 않았죠.사실 많은 허스키들이
늑대로 잘못 분류되어서 늑대가 하려고 했었죠.
어떻게 작동하는지 이해하세요.그래서 이 접근법을 LIME이라고 부릅니다.그들이 그 모델이 그렇지 않다는 것을 실제로 깨닫게 되는 곳에서요.
동물 그 자체도 보고 배경에 있는 눈도 보고 늑대라고 판단하는 거죠. 늑대가 많으니까요.
배경에 눈이 쌓인 늑대 사진들이 많이 있습니다.
훈련 데이터셋도 있겠죠?이것이 바로 이런 방식으로 이루어졌죠.그래서 이것도 지원됩니다.
예를 들어, 세이지메이커 클래리파이가 있죠.예를 하나 들어보죠. 어떻게 작동하는지를 예로 들어보죠.
피라미드 이미지를 보시면, 분류가 있습니다.
저건 피라미드예요.그리고 뭘 알아내려면
이미지의 일부가 그 결정에 영향을 미치고 있습니다.개별 픽셀을 보는 대신 다음과 같이 할 수도 있습니다.
기능으로 활용하세요, 그렇죠?우리는 슈퍼 픽셀을 살펴보죠.전체 지역, 여기서
이미지를 세그먼트로 나누고 그 중 일부를 분할합니다.
세그먼트는 랜덤 노이즈로 대체되죠?그리고 이런 이미지를 많이 만들죠. 섭동 같은 것이죠.그러면 어떻게 되는지 보실 수 있을 겁니다.
궁극적인 예측이 영향을 받습니다.그리고 결국 히트 맵을 만들면 이 경우 피라미드의 측면이 좀 더 진한 파란색이라는 것을 알 수 있습니다. 그래야 이 부분이 이미지에서 다음과 같은 부분이라는 것을 알 수 있습니다.
예측을 뒷받침합니다.이것은 피라미드인데, 이 경우에는 알고리즘이 다음을 이해하는데 도움이 될 수 있습니다.
우리가 생각하는 방식대로 작동하고 있는 거죠.
우리의 기대에 부응하는 거죠.좋아요, 제너레이티브 케이스는 어떨까요?글쎄요, 제너레이티브 케이스는 상황이 조금 더 어려워요. 왜냐하면 모두 같은 모델이기 때문이죠.
섀플리 값이나 SHAP 알고리즘에 구애받지 않고 말인데요, 제가 언급하는 걸 잊어버렸네요.
이것이 바로 세이지 메이에서 사용되는 알고리즘입니다.
커널 SHAP를 명확히 하세요.실제로 사용할 수 있습니다.
입력값을 기반으로 특정 단어의 생성 수를 예측하는 데 보통 단일 단어의 생성에는 신경 쓰지 않습니다.왜 전체가 필요한지 정말 알고 싶으실 겁니다.
완료가 이루어졌어요.하지만 다시 말씀드리지만, 분류를 위한 한 가지 비결은
실제로 모델이 어떻게 그런 결정을 내렸는지 물어보세요.물론 이 부분에서도 마찬가지입니다.
예를 들어, 이 이메일이 특정 이메일이라고 할 수도 있겠죠, 그렇죠?따라서, 아시다시피,
이걸 다른 제품 사용 관련 질문으로 분류할 수 있는데, 사실 맞아요.하지만 상상할 수 있듯이 이러한 설명은
그 자체가 환각이죠, 그렇죠?그러니까 솔리드 케이스라고 믿을 수는 없죠.우리가 보아온 다른 접근 방식으로는 에이전트 아키텍처라는 것이 있습니다.
사고의 연쇄를 통해 실행 계획을 세우세요.
리액트, 패러다임, 나무 같은 걸 예로 들어보죠.
생각해보면, 뭐가 됐든, 그 행동 계획은
일종의 설명이죠, 그렇죠?녹음할 수 있게 되면
그런 다음 나중에 감사하여 상담원이 특정 행동을 한 이유를 확인할 수 있습니다.그리고 아마 얘기해 볼게요
잠시 후에 그런 것들에 대한 다른 몇 가지 예를 들어보죠.좋아요, 마지막으로 한 가지 더
여기서 말하고 싶었어요.아, 그래서 GenAI의 경우 설명 가능성은 여전히 활발한 연구 분야로 남아 있다는 점을 말씀드리고 싶습니다.그래서 오기가 좀 어려워요.
쉽게 사용할 수 있는 레디 툴링으로 말이죠.따라서 몇 가지 접근 방식은
이 트랜스포머의 내부를 살펴보죠.
아키텍처와 모델, 그리고 아마도 이해는
신경망의 어떤 부분이 특정할까요?
실제로 트리거됐죠?특정 컨셉이 제시될 때 말이죠.하지만 번역하기가 더 어렵습니다.
이 접근법은 모델에 구애받지 않는 상황에 대한 것입니다. 한 모델에서 다른 모델로 전환하고 이제 무엇을 했든
더 이상 통하지 않아요, 그렇죠?그래서 이런 방법을 사용할 수 있는 방법이 몇 가지 있습니다. 하지만 제가 말씀드린 것처럼 여전히
활발히 연구되고 있는 분야입니다.이 슬라이드는 제가 시도하고 있는 건데요
간단히 말씀드리자면, 우리가 이런 AI 시스템에 대해 편향성, 공정성, 설명성에 관심을 갖는 이유는 이들이 일종의 불투명하고, 매우 복잡하고, 이해하기 어려운 것으로 인식되기 때문입니다.제대로 작동하지 않으면 이런 불의를 가중시킬 수도 있겠죠?어마어마한 수준으로요. 그래서 우리는 확실히 그걸 막고 싶어요.하지만 사실 다시 말씀드리자면, 이건 단순한 AI 시스템이 아니라 아주 간단한 것들도 있습니다.
이런 의사 결정 시스템, 맞죠?마치 이렇게 되어야만 하는 것처럼
자전거를 타려면 키가 커요.그게 만약의 규칙이잖아요, 그렇죠?아주 간단한 의사 결정 시스템이죠.하지만 누가 그런 컷오프를 생각해 냈는지 설명할 수 있는 건 어딨죠?어떤 장단점이 있었나요?제 말은 분명히 있잖아요.
보안 고려 사항, 안전 고려 사항,
아마도 비용도 들 수 있겠죠?따라서 최적의 제품의 안전에 조금 더 투자했다면 어린 아이들도 탈 수 있었을 수도 있었을 것입니다.하지만 다시 말씀드리지만, 우리는 잘 모릅니다. 그렇죠?그리고 우린 그걸 이용할 수 없어요.그래서 흥미롭게도
뭔가 생각을 자극하는 것 같은데요, 그렇죠?마치 조직, 정부, 법률이 있는 것처럼 말이죠. 그렇죠?그들이 결정을 내리고 있어요.그리고 어떤 면에서는 많은 기술이, 특히 편향성 같은 것에 대해서요.
우리가 이야기한 것은 실제로 이러한 시스템의 공정성을 평가하는 데 사용될 수 있습니다.
다양한 인구 통계에 대해서요.그리고 그건 마치 추구되지 않는 것과 같아요.
보통 요즘이잖아요, 그렇죠?생각해 볼 게 있네요, 멋지네요.또 다른 하나는 제어 가능성입니다.앞서 얘기했었죠.그러니 분명히 해야 할 일이 있습니다.
시스템을 모니터링하세요.이것이 바로 관찰성에 관한 것입니다.이번 주 초에 CloudOps 분야의 동료와 GenAI로 옵저버빌리티를 수행하는 방법에 대해 이야기를 나눴습니다.이 내용은 현재 YouTube에 게시되어 있습니다.하지만 AI 시스템을 조종한다는 측면에서는 흥미로울 수 있습니다.
여기저기서 특징들이 있습니다.예를 들어 Bedrock 에이전트의 경우 액션 그룹을 정의하고 해당 에이전트가 선택하는 경우
이 작업을 수행하기 위해 이러한 행동 중 일부는 기본적으로 아이템 효과가 없을 수도 있습니다.이 경우에는 심각한 부작용이 발생할 수 있습니다. 가설적으로 봤을 때, 일부 사례처럼
뭔가 삭제된 거 맞죠?따라서 상담원이 이 작업을 선택하기로 결정하면 사용자가 개입하여 “이 작업을 허용할지 거부할지 여부를 결정할 수 있습니다.따라서 Bedrock 에이전트 구성에서 이를 구성할 수 있습니다.한 가지 예를 들어보죠.
어떻게 이런 일이 가능할까요.멋지네요. 개인 정보 보호 및 보안, 분명히 매우 중요한 주제입니다.그리고 여기서 여러분께 다시 말씀드리고 싶은 것은, 우선 베드록과 같은 회사에서는 언제나 사용자가 자신의 데이터를 관리할 수 있다는 분명한 약속을 하고 있다는 것입니다.즉, 실제로는 우리가 여러분의 데이터를 사용하지 않는다는 뜻입니다.
모든 모델을 개선하고, 모델을 개선하고,
Bedrock에서 사용할 수 있는 타사 모델을 개선하세요.그래서 우리는 실제로 프롬프트와 완성을 저장하지 않습니다.
이런 것들이 이 모델들에도 적용되죠.사실 Bedrock의 초기 버전에서는 콘솔에 놀이터가 있고 타이어를 찰 수 있습니다.
아시다시피 특정 모델들 말이에요.ChadGPT와 마찬가지로 프롬프트를 넣으면 편의를 위해 프롬프트와 완료 내역을 기록할 수 있습니다.그리고 우리는 그게 사실이라는 걸 깨달았죠.
이 메시지를 희미하게 만들었죠.뭔가 보관하고 있는 것 같은데 이게 전부였는데도
놀이터에서 다 했어요, 그렇죠?프로덕션 용도로는 사용할 수 없습니다.그래서 고객에게 혼란을 주지 않기 위해 해당 기능을 삭제했습니다.기본적으로 데이터는 저장되지 않습니다.
어디에도 있잖아요, 그렇죠?이제 보관하고 싶을지도 몰라요
본인을 위한 데이터나 다른 곳에 기록해 두세요.그리고 설정하는 방법도 있습니다.
예를 들어 CloudWatch는 사용자가 제어할 수 있는 S3 버킷에 저장하기 위한 것이지만, 그건 여러분의 선택입니다. 그렇죠?그런 다음 이를 완전히 제어할 수 있습니다.그리고 네, 더 나아가서, 특정한 것을 고르면 되죠.
사업을 운영하는 지역, 그리고 물론 데이터도
시스템이 모델을 통과해 흐르기 때문에 해당 영역을 벗어나지 않습니다.
완성도를 만들어 보세요.이제 기능이 하나 생겼습니다.
Bedrock을 사용한 교차 영역 추론이라고 하지만 기본적으로는 꺼져 있습니다.따라서 구성을 해야 합니다.
이 경우 용량 문제가 발생할 경우에 대비하여 다른 지역을 사용할 수 있습니다.
또는 스로틀링 등등.하지만 다시 말씀드리지만, 전혀 그렇지 않습니다.
기본적으로 실행되고 있습니다.좋습니다. 물론 AWS의 표준 테이블 스테이크도 있습니다.암호화와 전송, 암호화가 저장되어 있습니다.알다시피, 사용자 지정 모델을 만들 수도 있습니다.사용자 지정 모델을 만드는 데 사용된 데이터는 다시 말하지만,
마찬가지로 어디에도 저장되지 않습니다.처음에 S3에 저장하면 사용자 고유의 버킷이 되고 작업이 완료되고 학습에 사용됩니다.훈련이 끝나면 데이터가 더 이상 필요하지 않은 것처럼 말이죠.그래서 그걸로 원하는 건 뭐든 할 수 있죠.물론, 모델들은
사용자 지정 방식으로 제작한 사용자만 액세스할 수 있습니다.
본인만 사용할 수 있습니다.그러니까, 알다시피, 저는 할 수 있어요.
계속 반복해서 말하자면, 메시지를 받고 있는 것 같고, 알다시피
액세스 관리도 마찬가지고요.그리고 추가로 다음이 있습니다.
CloudWatch로 사용량을 추적할 수 있는 방법은
Cloud Trail을 사용하여 문제를 파악하고, 해결하고, API 활동을 모니터링하세요.마찬가지로 다양한 종류의 규정 준수 체제를 사용할 수 있습니다.좋아요, 이제
좀 더 부가적인 방향으로 나아가고 있습니다.
제너레이티브 AI에 대한 고려 사항은 무겁거나 중요합니다.그래서 안전성, 독성, 진실성에 대해 조금 이야기했습니다.견고성이란 입력에 대한 작은 파동이 엄청난 파동으로 이어지지 않도록 하는 것을 의미합니다.
출력의 변화, 맞죠?시스템이 그러한 변화를 적절하게 처리하기를 원하시겠죠.물론 여기서 한 가지 알아두셔야 할 것은, 매번
특정 모델을 선택하면 모든 종류의 모델이 제작됩니다.
이미 보호 기능을 갖추고 있습니다.모델 자체에는 많은 가드레일이 내장되어 있습니다.보통은 구성할 수 없습니다.
온도 상위 B, 전달하려는 상위 K 등과 같은 일부 하이퍼 파라미터를 제외하고는 의미 있는 방식으로 말이죠.하지만 이 모델들의 내부 가드레일이 무엇인지 이해하는 것이 중요할까요?예를 들어, 다음과 같이
타이탄 이미지 제너레이터, 요청하려고 하면
아기 요다의 이미지를 생성하면 프롬프트에서 실제로 거부될 거예요. 왜냐면 이 이미지가 다음과 같다는 걸 알기 때문이죠.
아시다시피, 저작권이 있는 사진이죠.그 대신 돌아서서 그걸 속이려 하고 좋아한다면
이봐요, 저는 뾰족한 귀를 가진 초록색의 작은 동물을 만들고 싶은데요, 자루 같은 걸 쓰고 있잖아요, 그렇죠?결국에는 내부적으로 어떤 식으로든 그 무언가가 생겨나더라도
아기 요다처럼 보이지만 실제로는 출력을 막는 또 다른 검사 기능이 있을 겁니다.그래서 여러분이 알아두셔야 할 이 모든 것들이 있습니다.
지금 벌어지고 있는 일이죠.그래서 이것들이 무엇이고 어떻게 작동하는지 제대로 평가하는 한 가지 방법은
모델 평가를 사용하세요.그래서 작년에 우리는 재단을 설립했습니다.
세이지메이커 클라리파이를 사용한 모델 평가또한 오픈 모델도 출시했습니다.
FM-eval이라는 소스 라이브러리.그리고 Bedrock 평가에도 똑같은 기술이 적용되었습니다.따라서 여기서는 표준 데이터 세트를 사용하여 자동화할 수 있는 지표에 대한 자동 평가를 사용할 수 있습니다.
이번 평가에서는또한 인간의 평가를 선택할 수도 있습니다. 왜냐하면 결과물의 창의성과 같이 자동화하기 어려운 특정한 특징과 지표가 있기 때문이죠. 그렇죠?그중 하나일 수도 있겠죠.그럼 우선 다음과 같은 것부터 시작해보세요.
이러한 데이터셋의 기본 데이터셋이지만, 사용 사례에 따라 자체 사용자 지정 평가 데이터세트를 만들 때 진정한 가치를 얻을 수 있습니다.이것이 정말 유일한 방법입니다.
모델이 어떻게 동작하는지 구별할 수 있는 방법
사용 사례에 맞죠?순위표에 의존하는 대신, 순위가 조금 더 빨라지면
데이터세트가 공개되면 물론 이 모델들은 해당 데이터세트를 기반으로 최적화되고 학습될 것입니다.
그리고 잘 작동할 것입니다.그래서 중요한 건
자신만의 데이터세트를 가지고 세심하게 보호하세요.그래서 최근에는
모델 평가의 더 나은 측면에 새로운 기능이 많이 추가되었습니다.구체적으로 말하자면,
LLM은 심사위원으로서 매우 흥미로운 기능이라고 할 수 있습니다.
이제 프리뷰로 제공됩니다.물론 만약 여러분이
인간의 평가를 사용하면 다음과 같은 것을 기반으로 한 좋은 결과를 얻을 수 있습니다.
인간, 여러 사람이 같은 것을 보고 있을 수도 있습니다.
결정을 내리는 데 결과물이 나오긴 하지만 비용이 많이 들죠?따라서 대규모 작업을 원한다면 LLM을 심사위원으로 활용할 수 있습니다.
시작하기에 좋은 방법이겠죠.예를 하나 들어보죠.알다시피, 정말 그럴 수 없어요.
화면을 많이 볼 수 있지만 왼쪽에는 두 모델의 응답 1과 응답 2가 표시되고 아마도 실측 결과가 있을 수 있습니다.
오른쪽이 보이시죠.그래서 인간은 그걸 보고 이렇게 말할 거예요. 글쎄요, 제 생각엔
이게 더 마음에 들어요. 리커트 척도로 선택할게요.그리고 결국에는
어떤 통계는, 이봐, 뭐, 다음과 같다는 걸 보여줘요
모델 A가 실제로 모델보다 훨씬 더 나은 성과를 거두었습니다.
저한테는 B이고, 그 반대도 마찬가지예요.좋아요, 하지만 평가 결과는 훌륭합니다. 이러한 내장 컨트롤도 훌륭하지만 응용 프로그램 주변에 사용 사례별로 맞춤화된 가드레일이 필요할 수도 있습니다.또한 이러한 가드레일을 적용하는 방식에 있어 어느 정도 일관성이 필요할 수도 있습니다. 왜냐하면 방향을 바꿀 수도 있기 때문입니다.
한 모델에서 다른 모델로 이동하더라도 가드레일의 탄력성이 어느 정도 유지되는 것이 좋습니다.이것이 바로 우리가 출시한 이유이기도 합니다.
아마존 베드락 가드레일.출시된 지 얼마 되지 않았지만, 재발명품 출시 이전의 가장 최근 사례와 비슷했던 것은 이제 이런 것들이 가능하다는 것이었습니다.
독립형 API로 사용되기 때문에 반드시 Bedrock 모델에서만 작동할 필요는 없습니다.어느 곳에나 적용할 수 있습니다.
AWS 외부 AWS에 있는 모델.그냥 이렇게 부르면 됩니다.
API를 통한 가드레일.그리고 더 흥미로운 것은 re:Invent에도 있습니다.
두 가지 흥미로운 런칭입니다.하나는 이미지 필터링과 관련이 있습니다.이제 텍스트뿐만 아니라 이미지도 필터링할 수 있게 되었습니다.그리고 또 다른 한가지는
물론 자동 추론 검사에 관한 기조 연설에서 발표된 내용이기도 하죠.그리고 이건 정말 대단한 일이에요. 왜냐하면 이제 여러분은 그냥 그런 게 아니니까요.
모델이 갖는 일종의 무작위성에 의존해서 올바른 결과를 도출하는 거죠.대신 적용하고 있는 거죠.
추론 검사.그리고 더 얘기해 볼게요
이에 대해서는 잠시 후에 말씀드리겠습니다.필터를 정의하는 방법은 다음과 같습니다.자, 이제 막 살펴보죠.
몇 가지 기능이 있죠?제 말에 대해 말씀하실 수 있겠죠?
프롬프트와 제가 작성한 글, 증오심 발언, 모욕, 성적인 내용을 확인하고 싶어요.
폭력, 부정행위까지.그리고 이렇게 말할 수도 있겠죠. 음, 그러고 싶은데요
이미지에 맞게 설정하세요.그리고 또 하나 있어요.
프롬프트 공격 기능을 사용하면 잘 알려진 특정 프롬프트 공격을 자동으로 탐지할 수 있습니다.그러면 주제를 거부한 것입니다.따라서 실제로 구성할 수 있습니다.
30가지 다른 거부된 주제, 사실상
범위를 벗어난 대화제 챗봇이 정치 얘기, 투자 자문 등 당신이 하고 싶은 일을 절대 하지 않았으면 좋겠다고 말씀하시는 거잖아요
기본적으로 차단됐죠, 그렇죠?왜냐하면 결국에는 이걸 만들고 있는 거니까요.
고객을 위한 챗봇, 그 대가를 치르고 있잖아요, 그렇죠?그래서 여러분은 원하지 않으실 겁니다.
전혀 관련이 없거나 어쩌면 브랜드와 전혀 관련이 없는 것들에 대해 이야기하기 위해서죠?그러니까 영어로 프로그래밍하는 거죠.이걸 자연어로 정의하면, 아시다시피, 친절하죠.
보는 게 정말 흥미로워요.몇 가지 예를 들자면 분류기가 있고 이런 결정을 내리는 LLM도 있습니다.물론 PII 탐지 기능도 있습니다.특수 PII가 있는 경우 정규식을 사용할 수도 있습니다.
더 잘 정의하기 위해서죠.욕설 필터가 있잖아요.원하는 단어를 추가할 수 있는 표준 목록이 있습니다.
차단되고 싶은 것.그리고 자동화되기 전에도
추론 검사 출시와 함께 이 컨텍스트 검사를 출시했습니다.
근거와 관련성은 매우 중요합니다.첫 번째 방어 수준입니다.
환각에 반대해서요.따라서 RAG 애플리케이션의 경우
컨텍스트를 작성합니다.컨텍스트를 검색합니다.그러면 이 분류기는 모델을 통해 완성된 결과가 실제로 해당 컨텍스트에 기반하고 있는지를 확인한다고 말할 것입니다.그리고 추가로, 출력이 질문과 관련이 있는지도 확인하거나 이걸 이용해서 확인할 수 있겠죠?아직 접지된 상태일 수도 있지만
관련이 없죠, 그렇죠?그리고 감지하고 싶은데요
이 두 가지 상황.그리고 나중에 자동 추론에 대해 좀 더 알아보도록 하겠습니다.마지막으로 한 가지 더 말씀드리고 싶은 것이 있습니다.
여기 투명성이 있습니다.그리고 많은 것들이 있습니다.
여기에는 여러 가지 고려사항이 있습니다.그 중 하나는, 예를 들면,
생성된 결과물이나 일부 콘텐츠가 실제로는 AI가 생성한 콘텐츠라는 것을 알죠.그리고 아마존은 C2PA 운영 위원회와 타이탄 이미지 제너레이터와 같은 이미지 생성 모델에 합류했습니다.
이번 주 초에 발표된 노바 캔버스 모델.모두 이미지에 보이지 않는 워터마크가 포함되어 있습니다.크롭을 원하신다면
이미지에 조금만 더 있어도 실제로 워터마크가 남아 있을 수 있으며 이를 감지할 수 있을 것입니다.
이것은 AI가 생성한 것입니다.하지만 더 중요한 것은 보다 강력한 방어 수단으로서 메타데이터에 실제 자격 증명 디지털 서명이 첨부되어 있고 도구를 사용하여 이를 확인할 수 있다는 것입니다.이 경우 이 이미지가 실제로 이 모델을 통해 생성되었음을 알 수 있습니다.물론 광범위하게, 우리는 소위 말하는 것을 출판했습니다.
AWS 서비스 카드.이것이 우리의 투명성 선언입니다.우리는 어떤 것에 대해 이야기하거나
모델은 어떻게 학습되었나요?어떻게 벤치마킹되었나요?어떤 용도로 사용해야 할까요?그리고 어떤 용도로 사용해서는 안 되죠?그리고 Nova 모델도 마찬가지인데, 더 심층적으로 다루는 기술 보고서가 별도로 있습니다.
이에 대한 자세한 내용을 살펴보겠습니다.그래서 보통 고객들이 저희한테 와서 “뭐, 줄 수 있냐고 물어요.
이 외에도 용도를 명확히 하는 데 도움이 되는 몇 가지 추가 정보를 제공합니다.
우리 회사 모델?그래서 우리는 종종 이렇게 대답합니다.
추가 설문지를 제공해 주시면 규제 상황을 검토할 수 있도록 고객에게 제공하게 되어 기쁩니다.그래서 저는 이 점을 실제로 말씀드리고 싶습니다.
Matt를 무대에 맞이해서 그가 이에 대해 이야기할 것입니다.
Cisco의 책임감 있는 AI 여정. - 고마워요, 데니스좋아요, 제가 다른 강연자예요.데니스가 언급한 여러 측면을 아시게 될 겁니다.
책임 있는 프로세스를 우리의 접근 방식에 적용하기 위해 채택한 Cisco의 프로세스에 포함된 책임 있는 AI 툴입니다.
비즈니스 내 AI.됐어요, 초록색 버튼.그럼 시작하고 싶어요.
성명서부터 시작해서 환각 같은 걸 보여주고 싶은데요
이걸 감지한거죠.Cisco는 이 사업에 종사하고 있습니다.
다리 건설에 관한 얘기가 사실이든 거짓이든 맞죠?배경이 충분하지 않을 수도 있습니다.수사적으로 말하자면, 네, 시스코의
우리의 비전은 실제로 다리를 건설하고 인간을 연결하는 것입니다.우리는 사람들을 연결하면 놀라운 일들이 일어날 수 있다고 믿습니다.
이러한 연결을 통해서요.그래서 우리 비전의 일부는 사람들 사이에 다리를 놓는 것입니다.Cisco에서 가장 잘 알려진
전 세계 사람들 간의 연결을 보장하는 Cisco 네트워킹 솔루션, 그렇죠?Cisco의 협업 그룹.소프트웨어 제품군을 제공합니다.
내부적으로는 팀과의 연결을 제공하고, 외부적으로는 고객, Webex 제품군 및
컨택 센터 스위트.Cisco가 브리지를 구축한다고 하면, 네, 여기서부터 시작하겠습니다.저는 콜라바이에서 일해요.그래서 이 협업 사업부에서는 고객을 연결합니다.
내부적으로는 팀과, 외부적으로는 고객과 함께요.따라서 CollaBAI는 Cisco 협업 사업부의 중심이 되어 AI를 통합하려는 다른 제품 팀에 AI 기능을 제공합니다.
자사 제품에 포함된 기능.우리가 교차로에 서 있다는 것
문제를 해결하고자 하는 제품 관리자의 수
고객 문제, AI를 도입하려는 엔지니어, 엔지니어링 팀
툴링과 기능을 사용하고 이를 사용하여 이러한 문제를 해결하세요.그리고 AI 기능 개발 방식을 관리하는 중앙 집중식 Cisco 정책도 있습니다.그래서 저는 매일 그렇게 하고 있습니다.
제 역할은 책임감 있는 AI가 Cisco 내에서 어떻게 작동하는지를 가장 먼저 이해하는 사람이에요.먼저 시작해 볼게요.
이거 빨리 짚고 넘어가세요.저희 팀이 상호작용하는 분야는 다음과 같습니다.다시 한 번 말씀드리지만, 저희가 도와드리겠습니다.
미팅을 떠올리게 하는 Webex 제품군인 컨택 센터를 통해 고객 경험 공간에 도움이 되는 AI 기능을 구축하십시오.
또는 전화, 메시지, 팀 간의 이러한 유형의 상호 작용.그리고 사무실에서
회의실이 있는 사무실에서 컨퍼런스 하드웨어를 사용하고 있다면 이것이 바로 Cisco 디바이스입니다.또한 개발 및 배포도 진행합니다.
이러한 모델에서 실행되는 AI 모델.이 중 일부에 대해서는 나중에 좀 더 자세히 설명하겠습니다.그럼 우리가 어떻게 시작했는지부터 시작해보죠.
책임감 있는 AI 여정, 그렇죠?아마 익숙할 겁니다.
많은 사람들에게 말이죠.Cisco는 다른 많은 회사들과 함께 ChatGPT가 출시되었을 때 액세스가 제한되었습니다.
결정을 위한 내부 프로세스 및 워크플로를 개발하는 동안 제너레이티브 AI 모델 및 제품
해당 제품의 조달 및 사용을 관리하는 방법
우리 회사 내에서 말이죠, 그렇죠?비록 우리가 이미
책임감 있는 AI 워크플로우가 있었죠. 이전의 제너레이티브 AI는 제너레이티브의 빠른 채택이었죠.
AI와 그 범위, 모든 것, 모든 기능 전반의 모든 기능에 있는 것처럼 말이죠. 그렇죠?그래서 범위가 바뀌면서 해결해야 하는 몇 가지 어려운 문제가 생겼습니다.그래서 Cisco 사람들은 서로 다른 유형의 액세스를 필요로 했습니다.같은 모델이라도 사용하고 싶을 수도 있습니다.
용도가 다릅니다.그래서 용도가 달랐어요.
Cisco 전반의 사례와 요구 사항어떤 사람들은 LLM을 내부 워크플로우에 적용하고 싶어했습니다.다른 사람들은 그렇게 하고 싶어했습니다.
이러한 첨단 AI를 사용하여 제품에 적용하세요.
고객에게 판매하던 것들이었죠.그리고 Cisco에는 이전 제품을 사용하고 있던 연구 부서들도 있습니다.
세대 언어 모델인데 연구를 계속하고 싶어서 잠시 멈췄죠?우리가 이걸 좀 알아내는 동안 말이에요.이 모든 것을 만족시키다니
요구 사항이 서로 다르기 때문에 그룹 간의 긴밀한 협업이 필요했지만 항상 긴밀하게 협력할 필요는 없었습니다.법률, 개인 정보 보호, 조달, IT, 엔지니어링 부서 같은 것처럼요?마케팅 및 영업.모두 이 일에 이해관계가 있었죠.그리고 네, 그래서 우리는 해야 했어요.
이해를 돕기 위해 일종의 중앙 팀을 구성해
이러한 다양한 비즈니스 부문의 요구 사항.그리고 한 가지 문제는 이들 그룹 중 상당수가 이전에 AI 기술에 대한 경험이 없다는 점이었습니다.그리고 정말 많은 것들이 있습니다.
오해가 많아요.당신이 뭔가를 멀리하고, 내가 전할 수 있는 게 있다면 말할게
자, 이건 교육이에요.처음 시작할 때
책임감 있는 AI 정책에 대한 교육을 좀 더 받도록 하세요.알 필요 없어요.
미적분학, 그리고 머신 러닝이 내부적으로 어떻게 기능하는지에 대해 자세히 알아보고, 추론에 사용되는 상용 모델 간의 차이점을 이해하세요.예를 들어, 이해해 주세요.
모델을 그냥 실행하면 학습이 되지 않습니다.
추론을 통해서죠?모델을 사용하는 방법에는 여러 가지가 있습니다.훈련, 평가, 추론이 있죠.그리고 사람들은
이러한 정책 결정을 내리려면 정말 이해가 필요합니다.
이 기술의 사용과 그것이 고객 데이터에 미치는 영향 간의 차이점에 대해그게 데이터를 안전하게 사용하거나 이러한 시스템을 사용하는 방법이죠, 그렇죠?그래서 결국 성공했죠.이제 우리는 세 가지 주요 AI 클래스를 평가하는 탄탄한 프로세스를 갖추게 되었습니다.그리고 저는 그것들을 분류해 보겠습니다.
그 중 하나는 Cisco에서 사용하는 제품 또는 서비스 중 벤더가 추가하고 있는 제품이나 서비스입니다.
AI 기능이 추가되었습니다.그래서 우리는 무언가를 사용하고 있습니다.
그리고 출시가 있는데 갑자기 모든 제품에 AI 지원이 생겼습니다.따라서 이러한 것들이 적절한지 판단할 수 있는 좋은 방법이 필요합니다.
Cisco에서 사용하기 위해서죠?두 번째 범주는 봇을 만들려는 문서와 같이 우리가 가지고 있는 내부 사용 사례입니다.
쉽게 검색할 수 있도록 하거나 내부 워크플로를 다음과 같이 하기 위해서입니다.
간소화하고 싶어요, 그렇죠?세 번째 경우는
고객에게 제공하는 제품을 가져와 AF 기능을 통합하려고 합니다.
고객을 위해 여기에 포함시키세요.그 사용 사례는 실제로
여기서 가장 중점적으로 다루겠습니다.이것이 제가 협업 BU에서 가장 잘 알고 있는 부분인데요, 저희 팀이 제품 팀과 함께 작업하면서
이러한 AI 기능을 통합하세요.좋아요, 그럼 제가 할게요
다리로 돌아가세요.Cisco의 책임감 있는 AI 프로그램은 사용자를 연결하거나 연결하는 것과 같은 일종의 가교 역할을 한다고 생각합니다.
Cisco의 직원들이 AI와 소통하고 있죠?어떻게 하면 안전하게 할 수 있을까요?
안전하고 윤리적으로 말이죠.저희가 평가하는 부분은 세 가지입니다. 기초, 인프라, 그리고
끝에서 끝까지, 원한다면 다리의 길이요.사용자 경험은 처음부터 끝까지 이어집니다.먼저 기반에 대해 살펴보겠습니다. 이를 모든 것을 지원하는 모델이라고 부르겠습니다.
이 모든 것이 그 위에 만들어졌습니다.이게 바로 기계입니다.
학습 모델 그 자체.그래서 이 모델들 중 일부는
우리는 사내에서 개발하고, 다른 것들은 3사에서 조달합니다.
타사 상용 공급업체.알고 계신 다른 모델들
오픈 소스로 사용할 수 있습니다. 그냥 다운로드하여 사용할 수 있습니다.좋아요, 그럼
모델의 출처는 다양합니다.그래서 저희 팀은 광범위한 스펙트럼을 아우르며 작업합니다.
자연어 문제.그래서 우리는 이것들을 사용합니다.
LLM 같은 언어 모델이나 Obsible같은 다른 언어 모델도 있습니다.
특정한 경우에 사용하는 언어 분류기도 마찬가지죠.컴퓨터 비전이 있습니다.
우리가 사용하는 모델들.따라서 Webex 미팅에서 우리 팀은 미팅 내에서 배경 흐림 또는 제스처 인식을 켜거나 AI 지원 재조명을 켤 수 있는 기능을 제공합니다.컴퓨터 비전 모델에는 몇 가지 기능이 있습니다.오디오 및 음성 모델도 제작합니다.제가 가장 좋아하는 것 중 하나
Webex 제품군의 기능은 배경 소음 감소입니다.그리고 저는 모든 협업에 대해 잘 알고 있습니다.
서비스에도 이런 기능이 있지만, 저는 집에 애가 셋이고 강아지 한 마리가 있는데 이 기능이 정말 좋아요.게다가 이 모든 기능이 있습니다.
여기 있는 NOP 기능은 제가 만든 것 덕분입니다.
음성 모델을 ASR이라고 부르죠. 자동 음성 모델이죠.
음성 인식.그리고 이것들은
오디오를 텍스트로 변환한 다음 다운스트림에서 NOP 모델을 사용하여 추가로 처리할 수 있습니다.따라서 모델을 살펴볼 때는 한 번 살펴보아야 합니다.
몇 가지 다른 측면에서요.그 중 하나가 이 모델의 용도와 평가입니다.그럼 이 모델이 왜 개발되었는지 살펴볼까요?어떤 문제가 있었나요?
해결하려고 했던 건가?뭘 분류하려고 하는 거죠, 그렇죠?왜 그런지 확실히 이해하고 싶으세요?
모델이 개발됐어요.이해하고 싶으실 겁니다.
훈련 데이터의 출처.그래서 내부적으로는 모델들이
우리가 스스로 발전한다는 건 꽤 쉽게 할 수 있는 일이죠. 훈련에 대해 알기 때문이죠.
우리가 사용한 데이터죠.외부 모델은 좀 더 어려워요.광고가 있는 경우
모델을 제공하는 공급업체 또는 오픈 소스 모델을 보유하고 있는 경우 실제로 프로세스가 있습니다.
해당 회사들과 관계를 맺을 수 있는 곳
그리고 그들이 데이터를 어떻게 소싱하는지 더 잘 이해할 수 있도록 평가서를 작성하도록 요청합니다.윤리적인가요?합법적인가요?윤리적으로 주석을 달았잖아요, 그렇죠?알려진 편향은 예외적인 경우입니다.모든 모델은 통계적입니다.모든 것을 처리할 수는 없습니다.
100% 정확하죠?그래서 우리가 알고 싶은 건, 이런 모델들을 사용할 수 없다는 게 아니에요. 그래서 적절한 경우의 극단적 사례를 알고 싶습니다.
그 모델들을 사용하기 위해서요.여기서 살펴본 한 가지 예를 들자면, 규모가 작은 몇몇 언어 모델은 다음과 같은 경향을 보인다는 것입니다.
단어를 반복해서 반복합니다.가끔은 그런 말들이 별로 예의가 아닌 경우도 있어요.그들은 인터넷을 통해 교육을 받았어요.그러니까 다시는 그런 일이 아니에요.
사용할 수 없다는 거죠.그게 바로 우리가 원하는 거예요.
이 행동을 이해하고, 문서화하고, 알아두세요
사용 사례에서 확인해보세요.마지막으로, 우리는 다음을 필요로 합니다.
라이선스 및 법적 계약을 거쳐야 합니다.따라서 타사 공급업체인 우리는
모델 사용에 대해 그들과 협상해야 합니다.
오픈 소스 모델을 사용해서 말이죠.알다시피, 라이선스 조건을 이해하고 제대로 작동하는지 확인해야 합니다.
내부 개발 용도뿐만 아니라 상업적 용도로도 당사의 용도에 적합합니다.벤더 평가로 넘어가겠습니다.아마 이 모델을 둘러싼 플랫폼이라고 할 수 있겠네요.몇 가지 다른 점이 있습니다.
모델을 사용하는 방법.일부는 자체적으로 호스팅하고 일부는 Amazon Bedrock과 같은 관리형 솔루션을 사용합니다.Amazon SageMaker를 사용하면 모델이 실행되는 위치를 좀 더 세밀하게 제어할 수 있습니다.
구성 방법.그리고 우리 팀에서도 모델을 직접 호스팅해서 관리하는 역할을 하죠.
인프라는 스스로 완성하죠.GPU 몇 개 가져와. 모델이 몇 개 있어요.
거기서 작동시키세요.이 평가는 사실
관리형, 완전 관리형 솔루션에 더 초점을 맞춥니다.
아마존 베드락 처럼요.보통 이런 모습은 마치 어딘가에서 데이터를 관리하는 제3자를 평가하거나 클라우드 솔루션을 사용하는 것과 매우 비슷합니다.평가 내용도 매우 비슷합니다.에 대해 좀 알고 싶어요
데이터 프라이버시 및 보안.일부 플랫폼은 그렇습니다.다른 사람이 내 데이터를 사용하는 것을 원하지 않거나 이미 사용 중이라면 수신 거부해야 합니다.
계약상의 합의.그러니 확실한건 확실하겠죠?
데이터가 모델 학습이나 미세 조정으로 끝나지는 않을 거예요. 아시다시피, 언젠가는 대중에게 공개되잖아요, 그렇죠?그래서 우리는 데이터가 어떻게 돌아가는지 압니다.
시스템에서 처리됩니다.액세스할 수 있는 사람이 있나요?어디에서든 지속되죠, 그렇죠?저걸 만들고 싶어요
고객의 데이터가 다른 사람의 데이터로 유입되지 않는다는 것을 고객에게 보장합니다.
컴퓨터나 노트북 맞죠?이 모델의 가용성과 지원에 대해 알아보고 싶습니다.고객에게 서비스를 제공해야 하는 지역에서도 사용할 수 있나요?시간이 흐르면서 상황이 바뀝니다. 아시다시피 데이터 센터가 구축되고 모델이 배포됩니다.
여러 지역에 있습니다.우리가 고려해야 할 주요 사항 중 하나는 모델의 라이프 사이클입니다.이는 여느 소프트웨어와 비슷합니다.우리가 고객에게 제공하는 기능을 위해 우리가 의존하고 있는 모델이 더 이상 사용되지 않는 경우
더 이상 사용되지 않을 거예요, 그렇죠?시장은 너무 빠르게 변하기 때문에 어떤 모델에도 의존할 수 없습니다.
오늘로 2년 후에 이 시장에 나올 수 있잖아요, 그렇죠?그러니까 우리가 얼마나 오래 갈 건지 알아야 돼요
언제 더 이상 사용되지 않나요?하지만 모델을 유지하면서 모델로 변경하려면 거쳐야 하는 과정이 있었습니다.
우리의 고객 경험은 우리와 동일합니다.
그 모델을 기대하겠죠?콘텐츠 조정도 살펴봅니다.Denis가 몇 가지 언급을 했습니다.
가드레일이 작동하는 지역.모델에 내장되는 경우도 있습니다.플랫폼이 모델 외부에 콘텐츠 조정을 강요하는 경우도 있지만 반드시 그런 것은 아닙니다.
그 위에 구성을 해두세요.따라서 콘텐츠 조정이 필요한지, 필요에 맞게 어떻게 구성할 수 있는지, 가능한지 이해해야 합니다.그 다음은 생성된 콘텐츠의 소유권입니다.이건 약간 극단적인 사례이긴 하지만 제 생각에는 가장 큰 사례라고 생각합니다.
여기가 우리에게 미치는 영향은 네 가지 차이점이 있습니다.
여기에 관련된 당사자들.AI 기능을 사용하여 Cisco 제품을 구매하는 고객이 있습니다.Cisco는
기능 개발 중.아시다시피,
플랫폼 제공업체, 그리고
모델 제공자.그러니까 이 모든 당사자들, 그리고 일반적으로 비용을 지불하는 사람이 그러하듯이
모델이 산출물을 소유합니다.하지만 일부 사용 사례에서는 더 크고 강력한 모델을 가져와서 그 결과물을 사용하는 것이 점점 더 보편화되고 있습니다.
특정 작업을 수행하도록 소형 모델을 학습시키기 위해서죠.그리고 이런 사례들은 우리가 하기에 적절한지 확인할 것입니다. 왜냐하면 우리는
우리가 사용하고 있는 모델과 경쟁하게 되는 거죠. 왜냐하면, 더 낮은 모델로 대체하고 싶기 때문이죠.
지연 시간이나 더 저렴하죠.그럼 한 번 살펴보겠습니다.다음으로 가볼게요.
최종 평가.어디 보자, 속도를 좀 높여볼게.이것이 실제 엔드-투-엔드 사용 사례입니다.기능 자체도 마찬가지입니다.이는 지금까지 수집한 모든 정보를 기반으로 합니다.큐레이팅을 하고 거의 모든 수익을 올립니다.
평가에서 재사용할 수 있는 구성 요소처럼
지금까지 해왔던 것들이죠.먼저 살펴보자면
어떻게 하면 이 문제를 AI로 해결할 수 있을까요?저희 마케팅 팀 못지않게
저는 AI를 원해요. 모든 것들이요.
그냥 AI가 필요 없잖아요, 그렇죠?따라서 AI 솔루션이 필요하다면 아키텍처에서 선택한 모델들이 문제에 적합한지 아닌가요?잠재적인 부정적 영향을 살펴봅니다.최종 사용자가 의도치 않게 부정적인 선택을 하게 될 수도 있나요?
개인이나 집단을 향해서요, 그렇죠?우리는 데이터 위험을 살펴봅니다.다시 말씀드리지만, 더 넓은 수준에서 보면 단순히 미세 조정만 하는 것이 아닙니다.
그러면 데이터가 노출될 수 있습니다.RAG 시스템을 사용할 수도 있습니다. 앞서 말씀드린 데니스처럼 말이죠.
시스템에서 가져온 데이터도 있지만, 모든 사람이 접근할 수 있는 것은 아닙니다.
알다시피, AI 챗봇은 볼 수 있어야 합니다.그러니까 해야 돼요, 당신은
알다시피, 이러한 우려 사항도 고려하세요.최종 사용자 지원.전화도 거의 할 것 같았어요.
이게 더 많은 권한 부여죠.작업 중인 최종 사용자, 이러한 AI 출력을 받은 최종 사용자는 그것이 AI라는 것을 알고 있을까요?이를 구성하거나 거부할 수 있나요?
원하는 경우 기능을 사용할 수 있나요?조정할 수 있나요?편집도 하고, 수정도 할 수 있을까요?그러니까 AI를 활용하면 거의 더 많은 일을 하게 되는 거죠.그리고 어떤 것이라도 신고할 수 있나요?
그들이 발견한 문제 행동?그러니까 살펴볼 수 있겠죠.가드레일, 데니스는 가드레일의 범위를 잘 보여줬어요.일부 시스템에는 더 많은 가드레일이나 다른 유형의 가드레일이 필요합니다.
다른 가드레일보다.열린 대화식
어시스턴트는 폐쇄형 루프보다 훨씬 더 많은 유형의 공격에 노출되어 있습니다.그리고 우리는 모델로 유입되는 데이터 흐름을 더 잘 제어합니다.그런 다음 전체 시스템 개요를 살펴보겠습니다.AI로 구축된 대부분의 시스템에는 여러 단계가 있습니다.이러한 단계들도 마찬가지입니다. 복합적인 오류가 발생하여 부정적 결과를 초래할 가능성이 있을까요?
고객이 얻을 수 있는 성과는?한 가지 예를 간단히 들어보죠.이 기능은 저희가 만든 기능입니다.
컨택 센터 서비스의 경우 주제 분석이라고 합니다.고객 기록 세트를 가져와서 이유를 추출할 수 있습니다.이 고객들은 전화를 걸고 있습니다.
콜센터에 도움을 요청하세요.다음과 같은 이유를 알아낼 수 있습니다.
콜센터 관리자가 고객이 전화를 거는 이유를 알 수 있도록 고객이 전화를 거는 이유를 알 수 있도록 고객이 전화한 이유를 그룹화하고 주제별로 레이블을 지정합니다.
고객 센터로 연결하세요.이를 자세히 살펴본 결과, 전체 솔루션이 AI에 전적으로 의존한다면 이 단계에는 세 단계가 있다는 것을 알 수 있습니다.그리고 오류가 발생하면
첫 번째 단계에서는 그 다음 단계로 복잡하게 되죠.그래서 우리는 이렇게 하기로 결정했습니다.
UX를 약간 바꿔서 사용자 경험과
인간을 좀 더 일찍 소개하면
클러스터를 검토하고, 편집하고, 재생성 할 수 있어야 합니다.그래서 우리는 사용자에게 약간의 혜택을 제공합니다.
조금 더 강력해진 것은 수만 개의 스크립트를 직접 살펴보는 것보다는 낫지만, 사용자가 최종 모델을 좀 더 잘 제어할 수 있게 해주고 최종 모델을 보다 잘 이해할 수 있게 해줍니다.그리고 저는 떠날게요
콜라보레이션 BU에 한 가지 더 있는데, 저희가 하나 더 개척했습니다.
고객의 신뢰를 얻기 위해 투명성을 향해 한 걸음 더 나아가세요.모든 AI 기반 기능
현재 개발 중인 투명성 노트를 제작하고 있습니다.이를 통해 고객은 데이터의 흐름과 처리 방식과 관련하여 우려할 수 있는 모든 영역을 신속하게 식별한 다음 이 AI 기능이 비즈니스에 적합한지 여부에 대해 정보에 입각한 결정을 내릴 수 있습니다.Cisco의
경험이 AI를 책임감 있게 적용하는 방법을 결정하는 데 도움이 될 수 있습니다.
비즈니스에 적용하세요.그리고 고마워요.다시 연락드리죠, 데니스
(관중들의 박수) - 고마워요, 맷.브리지 비유가 마음에 들어요.정말 잘 된 것 같아요.자, 이제 자동화된 추론에 대해 다시 한 번 말씀드리면서 마무리하겠습니다.
이미 발표된 수표인데요, 조금 설명을 드리자면
어떻게 작동하는지 좀 더 설명해 주세요.그러니까 이건 정말 특별한 거예요.
업계 최초로 제품을 통합한 것입니다.
논리 규칙을 사용한 명시적 추론여기서 말씀드리자면 자연어로 정책을 정의한다는 겁니다.어쩌면 이미 가지고 계실 수도 있습니다.
정책 문서일 가능성이 높습니다.이러한 정책 문서는 구문 분석되어 명시적 규칙으로 전환되며, 이 규칙은 언어 모델에서 작성된 내용을 검증하는 데 적용됩니다.이런 종류의 예제에서는, 가설적으로 말하자면, 다시 말하지만, 일종의 문제에 대해 이야기하고 있습니다.
유니콘 항공사를 예로 들어보죠.예를 들어 정책을 정의하고 규정이 정해지면, 규정은 항공권 변경에 관한 것일 수도 있고, 정책이 항공권의 변경에 관한 것일 수도 있겠죠?읽어주실 수 있을지는 모르겠지만, 유니콘 항공을 타고 원더 시티로 날아갈 예정인데 제 성이
티켓에 철자가 틀렸어요.저는 지금 공항에 직접 와 있어요.변경사항을 직접 제출할 수 있나요?시스템에 따르면 네, 언제든지 항공권에 기재된 이름을 변경할 수 있습니다. 공항에 직접 방문하셔도 됩니다.그러니까 규칙이 있는 일종의 기본 상황인 거죠.
아직 검증되지 않았고 적용되지도 않았죠?이제 확인해 볼 수 있습니다.
특정 규칙에 어긋납니다.자동 추론에 따르면, 아니요, 이건 유효하지 않습니다.규칙은 다음과 같습니다.
그 이유는 다음과 같습니다.그래서 왜 그런지에 대한 설명 가능성까지 내재되어 있습니다.
뭔가 잘못됐어요.다음과 같은 경우 이름 변경이 허용됩니다.
변경이 허용되거나 변경이 허용되고 제출이 유효한 경우에만 가능합니다.제출은 다음과 같은 경우에만 유효합니다.
제출 방법은 이메일입니다.네, 정말 높은 수준의 프로세스인 것 같아요.
자동 추론 검사.로직을 사용하는 거죠.실제로 해당 텍스트에서 추출한 변수도 사용하고 있습니다.그러니까 일종의 1차 논리를 사용할 수 있는 형태로 그 이유들을 추론할 수 있겠죠.그럼 그걸로, 오, 하나
또 하나 말씀드리고 싶은 건 현재 제 생각에는
기능은 미리 보기가 제한되어 있습니다.따라서 제가 틀리지 않았다면 액세스를 요청해야 할 수도 있습니다.하지만 직접 해보시고 방법을 확인해 주세요.
사용 사례에 적합합니다.정말 고마워요.제발 잊지 말아주세요
설문조사를 작성하세요.(관중들의 박수 갈채)