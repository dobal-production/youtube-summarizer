- 리인벤트 2024에 오신 것을 환영합니다.여러분 모두 오늘 아침 Matt의 기조 연설과 우리의 세대 AI 기반 모델에 관한 흥미로운 발표를 들을 기회가 있었기를 바랍니다.오늘은 정말
여기 계신 분들을 위한 흥미로운 패널 토론이 준비되어 있습니다.업계 리더들이 어떻게 기반 모델을 개발했는지, 어떻게 혁신하고 제공할 수 있을지 논의할 예정입니다.
그들의 고객에게 말이죠.저는 슈바 쿰바다코네예요.저는 시니어 매니저입니다.
우리 세대 AI 조직은 AWS에 있습니다.저는 차별화된 세대인 SageMaker HyperPod 서비스의 시장 진출을 이끌고 있습니다.
AI 인프라 오퍼링.오늘은 Jeff가 이 자리에 합류했습니다.패널리스트를 모두 초대할게요
자기소개를 해주세요.그럼 계속해 보는 게 어때요, 제프?- 시작하게 돼서 반가워요.안녕하세요,
여러분, 저는 제프 부디에예요.저는 허깅 페이스의 제품 책임자예요.Hugging Face, 우리의 사명은 훌륭한 머신 러닝을 대중화하는 것입니다. 이에 대해 더 말씀드리게 되어 기쁩니다. - 와심. - 안녕하세요, 여러분, 제 이름은 와심 알 시크입니다.저는 라이터스의 공동 설립자이자 CTO입니다.라이터는 제너레이티브 AI입니다.
엔터프라이즈를 위한 플랫폼이자 혁신을 위한 우리의 사명
기업을 위해 일하세요.우리는 의료 및 금융 서비스 분야의 300개 이상의 대기업을 위한 선도적인 플랫폼을 자랑스럽게 생각합니다. - 그리고 로버트도. - 그리고 저는 로버트 베이코스입니다.저는 HOPPR의 공동 설립자이자 CTO입니다.우리는 기반을 다지고 있습니다.
의료 영상 모델 및 지원할 수 있는 의료 등급 플랫폼
해당 모델에 대한 추론. - 시작하기 전에
패널 토론을 통해 말씀드리자면, 빨리 말씀드리고 싶은데요.
HyperPod가 무엇이고 어떤 기능을 제공하는지 개괄적으로 설명해 주세요.지금 이 자리에 계신 여러분 중 건물을 짓고 싶으신 분이 얼마나 되십니까?
자신만의 기초 모델을 가지고 있거나 어떻게 시작할지 고민하고 계신가요?
세대 AI 모델 제작?(패널리스트들의 웃음) 뭘 보고 계세요?건물을 보고 계신가요?
자신만의 모델을 만들었나요?미세 조정을 고려하고 계신가요?
기존 오픈 소스 모델?어떻게 생각하세요?- [청중] 미세 조정. - “미세 조정”?좋아요.하지만 훈련이 끝나길 바라시잖아요, 알다시피, 두어 개
몇 개의 노드에 GPU를 사용하고 이를 설계하는 방법을 살펴보겠습니다.맞나요?알겠어요.그래서 우리가 상담하는 많은 고객들 중에 이런 일을 하려고 하는 사람들이
방금 말씀드린 것과 정확히 일치합니다. 모델을 미세 조정하거나 자체 기반 모델을 구축하는 것입니다. 일반적으로 그들은
몇 가지 주요 고려 사항.어떤 것들이 있는지 생각해보면
이들이 가장 먼저 생각하는 것 중 하나는 데이터입니다. 예를 들어, “내 준비는 얼마나 되었나요?
모델을 학습시키기 위한 데이터?라벨이 붙어 있나요?얼마나 차별화되었나요?데이터를 충분히 보유하고 있나요?
실제로 모델을 학습시키나요?그렇지 않다면 어디서 이 모든 데이터 소스를 가져오거나 수집할 수 있을까요?어떤 종류의 데이터를 사용하고 있나요?그냥 텍스트인가요?멀티모달인가요?어떤 종류...그게 제게 어떤 영향을 미치나요?
교육을 위해 선택해야 하는 스토리지 및 파일 시스템은 무엇입니까?”두 번째는 “얼마나 많은 GPU 성능이 필요할까요?아니면 얼마나 많은 액셀러레이터나
이 모델을 실제로 트레이닝하려면 컴퓨팅 파워가 필요할까요?”모델의 크기, 데이터 크기, 검토 중인 GPU 시간에 따라 달라지나요?그리고 실제로 어떤 종류의 GPU가 필요할까요?H100이 필요하신가요?A100은 충분한가요?GPU가 아닌 솔루션도 작동하나요?이 모든 것들이
고객들은 비용이 얼마이고 시간이 얼마나 걸리는지 알아내고 있습니다.
실제로 시장에 출시되려면 시간이 걸린다는 거죠.물론 이들이 이런 것들을 만들어내는 것에 대해 생각할 때
수백 개에서 수천 개의 액셀러레이터 컴퓨팅 클러스터, 이 클러스터를 관리하는 방법, 확장 효율성의 작동 방식 또한 중요합니다.모델 학습에 사용하는 GPU 수를 두 배로 늘린다면 교육 성능이 두 배로 향상되는 건가요?그렇지 않다면 어떻게 하면 실제로 즉흥적으로 연습할 수 있을까요?
트레이닝 퍼포먼스?그리고 어떻게 관리하시나요?
컴퓨팅 클러스터는?수백 개가 있다면
그리고 수천 개의 GPU, 어떻게 작업을 제출하고 계신가요?어떻게 확인하고 계신가요?
클러스터 활용도가 최소 100% 에 가깝습니까?그리고 클러스터 가동 시간은 어떻게 되나요?그리고 그것은 바로 복원력이 무엇이냐에 달려 있습니다.
클러스터의 인프라 복원력.이러한 GPU는 얼마나 자주 고장나나요?그리고 얼마나 많은 시간을 소비하고 계신가요?
데이터 과학자는 무엇이 실패했는지 분석하는 데 쓰고, 아니면 실제로 모델 자체를 혁신하고 구축하는 데 쓰고 있나요?이런 이야기를 많이 들었습니다.
고객의 우려와 고객의 의견을 거꾸로 SageMaker HyperPod를 설계하고 구축했습니다.지난 re:Invent에서 출시된 이후로 정말 좋은 성과를 거두었습니다.
고객 유치.정말 울려 퍼지죠.용도에 맞게 제작되었으니까요.
분산형 교육의 경우 원하는 고객의 호응을 얻고 있습니다.
수백 개의 GPU를 대상으로 트레이닝 작업을 시작하거나, 어쩌면 더 적은 수의 GPU를 대상으로 트레이닝 작업을 시작할 수도 있습니다.
100~수만 개 미만이죠.쉽게 확장할 수 있습니다.
고객이 실제로 모델을 학습하는 데 필요한 클러스터의 크기를 늘리거나 줄일 수 있습니다.HyperPod는 실제로 무엇을 제공할까요?그리고 왜 맞춤 제작 용도라고 할까요?
분산형 교육?이를 통해 데이터 과학자는 더 나은 교육 성과를 얻을 수 있습니다.즉, 영구 클러스터를 제공한다는 뜻입니다.
척추에만 있는 것이죠. 그래서 우리는 즉시 줄일 수 있죠.
분산한 순방향 및 역방향 패스로 인해 필요한 네트워킹 오버헤드
교육이 필요합니다.그리고 이 모든 걸 갖추면
노드를 데이터 센터에 최적으로 같은 위치에 배치하고 클러스터로 제공하면 크게 개선될 것입니다.
네트워킹 속도.또한 모든 분산 교육에 대한 지원도 제공합니다.
사용하고자 하는 프레임워크 (FSDP, DeepSpeed, DeepSpeed 등)
아니면 다른 선택도 가능하죠.또한 독점적인 세이지메이커도 제공합니다.
성능을 제공하는 분산형 교육 라이브러리
PyTorch를 통한 개선 사항.따라서 미세 조정이 필요한 경우
라마나 미스트랄을 미세 조정하면 실제로 얻을 수 있습니다
이러한 독점 라이브러리를 사용하면 성능이 향상되지만, 원하지 않고 지금까지 사용하던 라이브러리를 계속 사용하고 싶다면 유연성도 확보할 수 있습니다.HyperPod의 가장 중요한 가치는 복원력입니다.그리고 레질리언스가 왜 그렇게 중요할까요?규모가 어느 정도인지 생각해 보면 이 중 많은 부분이
미세 조정이 일어날 수 있습니다. 단 한 번의 GPU 고장이라도 전체 교육 작업에 지장을 주게 됩니다. 즉, 무엇을 이해하느라 많은 시간을 허비하게 됩니다.
GPU 장애 원인: “애플리케이션 오류였나요?메모리 문제였나요?발열 문제였나요?교체해야 하는 정말 잘못된 노드였나요?
교체하고 교체했나요?”상당한 금액을 지출하고 계시네요
그걸 분석하는 데 걸리는 시간과 실제 결과를 비교하면 되죠.
모델 개발에 시간을 할애하고 싶습니다.세이지메이커 하이퍼팟은 어떻게 작동하나요?
이 문제를 실제로 해결했나요?우린 딥 헬스 좀 하고 있어
클러스터가 가동되는 동안 노드를 체크오프하고, 클러스터가 생성되고 클러스터가 업데이트될 때, 상태 점검을 수행하고,
불량 노드를 교체합니다.클러스터가 가동되고 실행되면 다음과 같은 에이전트가 제공됩니다.
노드 상태를 지속적으로 모니터링하여 결함이 있는 노드, 즉 장애가 발생한 노드를 발견하면 이를 정상 노드로 구성된 웜 풀로 자동으로 교체할 수 있습니다.그런 다음 바로 시작할 수 있습니다.
마지막 체크포인트에서 훈련 일을 그만두세요
S3 버킷에 저장되거나, S3 버킷에 저장되도록 할 수 있습니다.
자동으로 제공됩니다.이제 중요한 점은 바로 이러한 레질리언스의 이점이 실제로 많은 매니지드 서비스가 제공하는 이점이라는 것입니다.장애가 생겼을 때
내부 노드, 매니지드 서비스가 자동으로 실행됩니다.
대신 처리해 주지만, 관리형 서비스는 추상화 계층도 제공합니다.
인프라에서 말이죠.그리고 대부분의 고급 ML 사용자는 이러한 제어 또는 더 깊은 수준의 액세스를 원합니다.
인프라, 즉 노드에 SSH로 연결할 수 있고 니켈 작업을 수행할 수 있다는 뜻입니다.
테스팅 혹은 DCGM 테스팅.그들은 이러한 수준의 가시성을 원합니다.모든 오픈 소스 도구, 프레임워크, 라이브러리를 사용할 수 있기를 원합니다.
그들은 그것을 선택하고 심도 있는 비주얼을 갖고 싶어하죠.
클러스터 및 GPU 사용률의 프로파일링 및 시각화뿐만 아니라 무엇이 좋은지 확인할 수 있는 도구
그들의 클러스터를 다루고 있어요.HyperPod를 사용하면 이 작업을 수행할 수 있습니다. 따라서 HyperPod를 제거하는 동안
인프라 레질리언스 관리에 있어 차별화되지 않은 과업, 즉 컴퓨팅, 네트워킹 등을 계속 사용할 수 있습니다.
프레임워크, 라이브러리.이 모든 컨트롤은 여전히 가능합니다.
아주 많은 부분이 여러분의 손에 달려 있고, 실제로 건물을 지을 수 있고
필요에 따라 성능을 최적화하세요.모든 노드에 대한 루트 액세스 권한을 얻을 수 있습니다.니켈 테스트뿐만 아니라 DCGM 테스트도 수행할 수 있으며 다음을 확인할 수 있습니다.
컨테이너 인사이트를 사용하여 클러스터 사용률을 확인하고 클러스터를 모니터링합니다.
CloudWatch를 통해앞서 말씀드렸듯이 당사는 독점적인 분산형 서비스도 제공합니다.
데이터 병렬을 위한 교육 라이브러리 및
다음을 사용하여 FSDP를 통해 원하는 최적화를 얻을 수 있도록 병렬 훈련을 모델링할 수 있습니다.
이러한 독점 라이브러리.요약하자면, HyperPod가 제공하는 것은
고객이 자신의 삶을 진정으로 혁신할 수 있는 방법입니다.
기초 모델 개발.컴퓨팅을 사용자 지정하고 다양한 GPU를 사용할 수 있으며
AWS에서 제공하는 비 GPU 기반 인스턴스.기술을 선택할 수 있습니다.
사용하려는 스택.워크로드 전체에서 사용할 수 있는 영구 클러스터가 있습니다.노드에 SSH로 접속할 수 있고, 루트 수준의 액세스 권한을 갖고, 모든 제어 권한을 가질 수 있고,
구축 시 원하는 유연성
학습 아키텍처뿐만 아니라 추론 아키텍처도 쉽게 사용할 수 있으므로 Slurm 또는 Kubernetes를 계속 사용하여 오케스트레이션할 수도 있습니다.
작업도 제출하세요.즉, 기존 도구와 기존 기술 스택을 변경할 필요가 없습니다.계속 사용할 수 있습니다.
원하는 도구.그런 다음 저희가 게시한 모델 레시피를 사용하여 쉽게 시작하거나 실행할 수 있습니다.
이러한 클러스터는 오버헤드를 최소화하면서 사용할 수 있습니다.이걸로 이제 돌아가고 싶어요.
패널리스트들에게 넘겨주세요. 먼저 여러분부터 시작하겠습니다, 제프.청중에게 무엇을, 어떻게, 오, 미안해, (웃음) 어떻게 바라는지 알려주면 어떨까요?
2025년과 그 이후를 위한 혁신이 필요할까요?허깅 페이스는 잘 알려진 브랜드입니다.정말 많은 일을 하셨어요
세대 AI 커뮤니티.어떤 것들이 있나요?
2025년은 물론 그 이후에도 혁신을 이루고 싶다고 생각하시나요?- 고마워요, 정말 고마워요. 허깅 페이스에 대해 이야기하기 전에 큰 박수를 보내고 싶어요
Writer AI의 친구들한테는 사람들이 제게 이렇게 물으면 “뭐가 좋을까요?
AI를 먼저 생각하는 회사의 예시죠?”저는 항상 Writer AI를 사용할 거예요. 모든 걸 다 해주고 있으니까요.
영향력을 극대화할 수 있게 해주는 것들이죠.첫 번째는 오픈 사이언스입니다.그들은 최첨단 연구를 통해 가능성의 한계를 뛰어넘고 훌륭한 논문을 발표합니다.두 번째는
오픈 소스 기여.허깅 페이스에 가서 작가 조직을 찾아보면 팔미라 모델 제품군이 있는데, 제 생각에는 14개가 넘는 모델들이 있는데, 허깅 페이스 허브에서 공개적으로 자유롭게 접근할 수 있습니다.제 생각엔 그랬던 것 같아요.
지난 달에만 10,000회 이상 다운로드되었으니 대단한 파급력이죠.게다가 이 사이트는 놀라운 추가 기능을 제공합니다.
제품에 가치를 더하고, 제품에 포함된 기능에 가치를 더하세요.
고객에게 제공한다는 것은 정말, 정말 좋은 예이며, 이렇게 될 수 있어서 정말 기쁩니다.
이 패널에서 여러분과 함께 말이죠.저는 허깅 페이스의 사명을 말하면서 제 소개를 시작했어요.그래서 우리의 사명은 민주화입니다.
훌륭한 머신러닝, 좋은 점은 커뮤니티 중심의 오픈소스에 기반하고 윤리 우선 원칙에 기반한다는 뜻입니다.그리고 우리는 다양한 방식으로 이 작업을 수행합니다.우리는 오픈 사이언스를 통해 이 일을 해냅니다.잠깐 얘기할게요.
그 얘기 좀 더 해볼게요오픈 소스를 통해 이 작업을 수행하고 다음을 통해 수행합니다.
당사의 제품 및 서비스.그러니까 허깅 페이스 허브를 의미합니다.개방형 모델을 사용하는 경우 허브를 통해 모델을 찾고 탐색하고 평가한 적이 있을 것입니다.오늘날 Hugging Face Hub에는 모든 종류의 머신러닝 작업에 사용할 수 있는 모델이 백만 개가 넘습니다.7백만 명이 넘는 사람들이
허브를 공개적으로 활용하여 자체 AI를 구축하고 있습니다.하지만 개인적으로도
이 허브에는 15만 개 이상의 조직이 설립되어 있습니다.
모델을 중심으로 협업하세요.오픈 소스라면 트랜스포머 라이브러리에 익숙할 것입니다. 이 라이브러리에는 텍스트 생성, 추론, 배포 모델, 데이터 세트, 가속화 등 20가지가 넘는 다양한 도구가 있습니다.하지만 더 얘기하고 싶어요.
오픈 사이언스에 대해 말씀드리자면, 그건 뭔가 중요하니까요.
그게 우리 사명에 정말, 정말 중요하죠.우리는 커뮤니티에 기여할 수 있기를 바랍니다.
최고의 폐쇄형 모델이 제공하는 것과 커뮤니티에서 사용할 수 있는 것 사이에 성능 차이가 있는 새로운 기반 모델입니다.이를 위해 HyperPod를 활용합니다.다음에 대해 조금 말씀드릴 수 있겠습니다.
그걸 어떻게 할 수 있는지, 원하신다면, 아니면 나중에 할 수 있어요. - 뭐, 확실히 할 수 있어요
그건 나중에 건드리죠.HyperPod가 새 모델을 만드는 데 어떻게 도움이 되는지에 대해 더 자세히 알아보고 싶지만, Writer와 함께 시작하셨으니 Waseem에 가서 그에 대한 이야기를 들어보고 싶습니다.
작가 헌장이 뭔지.제프가 팔미라 LLM에 대해 언급했잖아요그걸 어떻게 만들고 있는 거죠?뭘 하려는 거예요?
고객을 위해 성과를 내고 계신가요?- 네, 그럼요, 고마워요.고마워요, 제프그래서, 우리가 작가를 시작했을 때...2020년에 작가를 시작했습니다.우리는 도움을 주겠다는 사명 아래 첫날부터 시작했습니다.
엔터프라이즈 혁신 작업.즉, 기본적으로 어떻게
AI가 정말 도움이 될 수 있어요.이렇게 명확한 단계가 보이기 시작하면 2022년, 2023년, 4년 사이로 넘어가는 것과 같습니다. 그리고 우리가 말하고자 하는 건,
Writer를 시작할 당시에는 이러한 모델을 만들어 왔고 매년 더 큰 모델과 더 많은 기능을 통해 더 많은 것을 보게 될 것입니다.
그리고 더 많은 발전이 있었죠.이제 더 큰 모델을 넣을 때마다
좀 더 복잡한 구조물일수록 실제로
더 큰 도전을 해보세요.정말 빠르게 터치하세요. 예를 들어 HyperPod는 최신 모델에 많은 도움을 줍니다.그래서 우리는 최신 모델을 가지고 있습니다.
이건 팔미라 X 004입니다.우리의 프론티어 모델은 오늘날에도 존재합니다.오늘날 시장에서 가장 기능적인 호출 모델이 존재합니다.전 몰라요...기본적으로, 그것을 만들기 위해서는,
이를 위해 HyperPod를 사용합니다.자, 이것이 왜 중요할까요? 모델을 확장하기 시작하면 모델을 만들 때 그 변화가 머릿속에 떠오르기 때문이죠.우리는 변화에서 출발했습니다. “제가 만들 수 있을까요?”
10억이나 20억을 모델링해 볼까요?물론, 노드 하나, 노드 두 개, 큰 문제는 아니죠.”가장 큰 과제는
우리가 이러한 것들을 가져오기 시작할 때 우리와 함께 일하기 시작하세요
몇 천억 단위로 모델링해 보세요.그 단계에서는 기술 뿐만이 아닙니다.
그리고 지식을 갖추려면 하드웨어가 필요합니다.
실제로 신뢰할 수 있고, 실패하지 않아요.이를 바탕으로 우리가 보는 시각과 우리의 시각을 더 발전시켜 보자면
우리가 세우고 있는 비전은 실제로 더 나은 것을 만들기 위해 두 배로 늘리고 있습니다.
모델, 좀 더 복잡한 모델.저희는 그렇지 않다고 굳게 믿고 있습니다.
단지 매개변수가 더 큰 모델일 뿐이죠.의 파라미터 내에서
모델 자체는 유용하지 않습니다.여기에는 지식만 담겨있습니다.우린 뭘 굳게 믿어요
우리는 이것을 심층 모델이라고 부릅니다.이것이 오늘날 우리가 사용하는 모델이고 수백 가지가 있습니다.
조 단위가 아니라 10억 단위가 아니라 10억 달러가 우리의 큰 모델을 능가하기 때문이죠. 왜냐하면 우리는 앞으로 나아갈 테니까요.
레이어의 깊숙한 곳에는 모델 자체에 500개 이상의 레이어가 있습니다. (불분명하죠)자, 이런 종류의 트레이닝을 하려면 사실 믿을 수 있는 무언가가 필요하겠죠. 그냥 “아, 이건 GPU 클러스터야.다 똑같죠.달리고 있어요.”훈련이 계속 진행되고 있는지 확인해야 합니다.
그리고 훈련은 계속됩니다. 특히 훈련에 3개월이 걸릴 수 있는 경우에는 더욱 그렇습니다.
모델당 5개월, 실제로 실패하는 경우
정말 많은 노력이 필요할 수 있습니다. 팀,
실제 구현.자, 큰 부분이기도 하죠.
여기 엄청 빨리 만져야겠네요이 모든 걸 만들기 위해서
하이퍼팟은 우리에게 많은 도움이 됩니다.하지만 가장 큰 도움이 되는 것은 오픈 소스 커뮤니티라는 점이기도 합니다. 다시 연락드릴게요, 제프.이런 놀라운 경험도 없이
오픈 소스 커뮤니티, 특히 Hugging Face가 후원하는 커뮤니티라면 정말 힘들었을 겁니다.
우리가 실제로 혁신할 수 있는 거죠.오늘날 우리가 만드는 모든 것과
모든 혁신이 다가오고 있습니다. 특히 최신 제품은 더욱 그렇습니다.
저희는 2주 전에 자체 진화 모델이라는 것을 발표했습니다. 사실 이 모델은 모든 오픈 소스를 기반으로 만들어졌습니다.
오늘날 시장에는 과학자, 논문, 모형, 데이터가 존재합니다. - 흥미롭게도, 로버트, 호퍼 (Robert) 씨, 호퍼 (HOPPR) 는...의료 분야에서요.진단 영상을 보고 계시잖아요.어떻게 보고 계세요?
기초 모델을 만드시나요?그리고 오픈 소스 커뮤니티를 얼마나 활용하고 계신가요?
모델을 만들기 위해서요?- 네, 그래서 우리가 만들고 있는 건데...그러니까, 아시다시피
아시다시피 의료 영상 데이터는 매우 큰 데이터입니다.다루기 힘들고, 당연히 필요하죠...왜냐하면 우리는 다음에 대해 훈련하고 있으니까요.
16비트 고해상도 이미지. 우리 모델은 한 번에 여러 이미지를 사용할 수 있어야 하는 경우가 많습니다.이를 활용할 수 있어야 합니다.
HyperPod가 제공하는 컴퓨팅 인프라.그 중 하나예요, 알다시피, 정말...저희 서비스에 정말 큰 도움이 됐어요.
AWS에서 이 서비스를 제공할 수 있었죠.아시다시피 이 데이터를 이 안에서 옮길 수 있어야 합니다.
대규모 클러스터는 우리에게 정말 중요합니다.우리는 여러 가지를 사용하고 있습니다...저희는 자체 소유권을 가지고 있습니다.
오픈 소스를 활용하면서 함께 작업하고 있는 비전 트랜스포머
구축을 위한 언어 모델은, 기본적으로
의료 영상의 특징을 식별하고 출력할 수 있는 멀티모달 이미지-텍스트 모델
텍스트를 통해 다양한 형태로 (예비 단계인지 여부)
방사선학 보고서, 연구 결과 목록
연구 결과 또는 결과를 도출할 수 있다는 것
세그멘테이션 마스크, 바운딩 박스 등을 예로 들 수 있습니다.
XML을 통한 표현아시다시피, 숫자는
우리가 거기에서 취하고 있는 다양한 접근법들, 그리고 그 힘을 활용하고 있습니다.
아시다시피, HyperPod가 제공하는 기능은 실제로 사용할 수 있다는 점에서 큰 도움이 되었습니다.
정말 작업해야 하는 대용량 데이터에 맞게 최적화하세요. - 알겠어요, 고마워요
공유해 줘서 고마워요, 그렇죠?그래서 제프, 다시 돌아와서 어떻게 지내는지 말씀하셨잖아요
과학 모델을 살펴보고, 폐쇄형 모델과 비교하여 오픈 소스 커뮤니티에 더 많은 것을 가져오고자 하는 방법을 살펴보세요.두 번 클릭해 봅시다.
좀 더 자세히 설명해 드릴게요, 그렇죠?예를 들어, 어떤 것들이 있나요?
이러한 모델을 구축할 때 데이터 측면에서도 주요 관심사가 되는 것들이죠.
인프라 측면에서요?이 모델들을 만들면서 어떤 것들이 있나요?
곰곰이 생각해보고 계신 게 뭐죠?그런 다음 HyperPod와 다시 연결해 보고 싶네요.
이러한 요구 사항 중 많은 부분을 해결하고 있습니다. - 물론이죠.네, 말씀드렸듯이 저는...우리 오픈의 주요 목표는
우리 연구진인 과학팀은 현존하는 최고의 기술 간의 격차를 좁히는 것입니다.
개방형 모델과 폐쇄형 모델.그래서 GPT-3 세계로 돌아가서 커뮤니티와 함께 BLOOM을 만들었습니다. BLOOM은 출시 당시 최고의 완전 개방형 다국어 서비스였습니다.
1750억 개의 파라미터가 있는 대규모 언어 모델.이후 코덱스 이후 우리 팀은 커뮤니티와 함께 StarCoder 모델 제품군을 만들었는데, 출시 당시에는 이 제품군이 최고였습니다.
코드를 작성할 수 있는 완전 개방형 모델을 사용할 수 있습니다.나중에 우리 과학팀은 IDEFICS인 I-D-E-F-I-C-S를 만들었습니다. 이 모델은 출시 당시에는 다음과 같은 모델 제품군입니다.
다국어 LLM 작업에 사용할 수 있는 최고의 개방형 모델입니다.그리고 최근에는
몇 주 전에 우리 과학팀이 내놓은
소형 LM 모델 제품군인데, 출시 당시에도
이 사이즈에서 출시된 제품 중 가장 좋은 모델입니다.사실 목표는 격차를 줄이는 것입니다. 하지만 HyperPod가 항상 있었던 것은 아니었고 BLOOM 시절이 기억납니다.그러니까 2~3년 전쯤이었죠.더 나은 모델 아키텍처를 찾기 위해 과학을 혁신할 때, 그게 바로 과학이지만 과학을 현실로 만드는 것은 찾아서 사용할 수 있는 모델 체크포인트입니다.
그리고 Hugging Face에서 다운로드해 보세요. 그런 일을 하는 것은 과학적으로 할 일이 아닙니다.이건 정말 하드코어 엔지니어링 작업인데, BLOOM을 만들었을 때 1,000개 정도였어요.
전 세계 모든 조직의 연구원들이 함께 모여 이 프로젝트에 기여했습니다.하지만 실제로 일을 하고 있던 엔지니어들은
BLOOM을 교육할 때 함께 모인 클러스터는 아주 작은 팀이었고 수석 엔지니어는
그 사람이 스타스 베크먼이었기 때문이죠.그리고 Stas는 실제로 이렇게 썼습니다.
그의 경험에 관한 책, 오픈 소스 책. 그의 GitHub에 있어요. 거기서 그는 이야기를 들려주고
그가 이 책을 통해 배운 모든 교훈과 통찰력
BLOOM 트레이닝의 애로사항.좋은 소식은 이제 HyperPod를 사용하면 그럴 필요가 없다는 것입니다.
더 이상 예약하세요 (웃음) 왜냐하면, 모든 불편함이 있기 때문이죠.
저희가 거쳐야 했던 부분들은 HyperPod 내에서 일종의 제품화되어 서비스로 제공되고 있습니다.그래서 제가 IDEFICS에 대해 이야기할 때, 소규모 LM에 대해 이야기할 때, 이것은 우리의 이점을 활용합니다.
HyperPod에서 관리하는 내부 과학 클러스터입니다. 이러한 기능 중 몇 가지를 간략하게 설명해 주셨습니다.
이는 기본적으로 클러스터를 오토파일럿 모드로 설정하는 것이 매우 중요합니다. 말하자면, 사용자는 연구원이고, 기업으로서 유연성을 높일 수 있도록 하기 위해서입니다.
클러스터를 사용하는 방식에 대해서요.그러니까 다음과 같은 것들은요...CPU 파티션이 꽤 커요.크기가 꽤 크다는 것은 48,000개의 vCore가 거의 자동 조종 기능을 갖추고 있어 스팟 인스턴스를 다음과 같이 활용한다는 뜻입니다.
규모를 늘리거나 줄일 수 있습니다.클러스터를 최대 1,000개의 GPU로 확장했습니다.그리고 액세스를 통해
낮은 수준의 메트릭에 대해서는 스마트한 GPU 관리 기능을 사용할 수 있습니다. 그래서 언젠가는
문제가 발생하면 노드를 격리하고 다시 시작할지 아니면 노드를 유지하고 복구할지 결정할 수 있습니다.또한 연구자들을 위해 작성할 수 있는 지표도 이용할 수 있습니다. 예를 들어 뭔가
우리가 매우 중요하게 생각하는 것은 CO2 소비량입니다.
이러한 교육 작업을 통해 우리는 클러스터 사용자로서 GPU 사용률에 대한 메트릭을 얻을 수 있을 뿐만 아니라 이를 계측했습니다.
성능뿐만 아니라 당면한 작업의 CO2 소비량에 대해서도 마찬가지죠.그리고 재구성할 수 있으려면 유연성 또한 중요합니다.
클러스터는 우리 연구팀의 모든 작업과 심지어 그 이후의 작업에 따라 매우 쉽습니다. - 알겠어요.그리고 뭐...스케일링을 말씀하셨잖아요
수천 개의 GPU로그 중 일부는 어떻게 자동화되었나요?
HyperPod에서 도입한 레질리언스 기능이 전반적인 교육 경험에 도움이 되었나요?할 수 있을까요? - 네, 제 생각엔
가장 먼저 떠오르는 것은 GPU 사용률입니다. GPU 수준에서 가장 먼저 떠오르는 것은 다음을 확인하기 위한 것입니다.
자체 복구되지 않고 그냥 돌아다니면서 결함이 있는 노드는 없어야 합니다.하지만 이 또한 클러스터 수준에서 우리가 제대로 작동하는지 확인하기 위한 조치이기도 합니다.
일자리가 들어올 때 자원을 활용하죠.그러니까 축소하면 정말 많은 걸 의미하죠.
클러스터의 전반적인 GPU 사용률이 향상되었습니다. - 알겠습니다. 그리고 Waseem, HyperPod에 대한 교육도 하셨고, 필요한 데이터 포인트가 몇 개 있다고 생각합니다.
얘기도 좀 해봐요.너도 친절하게 해주고 싶니?
모델 확장을 시작할 때 HyperPod가 이러한 문제를 어떻게 해결했는지 경험을 공유해 주시겠어요?말씀하셨는데, 10억에서 20억으로 늘어났다는 얘기도 하셨잖아요.
HyperPod가 수천억 달러에 이르는 데 얼마나 도움이 되었는지만요. - 물론, 그 중 일부는 말이죠. - 실험을 시작하고 실제로 시작한 이후로 가장 중요한 것은 무엇이라고 생각해요.
HyperPod 사용 및 실제 교육, 사용...가장 큰 변화는 도움말뿐만이 아니라
규모 조정 및 구현, 이를 사용하려면 소규모 팀이 필요합니다. 실제로 비용을 관리하는 방식과 이에 대한 사고 방식을 생각하는 것입니다.
사실 리소스 배분이죠.HyperPod를 사용하기 전에는 항상 모든 종류의 트레이닝 클러스터를 한 가지로 생각했습니다. “그게 바로 GPU예요.누가 가장 싸게 줄 수 있겠어요?”우리 모두 진짜로 계속해요
PDGX 클러스터, 비슷한 속도, H100, 동일한 인프라 연결.하지만 HyperPod를 사용하면서 상황이 바뀌었습니다. 왜냐하면 하이퍼팟에서는
사실 무언가에 대한 가시성이 더 높아지기 시작했어요.
훨씬 더 중요하죠. 특히 규모에 있어서는 말이죠.
탄력성과 안정성.보통 하이퍼팟이 나오기 전에는
이에 대해 생각해 볼 겁니다. “제 교육 비용은
클러스터 비용에 추가로 60~ 70% 의 비용을 더하면 클러스터가 종료되어 하드웨어 장애가 발생할 수 있기 때문입니다.”사실, 이 한 가지는
아무도 얘기하지 않아요. 생각보다 많이 실패했다는 거예요.알다시피, 제 생각엔...라마를 믿어요...페이스북이나 메타 AI 팀, 라마 모델에선
마지막으로, 그들은 클러스터가 어떻게 실패했는지에 대해 많이 이야기한다고 생각합니다. 저는
틀린 말이 아닌 것 같아요. 매 시간마다 한 개의 GPU가 고장났어요.다시 생각해보자면 우리가 생각하는 방식과 비용에 대한 생각을 바꾸는 데 도움이 되죠.그래서 결국에는
실제로 보시면, 실제 비용을 계산하는 것은 단순한 GPU 가격이 아닙니다.그래도 중요한건
좋은 가격을 책정해 놓았지만, 사실 탄력성과 안정성에 비해 가장 저렴한 가격이죠. 훨씬 더 중요하죠.여러분이 일을 시작했을 때, 그것은 사실 단순한 일이 아닙니다.전체 작업을 놓칠 수도 있습니다.실제로 사람이 필요할 수도 있어요. 맞은편에서 일하면
시간대가 여러 개라서 누군가가 노드를 고칠 때까지 몇 시간씩 기다리면
노드를 교체하고 수정하세요.자, 이 모든 걸 생각해 보세요
사실 그냥 일어난 일이니까 걱정할 필요 없어요.시스템에서 실제로 모니터링할 수 있습니다. 특히 몇 주 이상에서 몇 개월 동안 한 작업, 하나의 모델로 실행할 때 말이죠.이것은 사실 우리가 내부적으로 실행할 수많은 데이터입니다. 그래서 기본적으로, 먼저,
셋업부터 시작하죠, 아시죠?간단한 클러스터를 예로 들자면, 최소한 몇 백 개의 노드가 필요하겠죠.
아시다시피, 72시간이죠.클러스터가 클수록 연결과 구성에만 더 오래 걸립니다.모든 노드에 동일한 버전과 소프트웨어가 있는지 확인하세요.
버전, 동일한 운영 체제, 해당 노드의 말 그대로 동일한 라이브러리는 실제로...흥미롭네요.무엇과 관련된 것들인가요?
자동화라고 하죠, 아시죠?모든 게, 그냥
처음부터 끝까지, 만들어보세요.사실 슬라이드에는 없지만 여기서 언급할 가치가 있는 것이 하나 있습니다.보통 트레이닝 작업을 할 때는 최소한 다음과 같은 팀이 필요합니다.
4~6명의 AI 운영 엔지니어가 말 그대로 클러스터를 돌보고, (불분명한) 클러스터를 모니터링하고, GPU와 노드를 모니터링합니다.그리고 HyperPod는 그걸 바꾸기만 하면 되죠.이제 말 그대로 엔지니어가 한 명 있어요.이 사람, 그냥 보고 있잖아
모든 걸 다 해줄거야.우리는 자동화에 크게 의존하고 있기 때문에 자동 체크포인트를 통해 이러한 문제를 해결할 수 있습니다.잘못된 노드를 대체하는 자동 복구 기능, 이 모든 게 그냥...AWS에서 처리해 주고, 우리 쪽에서는 (불명료함) 자체에 큰 문제가 없다면 말 그대로 그 과정을 그냥 받아들이고 (불명료) 하는 거죠. 그러니까 지금은 그냥 자유로워요.
또 다른 5~6명의 엔지니어가 말 그대로 도움을 줄 것입니다.
회사의 다른 업무입니다.그러니까 목표와 방법에 대한 생각만 하면 되죠.
실제로 리소스를 할당하는 것은 우리에게 많은 도움이 됩니다. 그리고 이것은 실제로 인프라를 어떻게 사용하는지, 모델을 어떻게 확장할 수 있는지, 얼마나 많은 레플리카를 필요로 하는지, 얼마나 많은 노드를 할당하는지에 관한 것이기도 합니다.이것은 우리의 생각을 바꾸기 시작하고 예산 편성에도 도움이 됩니다. 왜냐하면 이것이 기본적으로 우리가 지출하는 가장 큰 금액이기 때문입니다.
오늘날 Writers에서는 GPU 클러스터를 사용하여 이러한 모델을 구축하고 기업 고객을 위해 대규모로 이러한 모델을 제공합니다. 매번 수십억 개의 토큰이 있습니다.
매일 고객 전반에서 안정성과 고가용성을 제공합니다.많은 GPU가 필요합니다.그들과 팀원이 꽤 많은 사람을 관리하세요.다시 말씀드리지만, 오늘 우리 팀은
여러 시간대를 넘나들세요.정말 힘들었어요. 그래서 실제로 할 수 있는 사람으로 바꾸세요
처음부터 끝까지 관리할 수 있었다는 건 사실 우리에게 큰 승리였어요. - 그리고 제가 뭘 했냐면...Slurm 쓰세요?아니면 쿠버네티스를 사용하시나요?
하이퍼팟 버전인가요?- 지금은 Slurm을 사용하고 있는데 정말 기대됩니다.
쿠버네티에 대해 말이에요.우리는 우리가 할 수 있을 거라고 생각합니다.
추론을 위해 쿠버네티스 하이퍼포드를 활용하세요.이는 차세대 모델을 출시할 때 우리에게 큰 도움이 될 것입니다.이에 대해 우리가 다룬 것, 즉 스스로 발전하는 모델이라고 부르는 것이죠.이것은 새로운 유형의 트랜스포머 메커니즘으로 각 트랜스포머 레이어마다 메모리 레이어가 있습니다. 즉, 오늘날의 고객은
자체 모델을 가질 수 있습니다. 이 모델은 모델을 사용한 동작을 통해 실시간으로 학습합니다.그리고 그 모델들은 여전히
실제로 의존할 경우 쿠버네티스 클러스터에서 안전하고 격리될 수 있습니다.
쿠버네티스 보안을 통해 각 고객의 네트워크를 보호하고
각 모델이 그 주위를 이룹니다.그래서 오늘은 Slurm이었어요. 다음에 대한 계획을 세웠죠.
추론으로 쿠버네티 하이퍼팟을 통해 더 많은 규모를 확장할 수 있습니다. - 좋아요.그리고 어떻게...아까 말씀하셨잖아요. 팀이 아니라 엔지니어 한 명이잖아요. 그러니까 오늘은 각 교육 작업에 한 명, 두 명 정도 배정할 거예요.
하지만 보통 엔지니어 한 명인데 전체 팀 전체와 비교하면
클러스터를 돌봐주는 거요. - 맞아요, 그리고 그들도
모든 프로파일링 도구를 활용할 수 있었고
GPU가 어떻게 활용되고 있는지 명확히 이해할 수 있는 시각화 도구?이런 방법이 어떻게 도움이 되었나요?왜냐하면 넌 정말 대단하거든
팀의 규모를 축소한다는 것은 그만큼 더 많은 것이 가능하다는 뜻이기도 합니다.
가시성이 있어야 그 사람이 성과를 모니터링할 수 있습니다. - 100%.자, 이제 이 가시성 때문에
운영팀뿐만 아니라 우리 과학자에게도 도움을 주고
연구팀은 (불명료하게) 해보겠습니다. 이제 활용도에 대한 가시성이 확보되고
교육 수준, 사전 교육 또는 사후 교육, 활용 또는 문제 또는 실제 확장, 특히 다음과 같은 경우
대량의 데이터, 왜냐하면 하루가 끝날 무렵에는
클러스터는 단순한 GPU가 아닙니다.여전히 CBU와 RAM, 스토리지가 있습니다.모든 데이터를 모니터링해야 하므로 도구가 있으면 도움이 됩니다.
완전한 가시성을 확보할 수 있습니다.그럼, 작전팀이 할 수 있을 때
실제로 모든 것을 볼 수 있습니다. 모든 것을 트리거하고 자동화하여 일종의 이벤트를 넣을 수 있을까요?
실시간으로 트리거하면 많은 도움이 됩니다.그리고 같은 시기에 저희 연구팀도 실제로 작전 부서와 파트너십을 맺고 있습니다.그들은 실제로 사용할 수 있는 도구를 가지고 있고
이들을 모니터링하고 함께 작업하세요.더 이상은 없어요
“베어메탈 클러스터예요.만질 수 없어요.우리는
아무것도 볼 수 없어요.현장에 DevOps가 있어서 클러스터를 관리하고 관리합니다.”이제는 한 사람이 실제로 100퍼센트를 보는 것으로 바뀌고 있습니다.
그 노드들은 좀 더, 그리고 연구팀이 실제로 그들과 파트너십을 맺고 모든 데이터를 보고 있어요.
모든 모니터링. - 좋아요, 그리고 로버트 씨, 16비트 이미지에 대해 말씀하셨는데, 맞아요, 고해상도 이미지인데
모델에 필요합니다.트레이닝은 어땠나요?
HyperPod의 아키텍처는 이 문제를 해결하는 데 도움이 되었습니다.
데이터 관련 문제가 있으신가요?- 네, 그 중 하나는...미안해요, 너무 큰 소리로 말하고 있어요.우리가 당면한 가장 큰 어려움 중 하나는 우리가 사용해야 한다는 것입니다.
인스턴스 유형이 상당히 큽니다. 80GB가 있어야 하기 때문입니다.
수행할 수 있는 GPU 메모리 또는 그 이상의 메모리
우리가 달성해야 할 일.아시다시피, 해당 인스턴스에 액세스할 수 있습니다.
타입은 까다롭습니다.아시다시피 이러한 대금 청구를 준비할 수 있으려면 조정과 리드 타임, 그리고 AWS가 필요합니다.그래서 일단 그렇게 하고 나면 모든 것을 활용하게 되는 거죠...클러스터를 상당히 많이 활용하고 있습니다.
기본적으로 우리의 운영이죠.GPU를 사용하는 모든 것은 거의 독점적입니다.
전체 클러스터를 사용하는 용도죠.Docker를 설치했습니다.
주피터 허브를 클러스터에 설치했습니다.우리는 많은 실험을 합니다.
클러스터 자체에서 말이죠.그래서 우린...도구를 설치할 수 있게 해주는 정말 유연한 도구입니다.
클러스터에 필요한 것은 해당 GPU를 사용할 수 있어야 한다는 것입니다.
알다시피, 다음에 따라 최적의 방식으로
그 워크로드가 얼마인지, 실행 중인지
대규모 훈련 작업이나 클러스터 내 GPU 몇 개만 대상으로 실험을 진행하는 연구원이 필요하죠.그러니까, 아시다시피, 그건 정말...이건 정말 유연한 도구예요. 우리가 할 수 있는 건
정말 필요한 건 뭐든 해 보세요. 어려운 일이죠.처리해야 하는 데이터 유형 때문에 상당히 큰 GPU 인스턴스 유형에 액세스할 수 있어야 합니다.정말 유연하죠.이건
정말 강력한 도구였어요. - 크기가 크기 때문에 이러한 GPU에 데이터를 배포하거나 샤딩하는 방법을 어떻게 생각해 보셨나요?
다루고 있는 데이터세트는?- 그래서 우리는 실제로 클러스터 자체에 자체 분산 파일 시스템을 설치했습니다.FSX도 사용해봤지만 몇 가지 문제가 있었습니다.
FSX에서의 성능도 마찬가지입니다.아시다시피, 이것의 힘은 다음과 같이 내려갈 수 있다는 것입니다.
설치가 가능해야 하는 수준이 낮기 때문입니다.
필요한 도구, 그러니까 그 도구를 사용자 정의할 수 있는 것이죠.
분산 파일 시스템 덕분에 클러스터 전체에 데이터를 저장하는 방식을 최적화하여 워크로드에 맞게 최적화할 수 있게 되었어요. - 좋아요, 이제 그 종류에 대해 두 번 더 살펴보겠습니다.
여러분 각자가 어느 정도 구현해 보신 분산형 교육 기법이죠.이것은 아마도 HyperPod의 모든 액셀러레이터에서 어떻게 이 작업을 수행할 수 있는지, 그리고 여러분이 실험하고 있는 기술 자체의 새로운 혁신에 대해 약간씩 다루고 있을 것입니다.다시 말씀드리지만, 제프, 샤딩에는 어떤 것들이 있을까요?
사용해본 기법이요?실제로 작업한 라이브러리에는 어떤 것들이 있고 오늘 여기 계신 분들과 공유할 수 있는 모범 사례가 있나요?- 네, 사례보다 더 잘 공유할 수 있어요.도서관은 공유할 수 있어요.그래서 더 쉽게 실행할 수 있도록 나노트론이라는 라이브러리를 만들었습니다.
대규모 트레이닝은 Lighteval의 작은 동반자입니다. 평가를 쉽게 실행할 수 있는 방법이죠.일종의 트레이닝이죠.
우리가 사용하는 기술은 실제로 과학팀이 착수하는 프로젝트에 따라 달라집니다.그래서 저는 1,250억 개의 파라미터 모델인 BLOOM에 대해 이야기했습니다.작은 LM, 제 생각엔 우리가 내려간 것 같아요.
10억 파라미터 미만으로, 아주 작은 파라미터에 대해 1억 7,500만 파라미터처럼
이는 스마트폰에 대한 것이므로 작업에 따라 GPU의 개수에 대한 요구 사항이 매우 다릅니다.
얼마나 오래 필요할까요?유연성도 마찬가지고요.
HyperPod에는 작업을 분리하고 정확히 사용할 수 있는 기능이 있습니다.
우리에게 필요한 리소스는 정말 유용해요. - 좋아요, 그리고 당신은 어때요, 와심?디스트리뷰드를 어떻게 보셨나요?
트레이닝 테크닉?어떤 라이브러리를 사용해 보셨나요?어떻게 작동했나요?- 많이 써봤어요
도서관이 많아서 그렇지 않아요...예를 들어, 우리 모델의 각 세대는 사실 (불명료하게) 서로 다른 유형의 라이브러리를 사용했습니다.PyTorch는 활용도가 매우 높습니다.그 중 하나인 Nemo 메가트론을 사용하면...사실 우리는 이러한 모델을 만들고 훈련하는 데 사용했던 구현이었는데, 이것이 바로 하이퍼팟의 장점입니다.예를 들어, 소프트웨어 종류에 대한 제한이 없었어요.
또는 사용하고 싶은 라이브러리.갈 수 있어요, 알다시피...앞서 말씀드렸듯이 설치 수준이 매우 낮습니다.너도 알잖아.너네 놈들이 설치했잖아
자체 파일 시스템 맞죠?어떤 부분이 좋을까요?따라서 매우 높은 수준에 국한되지 않습니다. 예를 들어 (불명료하게) “이것은 특정 SDK이거나
구체적인 구축 방법”, 꼭 많이 알려주세요.예를 들어 최신 모델을 예로 들자면, 자체 구현이 가능하죠.실제로 그래야 할 것은
곧 오픈 소스가 출시될 예정이니 이에 관한 논문이 하나 나와요. 검소한 트랜스포머 (Srugal Transformer) 라고 불리는 것이죠.이 시스템은 자체 레이어 간에 관리형 KV 캐시를 사용하는 시스템입니다.
트랜스포머 레이어 자체는 아주 아주, 아주 사용자 정의했는데도 쉽게 사용할 수 있었습니다.
실제로 HyperPods에서 실행해 보세요.이에 대한 제한은 없었어요.그것도 똑같아요.
PyTorch 또는 이전 모델을 사용하여 작업을 실행할 때.우리는 많은 것을 활용합니다.
니모 메가트론 라이브러리.실제로 작동하고 있었어요.
아무 문제 없이 아주 간단하죠. 그리고 앞으로도 계속 될 거라고 믿어요. 왜냐하면, 알다시피
오픈소스 커뮤니티에는 매일 놀라운 것들이 많이 나오고 있습니다.그리고 유연성도 갖추고 있습니다.
하드웨어 측면에서는 무엇이든 변경하고 활용할 수 있습니다.
제약이 없는 라이브러리죠. 왜냐하면 혁신의 속도만으로도 놀라울 정도니까요.
오픈 소스 커뮤니티는 사실 모든 도구의 핵심입니다.예를 들어, 우리에게 필요하다는 아이디어가 떠오르죠.
특정 하드웨어를 어떻게 사용하는지에 대한 강한 의견을 말씀드리자면
그리고 특정 라이브러리.활용하기 어려울 거예요.
적어도 우리 편에서는요. - 그리고 로버트, 어떻게 지내세요...분산형 교육 라이브러리는 어떻게 살펴보셨나요?HyperPod에서는 어떻게 작동했나요?제대로 작동하려면 어떤 엔지니어링 노력이 필요했나요?- 네, HyperPod에서는 정말 쉬웠어요.DeepSpeed를 사용했을 때는...저희는 주로 사용하고 있습니다.
딥스피드와 파이토치.알다시피, 우리는 현재
다른 모델에 FSDP를 구현하고 있습니다.
현재 작업 중인 것이죠.HyperPod의 관점에서 보면 정말 쉽게 시작하고 실행할 수 있습니다.무엇이든 설치할 수 있습니다.
필요한 라이브러리.말씀드렸듯이, 필요한 만큼 낮은 레벨로 올라갈 수 있고, 정말 완전한 컨트롤을 할 수 있습니다. 제 생각엔...아시다시피, 정말 강력한 기능이죠.아시다시피, 당신은 정말...너도 알다시피, 네가
이런 유형의 데이터, 그리고 이런 유형의 GPU로 이런 규모로 작업하려면 정말 다음이 필요합니다.
워크플로우에 맞게 최적화하려면 반드시 해야 할 일이 있습니다.
모든 손잡이를 돌릴 수 있는 기능을 갖추세요.네, 궁극적으로는 상당한 유연성을 찾은 것 같아요.아시다시피, 이전 버전에서도 우리가 겪었던 어려움은 별로 없었습니다.예를 들어, SageMaker 교육에는 한계가 조금 더 많았기 때문에 정말 만족했습니다.
거기서 HyperPod로 옮긴 거요. - 그리고 꽤 많은 이야기를 나눴습니다.
트레이닝에 대해 폭넓게 다루고 있지만, 트레이닝 후에는 추론이 뒤따르는데, 그게 바로...다른 점이 있습니다.
난관이 많죠?확장성, 처리량, 지연 시간.먼저 시작하겠습니다.
이번엔 당신, 로버트, 그냥 섞어보자면
상황이 좀 나아졌어요.어떻게...어떻게 생각하세요?
모델을 배포하고 계신가요?그 방법에 대해 더 자세히 말씀해 주세요.
그걸 설계하고 계시잖아요.그 중에는 어떤 것들이 있나요?
고려해야 할 사항이 있나요?- 네, 의료 영상에는 아시겠지만 모르겠지만 많은 이미지가 포함되어 있는 경우가 많습니다.예를 들어 흉부 X-레이와 같은 엑스레이에는 보통 정면과 측면의 이미지가 두 개 이상 들어 있습니다.2D 유방조영술은
각각 4K 해상도의 이미지 4개 이상따라서 이제는 이미지 활용 방식을 최적화할 수 있어야 합니다.미안해요, 제 뇌는...(웃음) 저는 공백이 됐어요.클러스터를 활용할 수 있는 능력이 정말 필요해요,
알다시피, 정말 효율적이죠.그래서 우리가 한 일은...우린...오 젠장, 미안해.저는 (웃으며) 빈칸을 그리고 있어요.질문을 정말 빠르게 반복할 수 있나요?- HyperPod 사용에 대해 어떻게 생각하느냐가 관건입니다.
클러스터는 (불분명한) 클러스터이기 때문에-
- 네, 추론용입니다.알겠어요, 네.미안해요.
- 건너편 (불명료). - 미안해요네, 추론을 위해 지금은 사용하고 있습니다.
SageMaker 엔드포인트는 가능하지만 인스턴스 유형 때문에 이미지를 두 개까지만 지원할 수 있습니다.
지원하는 유형.따라서 HyperPod는 두 이미지 이상에서 추론을 수행할 수 있는, 즉 네 개의 이미지를 지원할 수 있는 훨씬 확장성이 뛰어난 접근 방식이라고 생각하고 있습니다.
이미지/한 번에 10개 이미지로, 다음 작업을 수행할 수 있습니다.
우리가 필요로 하는 추론, 그리고 궁극적으로는 더 발전시킬 수 있는 가능성을 모색하고 있습니다.
그 위에 우리만의 대기열 매커니즘이 있죠.아직 그 시점까지는 도달하지 못했어요.1사분기에 출시할 예정인데 아직 출시하지 못했습니다.
아직 문을 열지 않았어요.하지만 더 많은 이미지에 맞게 확장성을 높이는 것도 일종의 접근법입니다. - 영구 클러스터이고 기존 GPU인 경우에도 중요합니다.
가용 용량을 훈련에 활용할 수 있을 뿐만 아니라, 훈련을 마친 후 추론용으로도 활용할 수 있다면 리소스를 최적화하는 데 큰 도움이 됩니다.
이산화탄소 배출과 그 밖의 모든 것들 말이에요. 일반 TCO처럼
해당 인프라 활용.그럼 Waseem, 인프라 구축을 어떻게 생각하고 계신가요?추론을 위해 EKS에 대해 말씀하셨는데요.특별히 가장 중요하게 생각하는 사항이 있으신가요?- 알다시피, 이렇게 말할게요.제 엔지니어 중 한 명이 그냥 말했죠. “하이퍼팟이 만들어낼 것 같아요.
우리의 꿈 중 하나가 실현되었어요. 쿠버네티스에서 모델을 실행하는 거죠.우리는 수년간 이 방법을 시도해 왔습니다.우린...사실 예전부터 사용을 시작했었죠.
이러한 기존 기술은 AWS에서 나왔고, 우리는 말 그대로 베어 메탈에 의존해 왔습니다.
아니면 추론을 실행하기 위한 독립 실행형 서버일 수도 있습니다.Kubernete에서 대형 모델을 실행해 본 경험이 있는지 잘 모르겠습니다.최고의 경험은 아니죠, 아시죠?특히 이러한 모델을 실제로 스케일링하고 자동 스케일링할 때는 GPU가 내부에 있습니다.
쿠버네티는 여러 노드를 넘나듭니다.사실 정말, 정말 어렵습니다. 그래서 SageMaker 팀이 생각해낸 솔루션은 기본적으로
쿠버네티스의 강력한 면인데, 실제로 네트워킹을 할 수 있다면
격리, 자동 크기 조정, 그리고 이를 HyperPod와 연결하여 관리하는 것도 가능하죠.
그 (불분명한) GPU들.사실 아주, 아주 매끄럽게 진행됐죠.이건 뭔가...우리가 찾고 있었어
구현이 정말 기대됩니다.사실 오늘날 우리는 어떻게 시작할지 고민하는 중입니다.
마이그레이션을 하는 거죠. 추론해보면 모델 안에서 먼저 이야기할 때가 아니기 때문이죠.처리 자체에만 국한된 문제가 아닙니다. 특히 엔터프라이즈에서는 더욱 그렇습니다.다음과 같은 어려운 문제가 있습니다.
초당 요청 수, 아시다시피 코코넛은 몇 개입니까?
요청 활용 허용, 해당 모델 간의 일반적인 속도, 가끔은
가용성과 관련된 사항 및 확인 사항
SLA가 99% 를 넘습니다.거기서부터 활용하세요. 그러니까 이 방법이 정말 좋은 해결책이 될 수 있겠죠.
서버리스와 비슷하지만 여전히 쿠버네티입니다.얼마나 많은지 아직 알 수 있습니다.
활용 방법 및 구현 방법, 1초 남았습니다.
더 놀라운 부분이죠.제 CFO는 사실 로저 씨, 좋아해요. 이제 다음과 같이 볼 수 있으니까요.사실 제 비용은요.제 마진 알잖아요.제가 실제로 얼마나 하는지 알잖아요우리는 고객이 비용과 확장에 대해 생각하고 생각하도록 도울 수 있습니다.기본적으로, 많은 고객들이 관심을 덜 받는 것을 볼 수 있습니다.
하루에 얼마나 많은 사람들이 통화하는지, 그들은 동시에 얼마나 많은 대화를 하느냐에 더 신경을 씁니다.
두 번째 요청이 들어오고 때로는 그 반대의 경우도 있습니다.그리고 이 모든 것이 우리가 실제로 서비스를 제공하는 데 도움이 됩니다.
더 나은 방법으로 고객님. - 그리고 Jeff, 현재 HyperPod를 사용하고 계신가요?
추론용 클러스터를 사용하시나요?아니면 할 계획인가요?- 그래서 오늘날 우리는 교육에 초점을 맞춘 과학 클러스터를 가지고 있고, 프로덕션 인프라를 갖추고 있습니다. Hugging Face를 통해 발생하는 많은 추론이 이루어지고, 모두 HuggingChat과 같은 쿠버네티스 (HuggingChat) 로 관리됩니다.오픈 소스와 같습니다.
ChatGPT는 무료로 사용할 수 있습니다.제가 말씀드린 추론 API 같은 것들이요.허브에서 사용할 수 있는 백만 개의 모델을 모두 사용해 볼 수 있습니다.
페이지에서 바로 확인할 수 있습니다.배포하려는 경우 추론 엔드포인트 같은 것
프라이빗 모델을 포함하여 허브에서 호스팅되는 모든 모델을 위한 전용 인프라.하지만 우리에게는 추론이 매우 중요합니다.
이 사명에 중요한 역할을 합니다. 추론이란 고객이 자체 인프라 내에 배포할 수 있는 능력을 의미합니다. 따라서 사용 가능한 일부 모델을 사용하면
AWS의 Hugging Face에서는 아마도 다음과 같은 제품을 사용하고 계실 것입니다.
딥 러닝 컨테이너.우리는 구축하고 유지 관리합니다.
모든 허깅을 사용할 수 있는 딥 러닝 컨테이너
자신의 테넌시 내에서 모든 종류의 훈련과 추론을 수행할 수 있는 환경에서 모델을 바로 사용할 수 있습니다. 이는 정말 중요합니다. 소수의 회사가 통제하는 세상에서는 살고 싶지 않기 때문입니다.
모든 회사나 사용자가 가지고 있는 모든 경험.우리의 일상적 경험 중 상당수
이미 AI로 구동되고 있으며, 이는 가속화될 것입니다.소수에 불과하다면
이 모든 것의 배후에 있는 모델들은 정말 많은 문제를 야기합니다.우리가 살고 싶은 세상은 AI가 매우 탈중앙화되어 있고 그 안에 있는 세상입니다.
모든 회사가 회사를 설립하고 호스팅할 수 있는 능력
자체 모델.그리고 할 수 있을 때만 가능하죠
실제로 제어할 수 있는 모델을 직접 빌드하고 호스팅하세요.
보호할 수 있는 고객 경험
고객 데이터.API의 기반이 되는 GPT 모델은 하루가 다르게 바뀌는 경우가 많습니다.알아차리지는 못하겠지만, 갑자기
고객 경험이 변화함에 따라 인터넷을 통해 타사 공급자에게 고객 정보를 보내야 합니다.그래서 업계에는 정말 많은 문제가 있다고 생각합니다.
예상할 수 있겠지만, 회사가 자체적으로 호스팅할 수 있는 다양한 옵션을 제공하는 것이 매우 중요합니다.
자체 AI를 제어하세요.최근 예로 HUGS를 들 수 있습니다.그럼, 포옹을 위한 거지요.
Face Gen AI 서비스는 저희가 출시한 새로운 서비스입니다.
불과 몇 주 전이었죠.AWS 마켓플레이스에 있고, 최적화된 환경을 갖추고 있습니다.
자체 AWS 테넌시에서 호스팅할 수 있는 가장 인기 있는 개방형 모델을 즉시 배포할 수 있습니다.하지만 처음 질문으로 돌아가서 흥미로운 점은 HyperPod를 통해 클러스터를 원하는 방식으로 활용할 수 있다는 것입니다. 따라서 교육 작업 시 과학 클러스터에 있는 용량을 사용할 수 있다는 것입니다.
과학팀의 교육 워크로드는 그것을 완전히 활용하지 못하고 매우 역동적인 방식으로 우리의 생산 인프라에 추가하는 데 할애할 것입니다. - 맞아요, 그리고 여러분은
마켓플레이스뿐만 아니라 다른 것들도 언급했잖아요.
AWS를 껴안는 얼굴이 통과할 수 있는 통로들
파트너십은 활발합니다.클라우드 서비스 공급자로서 AWS와 파트너 관계를 맺은 것이 실제로 어떤 도움이 되었는지에 대해 말씀드리고 싶었습니다.
허깅 페이스의 사명.이게 정말 어떻게 도움이 되었나요?
더 빨리 도달하거나 자신의 능력을 강화하는 데 도움이 되었죠.
시장에서의 지위는?- 매우 시너지 효과가 있는 콜라보레이션입니다. 왜냐하면 우리 회사를 통해
AWS와의 협업...세이지메이커에 대해 말씀드렸어요.
Hugging Face 모델을 배포하고 학습하는 데 모두 사용할 수 있는 딥 러닝 컨테이너를 사용할 수 있을 뿐만 아니라 새로운 Trainium과 Inferentia를 개발하는 팀과도 협력하고 있습니다.
맞춤형 AI 액셀러레이터.제 생각엔, 오늘 아침 일찍
트레이니엄 2가 발표됐어요.정말, 정말 기대가 됩니다.그래서 이번 협력을 통해 고객이 자체 AI를 쉽게 구축할 수 있을 뿐만 아니라 비용 효율성도 높일 수 있게 되었습니다.따라서 Inferentia와 Trainium을 사용하면 직접 사용할 수 있습니다.
허깅 페이스 모델과 함께 말이죠.우리는 다음을 만들기 위해 오픈소스를 구축합니다.
쉽게 할 수 있습니다.마켓플레이스에는 머신 이미지가 있습니다.
AMI는 자체 워크로드를 설정하는 데 사용할 수 있습니다. - 그리고 Waseem, 같은 질문이 있습니다. 이 파트너십이 Writer에게 어떤 도움이 되었나요?이에 대해 의견이 있으신가요? - 아시다시피, AWS와 파트너십을 맺을 때 가장 눈에 띄는 것은 일반적으로 AWS는 기술이 단순한 것이 아니라는 것을 이해하고 있다고 생각합니다.
소프트웨어와 문서.직접 가서 알아내세요.예를 들어 HyperPod 자체는 시스템으로서 구현하기가 그리 복잡하지 않지만 여전히 새로운 기술입니다.그래서 초창기 시절을 기억합니다.
하이퍼팟을 소개했을 때죠.사실 저희 팀은
Slack에서 온라인으로 저희와 함께했어요.전화가 왔어요, 당신
하루에 몇 시간 동안 엔지니어가 도구를 활용하고 실제로 사용할 수 있도록 교육해야 한다면 실제로 많은 도움이 됩니다.그래서 제품을 사용하고 있는 것처럼 느껴지지는 않을 것 같고, 실제로 진정한 파트너십으로 느껴지죠.정말 신경 쓰시는 게 뭐냐면
시스템을 실제로 활용하고, 구현하고, 교육하는 것, 그리고 그뿐만이 아니라...아시다시피, 저는 HyperPod에 대해서만 말씀드렸습니다. 최근 경험에 대해서만 말씀드렸지만, 이는 다른 서비스에서도 마찬가지입니다.AWS와의 전반적인 파트너십에 감사드리며, 어떤 상황에서든 이를 이해해 주셔서 감사합니다.
회사 규모가 크든 작든, 그들은 여전히 실제로
그런 세부 사항들에 신경 써주세요. - '케이, 로버트, 당신은 어때요?- 네, 솔직히 AWS와의 파트너십이 우리에게 큰 도움이 되었습니다.
우리가 하고 있는 일을 하기 위해서요.AWS가 없었다면...먼저 스노우볼 디바이스에서 데이터를 로드하고, Spark 작업을 통해 대규모로 익명화되고, 상주하던 지역의 컴퓨팅 클러스터로 이동한 다음, 데이터를 FSX로 이동하고, 클러스터로 이동하고, 대규모로 훈련할 수 있습니다.정말 모든 것이 전부입니다.
전체 스펙트럼을 통틀어 우리가 가진 것을 상대적으로 성취할 수 있게 해주었죠.
엔지니어 그룹이 적기 때문에 기술적인 측면에서 볼 때 파트너십은 환상적이었습니다.지원 측면에서 보면 우리는 훌륭한 파트너십을 맺고 있습니다. 문제가 발생했을 때 차단을 해제할 수 있고, 심지어 전략적인 관점에서도 말이죠.
우리가 어디로 가고 있는지, 어떤 문제점이 있는지를 이해하기 위해 당사와 협력하는 것
우리가 경험한 것들, 그리고 우리가 활용하고 있는 서비스를 반복하기 위해 어떻게 피드백을 제공할 수 있을까요? - 좋아요, 감사합니다.이제 거의 시간이 다 되었으니 시간을 좀 내볼까 합니다.
오늘 와주신 세 분 모두에게 감사드리며
청중과 대화하고 있어요.또 어떤 Q&A에도 공개하고 싶어요. 저희가 여기 있을 거예요, 저는
다음 세션이 시작되기 5분 전, 그러니까 연단에 와서 질문을 하고 싶으시다면
저희와 대화를 나누시거나 그냥 채팅해 주세요. 부담없이 말씀해 주세요.하지만 모두 고마워요
이 세션에 참석해 주셔서 감사합니다. 패널리스트들께 감사드립니다.
시간을 내어 이야기해 주셔서 감사합니다.(청중 박수) - 감사합니다. - 감사합니다.(로버트는 불분명하게 말한다)