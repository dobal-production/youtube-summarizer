[음악 재생] 수석 부사장을 환영합니다
피터 드산티스 (Peter DeSantis) 는 AWS의 유틸리티 컴퓨팅 담당 부사입니다.[음악 재생] 감사합니다.리인벤트 2024에 오신 것을 환영합니다.[관객 응원] 그리고 함께 해주셔서 감사합니다.
먼데이 나이트 라이브의 또 다른 에피소드로
아니면 제가 키노트 이브라고 부르고 싶은데요.우리에겐 멋진 밴드가 있고 맥주도 맛있어요.하지만 사과하고 싶지만.알고 보니 IPA가 하나도 없었어요.내년에 수정하겠습니다.
IPA 애호가들을 위해.미안해요, 그건 제 잘못이에요.좋아요.오늘 밤, 우리가 할게요
우리가 평소에 하는 일이죠.이제 더 자세히 알아보도록 하죠.
몇 가지 기술적 혁신.그리고 여느 훌륭한 키노트 이브처럼
포장을 풀어야 할 선물을 하나 받을 수 있을지도 몰라요.하나쯤 있을지도 몰라요. 두고 봐야죠.하지만 시작해볼게요
가장 중요한 것부터 말씀드리자면, 저희가 여기서 하고자 하는 일입니다.
먼데이 나이트 라이브에서는 그 방법을 살펴보죠.그리고 어떻게 하느냐가 중요하죠.
왜냐하면 가장 중요한 몇 가지를 어떻게 전달하느냐가 중요하기 때문입니다.
클라우드 컴퓨팅의 특성.이는 단순한 기능이 아닙니다.
바로 시작할 수 있습니다.필요한 건 이런 것들이에요.
서비스를 디자인하는 것, 그게 바로 우리가 하는 일입니다.이런 것들이 일종의 징후입니다.
우리가 건물을 짓는 방식에 대해서요.그리고 오늘 밤엔 그럴 수도 있겠다는 생각이 들었어요.
조금 설명해 드리면 재미있을 것 같아요.
AWS가 유일무이한 우수하다고 생각하는 이유에 대해
이러한 기능을 제공하는 데 능숙합니다.그리고 이 부분을 준비하면서
Keynote에서 사용해 보기로 했습니다.
AI 어시스턴트.저는 그 방법에서 영감을 받았어요.
저희 팀과 아마존 전역의 모든 팀들
AI 어시스턴트를 사용해 일을 해왔습니다.
코드를 작성하고, 크리에이티브를 만들고, 이렇게 될 줄 알았어요.
실험해 볼 수 있는 재밌는 기회였어요.그래서 AI 어시스턴트에게 어떻게 시작하고 싶은지 말했어요.
이 프레젠테이션을 어떻게 시각화하고 싶은지요.그리고 몇 가지 아이디어가 떠올랐어요.제가 처음 떠올린 아이디어는 빙산이었어요.왜냐면 제가 얘기하고 싶었던 건
표면 아래에 있는 것이었는데 저는 별로 마음에 들지 않았어요.
빙산의 비유죠.빙산이 있으면 볼 수만 있습니다.
빙산의 작은 일각이지만 아래에 있는 건 얼음뿐입니다.두 번째 비유는
훨씬 나아졌어요.우주 비행이었어요.AI 어시스턴트가 말했죠.
설명해 드리자면, 출시 기간은 짧지만 엔지니어 팀이 많다는 것을 말씀드리고 싶습니다.
그리고 배후에서 운영자와 디자이너가 함께했습니다.그게 좀 더 이해가 됐어요.
하지만 아직 제대로 자리를 잡지는 못했어요.
제가 찾고 있던 것에 대해서요.그래서, 조금 더 뒤로 물러나서
제 AI 어시스턴트와 이야기를 주고받으면서 제가 가기로 결정했습니다.
나무에 대해 이야기하기 위해서요.나무는 큰 것을 상징합니다.
매년 논의하는 차별화된 기술 투자.장기 투자와 같은 것들이죠.
최고의 성능과 최저 비용의 인프라를 가능하게 하는 맞춤형 실리콘에 대해
AWS 고객을 위한 옵션.또한 AWS에 대한 우리의 투자도
보안을 지원하는 사용자 지정 하이퍼바이저
서버리스 컴퓨팅.아니면 우리의 대규모 투자
우리가 제공할 수 있는 데이터베이스 기술에
차별화된 데이터베이스 기능 및 성능먼저 말씀드리기 전에
오늘 밤 나무에 대해 말씀드리자면, 뿌리와 중요한 구조물에 대해 말씀드리겠습니다.
지탱해 주는 나무 아래
그들에게 영양을 공급해 주세요.그리고 원뿌리부터 시작해볼게요.모든 나무에 원근이 있는 것은 아니지만, 원근은
지표면 아래 깊은 곳에서 독특한 방식으로 물을 이용할 수 있어 나무도 잘 자랄 수 있습니다.
조건이 혹독할 때.그리고 가장 독특한 것 중 하나
AWS와 Amazon의 장점은 리더들이 지출하는 방식입니다.
세부 사항에 상당한 시간을 할애하고 이러한 세부 사항을 파악하는 것이 중요합니다.
이러한 세부 사항을 파악하면 실제로 무슨 일이 벌어지고 있는지 알 수 있기 때문입니다.
고객과 서비스를 함께 활용하면 여러분의 역량이 강화됩니다.
신속한 의사 결정 (수정 또는 예방 가능)
문제가 발생하기도 전에 말이죠.다른 곳에서도 이런 일이 일어납니다. 하지만 이런 정보는
조직의 여러 계층에 스며들어야 합니다.이런 일은 절대 일어나지 않습니다.
충분히 빨리요.얼마나 재미있었는지 생각해 보세요.
일이 잘 안 풀릴 때 상사에게 알리기 위해서죠.그 누구도 가장 좋아하는 일이 아니며, 보통은 그런 일이 일어나지 않는 경우가 많습니다.
거의 충분히 빠르게 말이죠.이제 쉽게 당신이라고 말할 수 있습니다.
세부 사항에 대해 자세히 알아보고 싶어요.어려운 부분은 건물을 짓는 것입니다.
확인해야 할 메커니즘은
대규모로 할 수 있죠.그게 바로 우리가 하는 일입니다.이에 대한 좋은 예가 하나 있습니다.
매주 수요일에 AWS 차원의 운영 회의가 열리나요?
모든 팀이 함께 모여 문제를 논의하고, 배운 내용을 공유하는 자리입니다.
그리고 서로에게서 배우세요.이것이 중요한 메커니즘입니다.
저를 포함한 우리의 지도자들을 세세한 부분까지 놓치지 않기 위해서죠.자, 이제 자세히 살펴보죠.
다른 면에서도 도움이 되죠.그 방법 중 하나는
어려운 장기적 결정을 더 쉽게 내릴 수 있도록 하는 것입니다.
우리가 내려야 할 일이죠.좋은 예가 바로 그 결정이었습니다.
투자를 시작하기 위해 내린 결정입니다.
맞춤형 실리콘에 말이죠.자, 오늘은 이런 것 같아요.
당연한 결정인 것 같지만 12년 전
전혀 명확하지 않았어요.세부 사항을 살펴보니까 알 수 있었죠.
절대 성과를 낼 수 없을 거라는 걸
Nitro 같은 것이 없어도 AWS에 필요했던 보안도 말이죠.그래서 우리는 가입하기로 결정했습니다.
안나푸르나 팀과 함께 어떤 결과가 나왔는지 알아냈습니다.
우리 사업의 가장 중요한 기술적 원동력 중 하나죠.만약 우리의 심층적인 문제가 아니었더라면
어려움을 이해하고 있었다면 우리는 쉽게 기다리기로 결심할 수 있었을 것입니다.하지만 다행스럽게도 우리는 기다리지 않았습니다.그리고 AWS의 이야기는 전적으로
그 결정 때문에 달라졌죠.이제 오늘 밤 이야기를 나눠보죠.
그 이야기의 다음 챕터죠.비유가 마음에 들긴 하지만
원뿌리에 대해 말씀드리자면, 깊은 뿌리는 지지하는 게 아닙니다.
가장 거대한 나무들.대신 나무는 다음에 의존합니다.
수평 뿌리 구조.이것의 흥미로운 예가 하나 있습니다.
수평 루트 구조는 버트리스 루트 시스템입니다.
아마존 열대우림의 모습이죠.이러한 지상 루트 시스템
세계에서 가장 큰 나무 몇 그루를 지원합니다.
불안정한 토양 시스템에서 자랍니다.그리고 지지대 뿌리는 수백 개에 달할 수 있습니다.
나무 밑둥에서 몇 피트 떨어진 곳에도 실제로
주변 나무와 맞물려 나무를 지탱할 토대를 만드세요.
열대 우림의 거대한 거인들.그러다 보니 또 다른 이야기가 떠오릅니다.
AWS의 독특한 특징, 혁신 능력
데이터 센터 전력에서 네트워킹에 이르기까지 전체 스택에 걸쳐
칩, 하이퍼바이저, 데이터베이스 내부에 이르기까지
고급 소프트웨어까지.투자하는 회사는 거의 없습니다.
너무 많은 중요 구성 요소에 걸쳐 너무 깊숙이이번 주에는 그 방법을 보여드리겠습니다.
이러한 폭넓은 혁신을 통해 우리는 매우 독특하고 독창적인 제품을 만들 수 있습니다.
귀사, 즉 고객을 위한 차별화된 역량.하지만 이러한 버트레스 루트 시스템은
나무가 서로 연결되는 놀라운 방법 중 하나일 뿐입니다.아마도 가장 놀라운 것일지도 모릅니다.
우드 와이드 웹은 예상치 못한 모습입니다.우리는 흔히 버섯을 떠올립니다.
땅에서 자라는 이 균류처럼요.하지만 사실 버섯은
땅 밑에서 자라는 균류의 열매인데요, 사실 거대한 유기체죠.
나무 뿌리에 서식합니다.그리고 나무에는 공생이 있습니다.
이 곰팡이와의 관계, 그리고 이 곰팡이는 의사소통을 위해 이 균류를 이용합니다
서로 정보와 자원을 공유하죠.그리고 이것이 숲을 만듭니다.
어떤 나무보다도 강하죠.이게 제 생각을 떠올리게 해줘요.
AWS에서 가장 중요하고 독특한 점은 이를 뒷받침하는 문화입니다.
우리가 하는 모든 일.제가 AWS나 아마존에 가입했을 때
1998년에 젊은 엔지니어였을 때 저는 집중력이 너무 강해서 놀랐습니다.
우리의 리더십은 문화를 구축하는 데 심혈을 기울였습니다.
우리 회사의 발전 초창기에 말이죠.우리의 고위 경영진은 시간을 들였습니다.
규모를 확장할 수 있는 메커니즘을 구축하기 위해서였습니다.
오늘날의 회사를 위해 말이죠.시간을 내어 글을 적었습니다.
우리의 리더십 원칙.우리는 시간을 들여 술집을 지었습니다.
솔직한 태도를 유지하기 위한 모금 프로그램
사람들에게 높은 기준을 제시하는 것에 대해
우리가 고용하고 싶었던 사람이었죠.주간과 같은 메커니즘을 만들었죠.
앞서 보여드린 운영 회의
우리가 의존하고 있지 않은지 확인하기 위해서요
좋은 의도를 바탕으로 규모를 키웠죠.이제 돌이켜보면 쉽게 알 수 있습니다.
제가 그 긴급성에 대해 얼마나 틀렸는지
이러한 투자에 대해서요.문화에 관한 것
가지고 있든 없든 둘 중 하나죠.만약 그렇지 않다면
행운을 빕니다.그리고 우리 문화는 특별해요
이는 꾸준한 집중력을 유지하면서 규모를 확장하는 데도 도움이 됩니다.
보안, 운영 성능, 비용 및 혁신에 중점을 둡니다.그리고 정신적으로
스케일링 이노베이션에 대해 저는 뭔가를 시도해 볼 거예요.
오늘 저녁에 새로 왔어요.흥미로울 줄 알았는데
몇 가지 혁신에 대해 들어보셨으면 좋겠습니다.
오늘 밤, AWS의 다른 리더들과 이야기를 나눠보겠습니다.
이러한 혁신 중 일부를 주도하고 있습니다.그러니 저와 함께 환영해 주세요.
AWS 담당 부사장이자 오랜 기간 동안 AWS를 이끌어 온 리더로
컴퓨팅 및 네트워킹, 데이브 브라운[음악과 박수] 음, 고마워요 피터.여기 오게 돼서 반가워요.제 AWS 여정이 시작되었습니다.
거의 18년 전, 14명으로 구성된 소규모 팀의 일원으로
남아프리카 케이프타운에서요.그리고 우리는 건물을 짓고 있었습니다.
어떻게 하면 탄력적 컴퓨팅 클라우드인 EC2가 될 수 있을까요?그리고 우리의 사명은 야심찬 것이었습니다. 바로 아키텍처링이었습니다.
궁극적으로는 계속 발전할 기본 오케스트레이션 레이어였죠.
클라우드를 강화하기 위해서요.그 당시에는 몰랐던 것이
이건 많은 일의 시작에 불과하다는 걸
컴퓨팅의 더 큰 변화.그 이후로 저희는 계속 발전해 왔습니다.
모든 면을 재창조하는 여정
인프라의 가치를 극대화하고 복원력, 성능 및 효율성을 극대화합니다.
고객을 위해.그리고 그 중 상당 부분이
여정은 당사의 맞춤형 실리콘 개발에 뿌리를 두고 있습니다.Graviton을 처음 소개했을 때
2018년에는 소유하는 것이 전부가 아니었습니다.
가장 빠른 칩이죠.보내는 게 더 중요했어요
개발자들에게 진정한 가치를 안겨주면서 시장에 신호를 보냈습니다.
다양하게 활용할 수 있는 하드웨어, 그리고 업계 협업의 촉발
데이터 센터의 Arm을 중심으로 말이죠.그런 다음 시야를 넓혔습니다.
훨씬 더 야심찬 것이죠.당사의 첫 번째 특수 목적 프로세서
완전히 기초부터 설계되었습니다.그래비톤2를 통해 우리는 초점을 맞출 수 있었습니다.
특히 스케일 아웃 워크로드에 대한 이유는 바로 이런 이유 때문입니다.
저희 고객들은 이를 보고 추진해 왔습니다.
당시의 경계는 웹 서버와 컨테이너화였습니다.
마이크로서비스, 캐싱 플릿, 분산 데이터 분석.바로 이 순간이 Arm이 만든 순간이었습니다.
정말 데이터 센터에 도착했습니다.그리고 Graviton3를 사용하면서
우리는 범위를 확장하여 상당한 성과를 거두었습니다.
전반적인 성능 향상.우리는 특별한 성능을 요구하는 특수 워크로드에 초점을 맞췄습니다.
컴퓨팅 파워와 그 결과는 놀라웠습니다. 머신러닝 추론을 통한 결과였죠.
과학적 모델링, 비디오 트랜스코딩에 이르기까지
및 암호화 연산.성능이 두 배 이상 향상되었습니다.
많은 컴퓨팅 집약적 워크로드에 적합합니다.그리고 오늘날 Graviton4는
우리가 지금까지 배운 모든 것의 정점입니다.
클라우드에서 프로세서 구축.저희 제품 중 가장 강력한 칩이죠.
멀티 소켓을 지원하고 세 번 사용할 수 있습니다.
오리지널 vCPU 수를 자랑하는 이 제품은 업계 최고의 판도를 뒤흔들 수 있습니다.
대규모 데이터베이스와 같은 까다로운 엔터프라이즈 워크로드
그리고 복잡한 분석.그리고 매 세대마다
Graviton을 통해 고객은 간단하게 다음을 수행할 수 있었습니다.
최신 인스턴스 유형으로 전환하면 즉시 확인할 수 있습니다.
성능 향상.이제 방법을 살펴보겠습니다.
Graviton의 성능을 최적화했습니다.
실제 워크로드에 적합합니다.최신 CPU는 정교한 CPU와 같습니다.
프런트엔드를 가져오는 어셈블리 파이프라인
명령과 이를 실행하는 백엔드를 디코딩합니다.성능을 평가할 때
다양한 워크로드가 마이크로 아키텍처에 어떤 스트레스를 주는지 살펴봅니다.
CPU의 문제죠.자, 워크로드는 민감할까요?
같은 요인에 영향을 받는 프런트엔드 스톨에
브랜치 수, 브랜치 대상, 지침 수, 워크로드 등
백엔드 스톨의 영향을 받는 성능에 민감합니다.
이는 L1, L2, L3 캐시에 있는 데이터의 영향을 받습니다.
그리고 명령 창 크기.요즘에는 전통적으로 마이크로벤치마크가
스트레스에 익숙해져 왔습니다.
프로세스 아키텍처.하지만 이 벤치마크를 예로 들어 보겠습니다.
L3 캐시가 생성되고 있습니다.
엄청난 수의 백엔드가 멈췄습니다.엔지니어링 용어로 말하자면, 이것은
CPU 파이프라인이 엄지손가락을 빙빙 돌리고 있습니다.
계속 들어오는 데이터를 기다리고 있습니다.
L3 캐시에서 쫓겨났습니다.그리고 수년 동안 업계는
벤치마크 최적화에 집착해 왔습니다.
바로 이것과 똑같습니다.하지만 이건 마치 훈련 같아요
100미터 스프린트를 해서 마라톤을 할 수 있는 거죠.물론, 두 경우 모두 달리고 있는 거지만, 기본적으로는 훈련을 하는 거죠.
다양한 도전을 위해 말이죠.실제 워크로드는 그렇지 않습니다.
이렇게 깔끔하게 행동하세요
그리고 깔끔한 벤치마크도 있고요.지저분하고 예측이 불가능하죠.
솔직히 훨씬 더 흥미로워요.어떤 일이 벌어지는지 한 번 살펴보죠.
이 마이크로벤치마크를 실제 애플리케이션 옆에 두면
카산드라, 그루비, NGINX처럼 고객이 사용하는 워크로드는
매일 실행되고 있습니다.마이크로벤치마크가 전부였는데
백엔드 지연에 대해 말하자면, 실제 워크로드에서는 병목 현상이 발생합니다.
완전히 별개의 요소 집합입니다.분기 예측 변수가 더 많이 누락되었습니다.명령어 누락이 많이 있습니다.
L1 및 L2 캐시에서 나왔습니다.TLB 미스가 있습니다.그리고 마이크로벤치마크와 달리 프런트엔드가 문제를 일으키고 있습니다.
모든 것이 멈췄습니다.그리고 이것은 프론트엔드로 요약할 수 있습니다.
스톨은 더 높지만 백엔드 스톨은 그렇지 않습니다.
마이크로벤치마크를 통해 살펴봤죠.이것이 바로 우리가 AWS에 집착하는 이유입니다.
실제 워크로드 성능에 대해프로세스를 설계할 때 우리는 이기기 위해 노력하지 않습니다.
벤치마킹 대회로, 우리는 운영 능력이 뛰어납니다.
실제 애플리케이션.그리고 이것들은 존재의 결과입니다.
실제 워크로드에 초점을 맞췄습니다.Graviton3의 기존 벤치마크를 활용하면
그래비톤2에 비해 30% 개선된 것으로 나타났습니다.나쁘지 않죠?하지만 잠시만요.NGINX를 테스트했을 때
놀라운 60% 의 성능 향상.왜요?우리가 크게 줄었기 때문이죠.
브랜치 오보, 그게 표준인 거죠.
벤치마크는 거의 신경 쓰지 않았죠.그리고 Graviton4를 통해 살펴본 적이 있습니다.
같은 패턴이 다시 재생됩니다.마이크로벤치마크에 따르면
25% 개선되었지만 실제 MySQL 워크로드는 잘 보이고 있습니다.
성능이 40% 향상되었습니다.그게 무슨 의미인지 생각해 보세요.
대규모 데이터베이스를 운영하는 고객.이것이 바로 고객들이 사랑하는 이유이기도 합니다.
그래비톤4.이건 그냥 슬라이드에 있는 숫자가 아니에요.실제 고객들이 보고 있는 모습입니다.
실질적인 개선은 계속되는 혜택으로 이어집니다.
그들의 고객들.이제 AWS에서는 그냥 이야기하는 것이 아닙니다.
그래비톤의 이점에 대해 말씀드리죠.우리는 그것을 직접 경험하고 있습니다.
서비스를 마이그레이션함으로써 놀라운 성과를 거두고 있습니다.
가격 대비 성능 개선.오로라 및 DynamoDB와 같은 서비스
Redshift를 비롯한 다양한 분야에서 그 중요성이 대두되고 있습니다.
그래비톤에서 실행함으로써 얻을 수 있는 혜택이 있죠.그리고 가장 큰 행사 중 하나인 아마존 프라임 데이에는
전 세계 쇼핑 이벤트에서는 25만 개 이상의 그래비톤이 판매되었습니다.
운영에 동력을 공급하는 CPU.그리고 최근에 우리는
중요한 이정표입니다.지난 2년 동안
전체 신규 CPU 용량의 50% 이상이 데이터 센터에 설치되었습니다.
AWS Graviton을 사용하고 있었습니다.생각해 보세요.다른 모든 프로세서보다 Graviton 프로세서가 더 많다는 뜻입니다.
유형을 모두 합쳤습니다.하지만 Graviton은 우리가 처음으로 혁신한 곳이 아니었습니다.
실리콘 수준에서요.일찍부터 우리는 만약 우리가 갈 거라는 걸 알았어요.
끊임없이 성장하는 기업을 위해 세계적 수준의 성능과 보안을 제공하기 위해서입니다.
혁신이 필요한 EC2 인스턴스의 수를 늘려야 할 것
전체 스택.그리고 그 이야기는
AWS 니트로 시스템.AWS 니트로 시스템은 완성품입니다.
서버 아키텍처의 재구상
근본적으로 변화하고 변화했습니다.
클라우드를 구축하고 보호하는 방법Nitro를 사용하여 제거했습니다.
다른 클라우드 제공업체들이 부담하던 기존의 가상화 관련 세금입니다.
오늘날에도 여전히 어려움을 겪고 있습니다.또한 우리가 얻는 민첩성도 있습니다.
가상으로 전환할 수 있게 해주는 Nitro의 아키텍처에서 비롯되었습니다.
모든 컴퓨터를 EC2 인스턴스로 만들 수 있습니다.애플 맥을 실행하고 싶으신가요?
클라우드에서?음, 니트로가 해냈어요.직접 접속이 필요해요
베어메탈 EC2 인스턴스의 기본 하드웨어에 액세스할 수 있습니다.Nitro도 이를 처리합니다.하지만 어디에 초점을 맞출지 살펴보죠.
이 여정은 시작됐습니다.보안.Nitro는 보안만 개선한 것이 아닙니다.이는 우리의 전체 접근 방식에 혁명을 일으켰습니다.
하드웨어 공급망 무결성에 대해이제 클라우드에서의 보안은
절대적인 확실성이 요구됩니다.AWS에서는 알아야 할 사항을 잘 알고 있습니다.
모든 하드웨어가 우리가 기대하는 소프트웨어를 실행하고 있다는 것
그리고 우리가 기대하는 방식도 마찬가지죠.이것은 단순한 수준을 넘어선 것입니다.
전체 플릿의 소프트웨어 및 펌웨어 업데이트.암호화 증명이 필요합니다.
무엇이 실행되고 있는지 알려주는 것을 증명이라고 합니다.
모든 단일 시스템에서 말이죠.그리고 우리의 규모도
그건 엄청난 도전이죠.생각해 보세요.우리는 청렴성을 증명하고 있습니다
글로벌 인프라 전반의 수백만 구성 요소
실시간으로 말이죠.프로세스에 대해 생각해 봅시다.
부팅 시퀀스를 신중하게 일련의 순서로
조율된 단계.모든 것은 읽기 전용으로 시작됩니다.
대부분의 기능을 활성화하는 메모리 또는 ROM
칩의 기본 부분.그리고 거기서부터 프로세서가
펌웨어의 다음 레이어를 로드한 다음 부트로더를 로드합니다.
운영 체제로 넘어가고 마지막으로 애플리케이션으로 넘어갑니다.하지만 중요한 인사이트는 다음과 같습니다.이러한 각 단계는 다음을 나타냅니다.
잠재적 약점, 승인되지 않은 코드가 있는 곳
잠재적으로 실행될 수 있습니다.그리고 훨씬 더 근본적으로
이 전체 체인은 신뢰의 근원에 달려 있습니다.그렇다면 진짜 질문은 이것입니다.
첫 번째 링크를 어떻게 검증할 수 있을까요?그러기 위해선 우리가 가야 할 일이 있어요.
처음부터 제조 현장으로 돌아가 봅시다.서버의 여정은 아직 갈 길이 멉니다.
초기 제조, 그 다음 조립
운송 경로를 거쳐 데이터 센터까지그리고 마지막으로 설치까지.매 단계마다 확신을 가져야 합니다.
타협된 것은 하나도 없습니다.이건 찾기에 관한 게 아니에요
취약점은 사실 이후입니다.끊어지지 않는 체인을 만드는 것이 관건입니다.
구성 요소가 만들어지는 순간부터 보관 및 검증을 거칩니다.
실제로 제조되기 전까지는 말이죠.
실제 고객 워크로드 실행이제 다음 중 하나의 부팅 프로세스를 자세히 살펴보겠습니다.
Graviton4 기반 워크로드.당사의 토대는
하드웨어 보안과 신뢰의 근본
Nitro 칩 자체에 있습니다.제조 과정 중
각 니트로 칩마다 고유한 비밀이 생성됩니다.
그리고 칩 안에 저장됩니다.다음과 같이 생각할 수 있습니다.
이 칩의 고유한 지문이지만 절대 볼 수 없는 지문입니다.
실리콘을 남깁니다.그리고 이 비밀이 기본이 됩니다.
퍼블릭 프라이빗 키 페어의 경우개인 키는 그대로 유지됩니다.
공개 키가 일부가 되는 동안에는 칩 내에 영구적으로 잠깁니다.
당사의 안전한 제조 기록에 관한 것입니다.그리고 여기가 저희 체인이 있는 곳입니다.
양육권이 시작됩니다.니트로 칩의 개인 키가 앵커가 됩니다.
측정된 부팅 프로세스용.부팅의 각 단계에서 다음을 생성합니다.
새 개인 키에 서명하여 이전 개인 키를 파괴합니다.이는 마치 안전한 배턴을 건네는 것과 같습니다.각 핸드오프는 완벽해야 합니다.
아니면 레이스가 멈춥니다.그리고 이 일련의 시그니처들은
칩 생산부터 모든 것을 검증해 보겠습니다.
품질부터 펌웨어 버전, 정체성까지.시스템 액세스가 제한되어 있습니다.
이를 통과할 때까지 나머지 AWS에
증명 프로세스를 완료하세요.그리고 모든 실패는 즉각적임을 의미합니다.
격리 및 조사.하지만 그래비톤 덕분에 우리는 한 걸음 더 나아갔습니다.
보안의 경계는 훨씬 더 넓어졌습니다.그래서 Nitro를 기반으로 건물을 짓는 거죠.
안전한 기반, 우리는 증명을 다음과 같이 확장했습니다.
그래비톤 4 프로세서 그 자체.그리고 이것이 실제로 만들어내는 결과입니다.
중요한 시스템 간의 서로 맞물리는 신뢰망
구성 요소.그래비톤4 프로세서가 두 개일 때
함께 작동해야 하는 경우, 먼저 암호화 방식으로 작동해야 합니다.
서로의 신원을 확인하고 확립하세요
암호화된 통신.같은 일이 일어납니다.
그래비톤4와 니트로 사이 (키 교환 포함)
호스트의 ID 및 해당 개인 키에 연결됩니다.이게 무슨 뜻인지 생각해 보세요.모든 중요한 연결
시스템에서 CPU에서 CPU로의 통신
PCIe로의 트래픽은 하드웨어 기반 보안으로 보호됩니다.
이는 제조에서 시작됩니다.니트로와 그래비톤4 사용
협업을 통해 우리는 연속적인 제품을 만들었습니다.
증명 시스템.이것은 단순한 증분이 아닙니다.
보안이 개선되었습니다.니트로의 조합은
하드웨어 기반 보안 및 Graviton4의 향상된 기능
지금까지 출시된 제품 중 가장 안전한 컴퓨팅 제품 중 하나를 만들어 냈습니다.여러분에게 이는 곧 워크로드를 의미합니다.
암호학적으로 검증된 하드웨어에서 실행
제조 단계부터
매 순간의 작업 내내보안은 불가능하기만 합니다.
기존 서버로는 달성 가능
그리고 데이터 센터.하지만 또 어떤 문제가 있을까요?
니트로로 해결할 수 있을까요?음, 그걸 이해하려면 다음이 필요하겠죠.
스토리지의 역학을 살펴보기 위해서요.하드 드라이브 용량의 진화
끊임없이 발전해 왔습니다.몇 년에 한 번씩 제조업체를 운영합니다.
플래터에 더 많은 데이터를 넣을 수 있는 새로운 방법을 찾았습니다.초창기를 돌이켜보면
2006년 즈음에 AWS를 사용할 때는 다음과 같은 드라이브를 사용하고 있었습니다.
수백 기가바이트 단위로 측정되었습니다.현재 우리는 드라이브를 배포하고 있습니다.
20테라바이트 이상입니다.자, 이와 동시에 비용도
테라바이트당 스토리지가 크게 떨어졌습니다.
지난 수십 년간 설계 및 제조 공정의 혁신으로 인해
그리고 재료.그래서 우리가 항상 그럴 수 있도록
스토리지 시스템을 최대한 효율적으로 운영하고
항상 준비가 되어 있는지 확인해야 합니다.
한 차원 높은 드라이브 크기와 차세대 스토리지 혁신을 실현하기 위해서죠.이제 더 잘 이해해 보겠습니다.
이로 인해 발생하는 복잡성, 이제 디자인을 좀 더 자세히 살펴보겠습니다.
일반적인 스토리지 시스템의 모습이죠.생각해 보면
S3 및 EBS와 같은 스토리지 서비스는 다음과 같이 구성됩니다.
세 가지 주요 구성 요소.먼저 프론트엔드 플릿이 있습니다.이러한 서버를 처리하는 웹 서버입니다.
API 트래픽, 인증 요청
고객 인터페이스를 관리할 수 있습니다.그 뒤에는 우리가 부르는 것이 있습니다.
인덱스 또는 매핑 서비스.다음과 같이 생각할 수 있습니다.
마치 수술의 두뇌처럼 말이죠.모든 데이터를 추적합니다.
그리고 데이터가 정확히 어디에 저장되어 있는지.고객이 책을 읽고 싶어할 때
이 서비스는 고객의 데이터를 알려줍니다.
정확히 어디로 가서 찾을 수 있을까요?그리고 마지막으로,
스토리지 미디어 레이어입니다.실제 데이터가 있는 곳입니다.자, 좀 더 자세히 살펴보죠.
스토리지 서버.일반적으로 당사의 스토리지는
서버는 우리가 부르는 것을 기반으로 구축되었습니다.
헤드 노드 아키텍처.헤드 노드 자체는 기본적으로
그냥 표준 컴퓨팅 서버일 뿐이죠.CPU, 메모리,
네트워킹 기능이 있고 모든 측면을 관리하는 특수 소프트웨어를 실행하고 있습니다.
중요 기능을 포함한 데이터 스토리지
데이터 내구성, 드라이브 상태 모니터링, 조정 등
모든 I/O 작업그리고 이 헤드 노드에 연결하면
우리는 그냥 서 있는 JBOD라는 애칭으로 불리는 것을 가지고 있습니다.
'그냥 디스크 한 무리'라는 뜻입니다.말 그대로 그게 전부입니다.하드 드라이브로 가득 찬 섀시
모두 SATA 및 PCIe 연결을 통해 헤드 노드에 직접 연결됩니다.하지만 여기서 중요한 것은 이것입니다.
설계, 컴퓨팅 간의 비율
스토리지는 설계 시 고정됩니다.일단 빌드하고 배포하면
이 서버들은 CPU, 메모리, 메모리 등의 특정 비율에 고정됩니다.
그리고 스토리지 용량.이제 드라이브 용량이 늘어나면서
지난 몇 년 동안 이 고정 비율은 점점 더 어려워지고 있습니다.
효과적으로 관리하기 위해서죠.따라서 최종 결과는
용량을 늘리는 여정 중에 있습니다.
드라이브 크기를 모두 늘려 스토리지 시스템의 성능을 높였습니다.
그리고 드라이브 수.그리고 저희는 비교적 비교적 먼저 시작했죠.
보통 수준의 구성으로 서버 한 대에 12개 또는 24개의 드라이브가 있을 수 있습니다.그리고 드라이브 기술이 발전하면서 관리 능력도 향상되었습니다.
더 큰 드라이브 풀.우리는 이 수치를 계속 올려왔고,
호스트당 드라이브 36개, 항상 72개 시도
집적도와 관리 용이성 사이의 최적의 지점을 찾는 것.그리고 Barge를 만들었습니다.바지선은 우리의 가장 야심찬 창고였습니다.
밀도 엔지니어링 프로젝트는 아직 없습니다.다음을 포함하는 대규모 스토리지 서버
단일 호스트에 288개의 하드 드라이브그 숫자를 생각해 보세요.
잠시만요. 288개의 드라이브오늘날의 20테라바이트 드라이브로는 거의 6페타바이트에 달합니다.
단일 서버의 원시 스토리지더 많은 스토리지가 필요하죠.
AWS 초창기 시절의 일부 데이터 센터보다 더 많죠.자, 이것이 우리가 실제로 시도한 것입니다.
가능했던 것의 한계를 뛰어넘으세요.
저장 밀도와 함께 말이죠.하지만 정말 인상적이었죠.
엔지니어링 성과는 우리에게 몇 가지 중요한 교훈을 주었습니다.
밀도의 한계에 대해서요.바지선이 우리에게 가르쳐준 첫 번째 교훈
신체적 제약에 관한 거였어요.그리고 이것들은 말 그대로
제약이 심하죠.각 바지선 랙의 무게는
믿을 수 없을 만큼 큰 4,500파운드였죠.2톤이 넘어요.이로 인해 몇 가지 현실적 어려움이 생겼습니다.
우리 데이터 센터에 있는 우리한테는 말이죠.바닥을 보강해야 했습니다.
배포 위치를 신중하게 계획하세요.
그리고 이런 것들을 옮길 때는 특수 장비를 사용하세요.이제 288개의 스피닝 드라이브를 포장하고 있습니다.
함께 사용하면 무게가 늘어날 뿐만 아니라 제가 좋아하는 제품도 만들 수 있습니다.
바이브레이션 오케스트라라고 부르기 위해서요.하우징은 함께 움직입니다
일반적으로 큰 문제는 아니지만, 288개가 있으면
7,200RPM으로 회전하면 진동에 영향을 미칩니다.
실제로 성능에 영향을 미칠 만큼 중요해질 수 있습니다.
그리고 드라이브의 안정성.그리고 다음이 있습니다.
소프트웨어 복잡성.에서 288개 드라이브 관리
단 한 명의 호스트가 우리 회사의 소프트웨어 시스템을 밀어붙였습니다.
한계에 다다랐죠.모든 것을 다르게 생각해 보세요.
처리해야 하는 장애 모드
데이터 배치 알고리즘의 복잡성과 유지 관리 문제
이러한 대형 드라이브 풀에서 일관된 성능.하지만 아마도 가장 중요한 것은
교훈은 폭발 반경에 관한 거였어요.바지선 서버와 서버가 고장났을 때
실패했지만 그 영향은 엄청났습니다.갑자기 이런 일을 하게 되셨군요
6페타바이트의 스토리지를 사용할 수 없게 될 수도 있습니다.그리고 중복성이 있더라도 복구 프로세스는
그 만큼의 데이터에는 상당한 양이 필요합니다.
시간 및 네트워크 대역폭.그래서 우리는 알고 있었죠.
바지한테 작별 인사하러 말이야[안개 뿔 소리] 그래서, 그 교훈을 바탕으로
우리는 한 걸음 물러서야 했어요.운영을 어떻게 줄일 수 있을까요?
민첩성을 높이는 동시에 복잡성도 높였습니다.
여전히 높은 성능을 제공하면서도 스토리지 인프라의
고객을 위한 성능?이를 위해 우리는 우리의 제품을 선택합니다.
통찰력을 위한 스토리지 서비스.따라서 S3 및 EBS와 같은 스토리지 서비스는
그리고 EFS는 모두 당사 표준을 기반으로 구축되었습니다.
스토리지 서버 아키텍처.하지만 일부는 있었습니다.
독특한 요구 사항.일부 서비스에는 더 많은 메모리가 필요했지만
일부 제품은 컴퓨팅이 덜 필요했습니다.하지만 스토리지 계층 자체 내에서는
기능은 동일했습니다.그럼, 이 둘의 긴밀한 결합이 있었을까요?
컴퓨팅과 스토리지가 우리를 제한하고 있었나요?디스애그리게이션의 개념,
컴퓨팅과 스토리지를 분리해서 찾기 시작했어요
정말, 정말 매력적이었어요.유지할 수 있는 방법을 찾을 수 있다면
다이렉트 액세스와 퍼포먼스
독립적인 확장을 허용하면서 서비스에 필요한 것
컴퓨팅과 스토리지를 통해 얻을 수 있는 것은
두 세계의 장점이죠.여기서 우리는 생각하기 시작했습니다.
이미 가지고 있던 것을 활용하는 것에 대해
저희 툴킷에는 Nitro가 있습니다.그래서, 연결하는 대신
헤드 노드로 연결되는 드라이브는 스토리지를 세분화하고 있습니다.
Nitro 카드를 해당 카드에 직접 내장함으로써
JBOD 인클로저.이 Nitro 카드를 선물용이라고 생각하시면 됩니다.
우리의 드라이브는 그 자체로 지능적입니다.
그리고 네트워크 연결성.각 드라이브는 안전하게 가상화되어 있습니다.
격리된 네트워크 엔드포인트.그리고 정말 강력한 것은
이 접근법은 직접성을 보존한다는 것입니다.
드라이브에 대한 낮은 수준의 액세스 권한과 필요한 스토리지 서비스
물리적인 제약에서 완전히 벗어나고 있으면서도
예전에도 그랬던 것이죠.그리고 Nitro는 이 모든 것을 처리합니다.
네트워킹 복잡성, 암호화 및 보안.Nitro는 다음과 같은 목적을 위해 설계되었기 때문입니다.
고성능과 짧은 지연 시간을 자랑하는 당사는 이 모든 것을 제공합니다.
드라이브에 액세스하더라도 드라이브의 기본 성능
네트워크를 통해이게 바로 실제 모습입니다.
우리 데이터 센터에서 본 모습이죠.언뜻 보면 이렇게 생각할 수도 있습니다.
표준 JBOD 섀시처럼 보이지만 몇 가지 중요한 차이점이 있습니다.앞서 말씀드린 Nitro 카드들
실제로 드라이브와 함께 여기에 내장되어 있습니다.그리고 이 디자인의 아름다움은
단순함입니다.랙 안을 들여다보면
이것들 중에서 다음과 같은 것이 보일 것입니다.
기존 스토리지 서버라기보다는 네트워크 스위치와 비슷합니다.그리고 이 또한
유지보수가 더 간단해졌습니다.우리의 세분화 덕분에
스토리지 아키텍처, 장애가 발생한 드라이브는 신속하게 처리할 수 있습니다.
서비스에서 제거되고 다른 정상 드라이브로 교체됨
몇 번의 API 호출만으로 가능합니다.그리고 핫스왑이 가능한 드라이브도
데이터 센터 기술자는 컨테이너를 사용하여 이러한 장치를 별도의 작업 없이 쉽게 수리할 수 있습니다.
서비스 가용성에 영향을 미칩니다.따라서 드라이브 고장은 더 이상 발생하지 않습니다.
걱정이 되는데요, 헤드 노드는 어떨까요?글쎄요, 여기가 일이 시작되는 지점입니다
정말, 정말 흥미로워요.전통적인 건축물에서는
헤드 노드 장애가 주요 사건이었습니다.수십 개 또는 수백 개에 대한 액세스 권한을 잃게 됩니다.
가서 수리할 수 있을 때까지는 드라이브가
저 서버, 서버 교체해Barge의 예를 기억하세요.
단일 서버 장애가 288개 드라이브에 영향을 미쳤습니다.스토리지가 분리된 경우 헤드 노드 장애가 발생합니다.
거의 사소해집니다.드라이브 주소가 지정되었으므로
네트워크상에서 독립적으로 간단하게 시작할 수 있습니다.
새 컴퓨팅 인스턴스를 만들고 모든 드라이브를 다시 연결합니다.그리고 동일한 프로세스입니다.
표준 복구에 사용합니다.
EC2 인스턴스의그리고 일반적으로 이런 일이 발생합니다.
몇 분 후에데이터 이동이 필요 없습니다.
복잡한 재구축 프로세스 없이 다시 연결하고 작업을 재개하기만 하면 됩니다.그리고 이러한 실패 시나리오도
중요한 것을 강조하세요.획기적으로 줄었습니다.
폭발 반경을 실제로 개선하면서
회복 속도.이건 시작에 불과합니다.
디커플링을 할 때 어떤 일이 가능한지에 대해
스토리지에서 컴퓨팅하세요.또 다른 강력한 이점
디스애그리게이티드 스토리지의 장점은 컴퓨팅을 확장할 수 있다는 것입니다.
그리고 스토리지를 독립적으로 사용할 수 있습니다.S3에 새로 상륙할 때
스토리지 용량에는 일반적으로 기간이 있습니다.
데이터를 하이드레이션하고 리밸런싱할 때 컴퓨팅 부하가 심함
새 드라이브 전반에 걸쳐 말이죠.이제 일시적으로 확장할 수 있습니다.
이 초기 기간 동안만 컴퓨팅 리소스를 확장 및 확장한 다음 다시 축소합니다.
정상 운영의 경우.그리고 이런 유연성,
이를 통해 운영 효율성을 높이고 궁극적으로 더 나은 가치를 제공할 수 있습니다.
고객을 위해.하지만 분리된 스토리지를 사용하면서 성공적으로 해체할 수 있었습니다.
스토리지를 제한했던 고정된 비율에서
오랜 세월 동안 건축을 해왔습니다.컴퓨팅과 스토리지를 분리하여 확장할 수 있습니다.
예상대로 고성능을 유지하면서 각 구성 요소를 독립적으로
클라우드 환경에서우리는 크게 줄었습니다.
폭발 반경.이제 실패를 제한할 수 있습니다.
복구 속도가 빨라지고 서비스가 더 많아집니다.
그 어느 때보다 탄력적입니다.그리고 실제로 운영되고 있는 모습도 보이고 있습니다.
민첩성 향상으로 이점을 얻을 수 있습니다.당사의 서비스는 적절한 규모로 운영될 수 있습니다.
실제 요구 사항을 기반으로 한 컴퓨팅 리소스,
하드웨어 제약이 아닙니다.유지보수도 더 간단하죠.
용량 계획이 더 유연해져서 더 빠르게 혁신할 수 있습니다.하지만 아마도 가장 중요한 것은 이 아키텍처가 우리를 뒷받침한다는 점일 것입니다.
미래를 위해서요.드라이브 용량이 계속 증가함에 따라 스토리지가 분리되었습니다.
적응할 수 있는 유연성을 제공합니다.
인프라를 발전시키세요.해결책으로 시작한 것은
스토리지 집적도 문제가 대두되고 있습니다.
훨씬 더 근본적인 것은 우리에게 도움이 되는 새로운 프리미티브입니다.
더 효율적이고 안정적인 스토리지 서비스를 구축하세요
고객인 여러분을 위해그리고 그걸로
다시 피터한테 넘겨줄게.[음악과 박수] 좋아요.정말 멋졌어요.데이브가 몇 가지 멋진 모습을 보여줬어요
AWS 컴퓨팅의 혁신.이제 몇 분만 시간을 할애하고 싶습니다.
완전히 다른 종류의 워크로드에 대해 말씀드리자면:
인공 지능.사실 두 가지 워크로드죠.AI 모델 트레이닝이 있습니다.
그리고 AI 추론.그리고 정말 멋진 것 중 하나는
AI 워크로드의 특징은 다음과 같습니다.
우리 팀이 발명할 수 있는 새로운 기회
완전히 다른 방식으로 말이죠.그 중 몇 가지를 살펴보도록 하겠습니다.
오늘 밤 이 자리에서 혁신은 우리 자신을 밀어붙여 건설에 나서는 것과 같습니다.
최고 성능의 칩을 연결하고 상호 연결합니다.
새로운 기술을 활용해서 말이죠.하지만 다음 사항도 살펴보도록 하겠습니다.
우리가 지금까지 해왔던 혁신을 어떻게 적용하고 있나요?
지난 10년 동안 이 새로운 영역을 개척해 왔고,
AWS의 성능, 안정성 및 저렴한 비용 제공
AI 워크로드에.그리고 스케일아웃에 대해 많이 이야기하죠.
웹 서비스, 빅 데이터 애플리케이션과 같은 워크로드
및 분산 시스템.스케일아웃 워크로드
추가하면 매우 효율적으로 실행됩니다.
시스템에 추가 리소스.그리고 우리는 많은 투자를 했습니다.
최적화된 인프라를 만들기 위해
이러한 워크로드에 적합합니다.사실, Dave가 방금 말씀드렸듯이
이러한 혁신들 중 일부는 앞서 말씀드렸죠.하지만 AI 워크로드는 확장되지 않습니다.
워크로드는 스케일업 워크로드입니다.그 이유를 보여드릴게요.운전을 하는 이유 중 하나는
AI 기능의 출현은 모델이 점점 더 커지고 있다는 것입니다.
훨씬 더 커졌죠.지난번에 이 얘기를 했을 때
2022년에는 모델에 대한 기대가 컸습니다.
수십억 개의 파라미터가 있습니다.작년에는 정말 기뻤습니다.
약 수천억 달러였죠.그리고 머지않아 프론티어 모델이 등장할 가능성이 높습니다.
수조 개의 파라미터가 있을 겁니다.왜 이런 성장이 나타나는 걸까요?글쎄요, 2020년에 연구자들이 발표한 바에 따르면
스케일링 법칙 (Scaling Laws) 이라고 불리는 획기적인 논문이 하나 있습니다.그리고 다음과 같은 가설을 세웠습니다.
특정 항목을 확장하면 모델 기능이 향상되고
즉, 파라미터의 개수, 데이터셋 크기
그리고 컴퓨팅의 양.그 이후로도 많은 관심을 받고 있습니다.
더 크고 컴퓨팅 집약적인 모델을 만들기 위해서죠.그리고 이 모델들은 실제로
더 유능해졌어요.여러분도 이런 경험을 하셨을 겁니다.
일상 생활에서 말이죠.자, 자세히 들여다보면
이 그래프를 보시면 뭔가 보이실 겁니다.
꽤 흥미로워요.이 그래프는 로그-로그 그래프인데, 그래프는
X축과 Y축이 대수입니다.그리고 로그-로그 그래프의 직선
오해의 소지가 있을 수 있습니다.좀 더 자세히 살펴보겠습니다.
컴퓨팅 그래프를 보세요.이제 우리는 익숙해졌습니다.
선형 그래프에 X를 추가할 때마다
Y가 나오는데, 이는 선형 관계입니다.하지만 로그-로그 그래프에서는 직선이 다음을 나타냅니다.
곱셈 관계, 예를 들어 X를 네 배로 늘리면
Y를 두 배로 늘릴 수 있습니다. 그리고 이것에서 볼 수 있는 것은
그래프를 스케일링하는 것은 정말 놀랍습니다.손실을 절반으로 줄이려면
Y축의 측정값은 백만 번 사용해야 합니다.
더 많은 컴퓨팅.백만 번 말이죠.자, 이제 50% 더 좋아진 모델이죠.
이 Y축에서는 실제로 측정이 훨씬 더 스마트해질 것입니다.
다른 여러 벤치마크에서도 마찬가지였죠.하지만 이 관계는
컴퓨팅과 모델 손실은 업계가 왜 이렇게 변하는지 설명해 줍니다.
더 나은 AI 인프라 구축에 수백억 달러를 투자하고 있습니다.하지만 뭐가 더 좋을까요?
AI 인프라란 무엇일까요?이해를 돕기 위해 살펴보죠.
대규모 AI 모델이 어떻게 학습되는지 살펴보세요.핵심은 현대식 제너레이티브 AI입니다.
애플리케이션은 예측 엔진입니다.토큰 세트를 입력해 프롬프트를 생성하면
이는 기본적으로 단어의 일부이며 다음 토큰을 예측합니다.
순차적으로 한 번에 하나씩요.그리고 이 아주 기본적인 기술부터
다음 토큰을 예측해보면 꽤 놀라운 자산이 몇 개 나옵니다.
추론이나 문제 해결 같은 것처럼요.이러한 예측 모델을 구축하려면 모델을 훈련해야 합니다.
찾을 때까지 수조 개에 달하는 데이터 토큰에 대해
예측 오차를 최소화하는 모델 가중치 세트
교육 데이터 전반에 걸쳐그리고 이 훈련 과정은
이 모든 토큰에는 엄청난 양의 컴퓨팅이 필요합니다.가장 큰 모델을 학습시키려면
단일 서버에서는 가장 큰 단일 서버라도
몇 세기 또는 수천 년이 걸릴 수도 있습니다.물론,
우리는 마비시킬 필요가 있어요.시작하기에 가장 좋은 곳입니다.
훈련 데이터를 분할하는 거죠.그리고 이런 것 같습니다.
충분히 간단하죠.시간이 걸리는 걸 복용하면
한 대의 서버에서 천 년을 보내고 천 대의 서버에서 운영되는 셈이죠.
서버, 1년이 걸릴 거예요.다음과 같은 경우에도 마찬가지일 것입니다.
워크로드는 스케일 아웃 워크로드였지만 아쉽게도 그렇게 간단하지는 않습니다.방금 설명드린 데이터 분할 프로세스는
이를 데이터 병렬화라고 합니다.인생의 많은 좋은 일들과 마찬가지로 데이터 병렬 처리도 뒤따릅니다.
몇 가지 세밀한 글씨도 있고요.이렇게 간단하게 나누면
제가 설명드린 정복 접근법을 생각해보면 여러분은 정말로 구축을 해나갈 수 있을 것입니다.
독립된 모델들을 잔뜩 모으고 그 둘을 합치려 하는 거죠.
마지막에 말이에요.그리고 그건 그냥 효과가 없어요.대신 데이터를 활용할 때는
병렬 처리를 위해서는 모든 서버를 공유하고 결합해야 합니다.
모델의 가중치가 지속적으로 증가하기 때문에 기본적으로
하나의 공유 버전을 구축할 수 있는 대규모 서버 클러스터
모델의그리고 여기가 뭐라 불리는건지
전체 배치 크기가 실제로 작용합니다.글로벌 배치 크기가 가장 큰 집합입니다.
결합하기 전에 처리할 수 있는 데이터의 양
모든 서버의 결과.그리고 이 글로벌 배치 크기는
아주 작은 분수입니다.
전체 훈련 데이터의 비중이죠.데이터 병렬 처리 방법은 다음과 같습니다.
정말 효과가 있어요.많은 양의 데이터를 가져오는 것이지 더 큰 데이터는 아닙니다.
전 세계 배치 크기보다.다음으로 할 일은 청크를 나누는 것입니다.
여러 개의 동일한 부분으로 나누어 모든 서버에 적용하세요.그러면 각 서버가 학습합니다.
할당된 데이터 비트를 기반으로, 그리고 데이터가 완료되면
결과를 클러스터의 다른 모든 사람과 결합합니다.그리고 모두가 합쳐지면
결과가 나오면 모두가 다음 단계로 넘어갈 수 있습니다.
다음 데이터 배치로 넘어가죠.따라서 실제로 이 한계는
이러한 글로벌 배치 크기 제한은 실제로 확장만 가능하다는 것을 의미합니다.
훈련 클러스터를 기껏해야 수천 대의 서버로 확장할 수 있습니다.이보다 훨씬 더 나아가면 각 서버는 실제로 다음과 같은 결과를 얻게 됩니다.
더 많은 시간을 소비하는 소량의 데이터
예전보다 결과를 조율하는 것
실제로 데이터를 처리할 때 말이죠.따라서 서버를 계속 추가하면
속도가 빨라지는 게 아니라 비용만 늘어나는 거죠.자, 이 점에 대해 이해해 보자면
데이터 병렬 처리와 이것의 한계는 두 가지 기본 기둥을 강조합니다.
AI 인프라의첫째로, 왜냐하면 우리는
글로벌 배치 크기로 인한 확장의 한계는 더 큰 모델을 만드는 길입니다.
더 강력한 서버를 구축하고 있습니다.이것이 스케일업 부분입니다.
인프라 과제에 대해서요.둘째, 한계에도 불구하고
AI 모델 구축의 규모 확대를 통해 우리는 여전히 많은 가치를 얻고 있습니다.
이러한 초대형 클러스터를 구축합니다.그리고 이를 잘 하기 위해서는
우리가 구축해 온 스케일아웃 도구를 활용하세요
오랜 세월 동안 말이죠.효율적인 데이터 센터 같은 것들은요.
빠른 확장과 훌륭한 네트워킹.먼저 살펴보도록 하겠습니다.
첫 번째 부분부터 살펴보죠. 바로 스케일업 과제입니다.구축한다는 것은 무엇을 의미할까요?
가장 강력한 서버?즉, 일관성 있는 서버를 원한다는 뜻이죠.
많은 양의 컴퓨팅과 고속 메모리가 포함된 컴퓨팅 시스템
가능한 가장 작은 공간에.자, 안에 있는지가 왜 중요할까요?
가능한 가장 작은 공간인가요?이 모든 컴퓨팅이 필요하거든요
메모리가 서로 가까우면 배선이 가능하다는 뜻이죠.
모든 것을 한데 모아 엄청난 양의 고가를 사용하죠.
대역폭, 지연 시간이 짧은 연결.자, 레이턴시 부분은 아마도
꽤 직관적이긴 하지만, 서로 가까울수록
처리량도 더 많이 얻을 수 있습니다.그 이유는 다음과 같은 경우
물건을 더 가까이 두면 더 짧은 와이어를 사용할 수 있습니다.
서로간에 데이터를 전송하려면 더 많은 와이어를 패킹할 수 있습니다.또한 지연 시간이 짧아지고 더 효율적으로 사용할 수 있다는 의미이기도 합니다.
데이터 교환을 위한 프로토콜.아주 간단해 보이지만 아주 간단합니다.
흥미로운 도전이죠.작년에 저희는 트레이니엄 2를 발표했는데요,
차세대 트레이니엄 칩.그리고 오늘 밤은 제가 안내해 드릴게요
Trainium2를 사용하여 가장 강력한 제품을 만드는 방법을 살펴보세요
역대 AI 서버.이제 가장 작은 것부터 시작해 보겠습니다.
시스템의 일부인 Trainium2 칩입니다.몇 가지 지적해 드릴게요.
이 칩을 사용하려고 할 때 우리가 맞닥뜨리게 될 엔지니어링 한계는
그리고 가장 큰 AI 서버를 만드세요.이제 칩이 제조되고 있습니다.
매우 인상적인 실리콘 웨이퍼에
제조 기술 및 이러한 프로세스
항상 개선되고 있습니다.따라서, 최대한의 성과를 내고 싶으시다면
시스템의 컴퓨팅과 메모리는 시작하기에 좋은 곳입니다.
첨단 칩 중 가장 진보한 패키징으로 최대 규모의 칩을 만들고 있습니다.
제조 기술.그게 바로 우리가 한 일입니다.
트레이니엄 2를 사용했어요.하지만 여기서 실제로 마주치게 되는 부분이 있습니다.
첫 번째 엔지니어링 한계죠.칩 제조 공정
사실 칩을 생산할 수 있는 최대 크기입니다.
에칭할 때 사용하는 렌즈에서 나온 거예요.
실리콘 웨이퍼는 레티클이라고 불립니다.
최대 칩 크기를 약 800제곱밀리미터로 제한합니다.
또는 1.25제곱인치.자, 아마 이렇게 생각하실 겁니다.
제 손에 있는 게 훨씬 커 보여요
1.25제곱인치보다, 그 이유는
제가 들고 있는 건 칩이 아니라 패키지입니다.우리 대부분이 생각할 때
컴퓨터 칩에 대해 말하자면, 우리는 그 안에 있는 것을 떠올립니다.
마더보드 한가운데 방열판 아래에 있어요. 하지만 사실 저건 패키지입니다.
칩은 패키지 안에 들어 있어요.그리고 몇 년 전, 패키지는
아주 간단한 일이었어요.기본적으로 둘러싸는 방식이었죠.
칩 한 개를 마더보드에 장착하는 거죠.패키지를 통해 이동할 수 있었습니다.
실리콘 칩이라는 아주 작은 세상에서
모든 것을 하나로 연결하는 더 큰 와이어 트레이스까지
마더보드에.하지만 오늘 패키지는
훨씬 더 발전했습니다.고급 패키징을 생각할 수 있습니다.
하나의 패키지 안에 여러 개의 칩을 연결하여 하나의 패키지를 사용하는 것과 같습니다.
인터포저 (interposer) 라고 불리는 특수 장치.인터포저는 사실
그 자체로 작은 칩이지만 작은 마더보드의 역할을 하며 이러한 기능을 제공합니다.
칩을 약 10회 상호 연결할 수 있습니다.
얻을 수 있는 대역폭의 양
일반 PCB 기반 마더보드에서지금은 고급형을 사용하고 있습니다.
지난 몇 세대 동안의 패키징 기법
당사의 그래비톤 프로세서.여기 그래비톤3과 그래비톤4가 보이는데요, 두 칩을 모두 볼 수 있습니다.
또는 두 패키지 모두에 칩이 여러 개 있을 수도 있습니다.
또는 패키지 안에 칩렛이 들어 있습니다.그래비톤4 패키지
실제로 칩렛이 일곱 개 있습니다.가운데에 있는 커다란 칩이
컴퓨팅 코어와 그 작은 칩은
주변기기에서는 칩이 메모리에 액세스할 수 있도록 허용하는 등의 작업을 수행합니다.
그리고 시스템 버스의 다른 부분들.이제 컴퓨팅을 분리해서
코어를 사용하여 비용 효율적으로 작업을 수행할 수 있었습니다.
Graviton4 프로세서의 코어 수를 50% 늘리세요.자, 이 접근법은 정말 대단했습니다.
Graviton에 도움이 되긴 하지만, 이건 테이블 말고도 할 수 있습니다.
훌륭한 AI 서버를 구축할 때 말이죠.다음은 제가 들고 있던 Trainium2 패키지입니다.
제 손에는.보시다시피 두 개가 있습니다.
패키지 한가운데에 트라이늄 칩이 나란히 놓여 있습니다.각 트레이니엄2 칩이 놓여 있습니다.
다른 칩 두 개 옆에이 칩은 HBM 또는
고대역폭 메모리 모듈.HBM은 특수 모듈입니다.
메모리 칩 스택이 들어 있습니다.칩을 쌓아 올리면
같은 공간에 더 많은 메모리를 담으세요.이것이 가능한 이유는
메모리 칩은 실제로 더 적은 전력을 사용합니다.
열을 덜 내뿜을 수 있죠.좋아요, 그러니까 이 패키지를 보시면
컴퓨팅 메모리가 많이 필요한데 왜 안 되는지 궁금하실 수도 있습니다.
패키지를 더 크게 만든다고요?그냥 계속하세요.그리고 여기가 우리가 달려가는 곳입니다.
두 번째 제약에 부딪혔습니다.그걸 이해하려면
좀 더 자세히 살펴보죠.오늘날 패키지는 실제로 제한되어 있습니다.
최대 칩 크기보다 약 3배 더 크면
고려해보면 여기 보이는 것과 거의 같습니다.
이 두 칩과 HBM이죠.이제 이 그림에서는
아래쪽에 있는 인터포저를 잘 보여드리기 위해 HBM을 몇 개 떼어냈습니다.
연결에 사용되는 모든 작은 돌출부들은
칩을 인터포저에 연결하죠.하지만 더 좋은 각도가 있네요
이걸 보기 위해서요.이건 정말 멋진 사진이에요.
안나푸르나 팀이 저를 위해 만들어줬어요.그들은 조심스럽게 칩의 단면을 잘라냈습니다.
보라색 선을 따라가다가 현미경을 사용했죠.
옆에서 본 이미지를 날려버리기 위해서죠.몇 개 보이시죠?
정말 흥미로운 것들이죠.왼쪽 상단에 보이시죠?
트레이니엄2 컴퓨팅 칩.그 옆에는 HBM 모듈이 보입니다.한 가지 정말 멋진 점은 할 수 있다는 것입니다.
HBM 모듈의 레이어를 실제로 볼 수 있습니다.그리고 둘 다 위에 앉아 있습니다.
얇은 연속 웨이퍼, 이것이 인터포저입니다.
칩을 서로 연결하는 거죠.여기서 볼 수 있는 또 다른 것은
칩을 연결하는 조그마한 연결부들인가요?
인터커넥터에.그리고 이것들을 보실 수 있습니다.
정말 작고 작은 점들이에요.그 전기 연결부들
칩과 인터포저 상단 사이
엄청 작아요.각각의 크기는 약 100미크론입니다.이는 가장 미세한 입자보다 작습니다.
지금까지 본 적 없는 소금이죠.그리고 이 모든 인맥들
그 칩을 사용하려면 제자리에 있어야 합니다.
연결 상태를 유지하기 위해서죠.그래서 한계가 있는 거죠.
패키지의 크기가 제한되는 이유는 패키지가 그대로 있어야 하기 때문입니다.
이 모든 것을 보관할 수 있을 만큼 안정적입니다.
연결부가 연결되어 있습니다.그리고 이것들이 너무 작게 놔두지 마세요
치수가 오해를 불러올 수 있는 이유는 이 칩에는
엄청난 양의 힘과 열이 이리저리 움직입니다.그 트레이니엄2 칩 중 하나
사람이 수백만 명이 할 수 있는 충분한 계산을 할 수 있습니다.
단 1초만에 몇 년이요.이 작업을 수행하려면 이러한 칩이 필요합니다.
엄청난 전력이 공급되죠.이제 그 모든 힘을 약하게 움직여서
전압은 큰 전선을 사용해야 합니다.물론 크다는 것은 상대적인 용어입니다. 하지만 여기서 와이어를 볼 수 있습니다.
패키지 맨 아래에는 칩이 있습니다.
이걸 파워 VIA라고 부르죠.그리고 우리가 사용해야 하는 이유는
큰 와이어는 무언가를 피하기 위한 것입니다.
전압 강하라고 하죠.반도체는 존재를 이용합니다.
정보를 저장하고 처리하기 위한 작은 전하가 없을 수도 있습니다.따라서 칩에 전압이 가해지면
떨어지거나 늘어지는 현상이 발생할 경우 일반적으로 다음과 같이 기다려야 합니다.
전력 공급 시스템이 조정됩니다.그리고 기다린다는 건 아무것도 아니에요
칩으로 하고 싶은데요.칩에는 저전압 전력이 필요하지만 전력을 공급하는 것이 더 효율적입니다.
더 높은 전압에서.따라서 데이터 센터는 실제로 다음을 제공합니다.
여러 전압에서 전력을 공급합니다.그 결과 점진적으로 낮아지고 있습니다.
칩에 점점 더 가까워지죠.이제 마지막 단계가 시작됩니다.
전원이 패키지에 들어가기 전에어떻게 되는지 보실 수 있을 겁니다.
보통은 다음과 같이 하면 됩니다.
당사의 트레이니엄1 마더보드.최종 전압 스텝 다운은
가까운 위치에 있는 전압 조정기를 통해 이루어집니다.
가능한 한 패키지에 연결하십시오.여기서는 그것들을 강조하고 있습니다.
칠판에.이제 전압 강하를 줄이려면
저희 Trainium2 팀은 Trainium2를 최적화하기 위해 노력했습니다.
이 전압 조정기는 칩에 훨씬 더 가깝습니다.여기 Trainium2 보드가 보이는데
보드 상단에는 전압 조정기의 흔적이 보이지 않습니다.대신, 전압 조정기는
실제로는 패키지 주변에 있습니다.이 작업은 상당히 어렵습니다. 왜냐하면 전압 발생기가 있기 때문이죠.
열을 발생시키세요. 그래서 해야 할 일이 있죠.
몇 가지 새로운 엔지니어링.하지만 그 전압을 움직여서
레귤레이터가 칩에 가까워지면 실제로는 더 짧은 와이어와 더 짧은 와이어를 사용할 수 있습니다.
전압 강하가 적다는 뜻이죠.다음은 Trainium1이 어떻게 반응하는지 볼 수 있는 사진입니다.
부하가 증가할 때시작하면 이런 일이 일어납니다.
많은 양의 컴퓨팅을 수행하면 언제 부하가 걸리는지 알 수 있습니다.
스파이크 전압이 크게 떨어집니다.짧지만,
그 전압 저하는 칩을 의미하죠.
최적의 컴퓨팅이 아닙니다.그리고 이런 극단적인 변동성
실제로 칩에 무리가 가서 잠재적으로 사용 수명을 단축시킬 수 있습니다.이제 동일한 부하를 살펴보겠습니다.
트레이니엄 2에 적용되고 있습니다.발음이 없다는 걸 알아두세요.
전압 강하, 그 이유는
전선이 짧아서 그런지
칩의 스로틀링 현상이 없으므로 성능이 더 좋아집니다.좋아요, 칩에 대한 얘기는 그만두세요.서버를 살펴보죠.이것은 두 대의 Trainium2 서버가 있는 랙입니다.
하나는 상단에, 다른 하나는 하단에 있습니다.대형 서버죠.각 Trainium2 서버는 서로 구성되어 있습니다.
8개의 액셀러레이터 트레이로 구성되어 있습니다.그리고 각 트레이에는 두 개가 들어 있습니다.
Trainium2 액셀러레이터 보드 (각 보드에는 전용 보드가 있습니다)
니트로 카드.GPU가 켜져 있는 것처럼 말이죠.
엔비디아 기반 시스템인 Trainium 서버는 액셀러레이터입니다.이들은 계산을 수행하도록 설계되었으며
AI 모델을 구축하는 데 필요한 연산.하지만 지원하지 않습니다.
실행해야 하는 일반 지침
운영 체제 또는 프로그램
이를 위해서는 헤드 노드가 필요합니다.이것이 사실 엔지니어링입니다.
저희 서버에만 한정하세요.트레이닝 액셀러레이터의 수
우리가 설치할 수 있는 서버는 사실 제한되어 있습니다.
헤드 노드의 효율적인 관리 능력 덕분입니다.
그리고 해당 노드에 피드를 주죠.그래서 액셀러레이터를 더 추가하죠.
지금까지 해왔던 것 외에도 실제로 비용이 추가될 수 밖에 없습니다.
성능을 더 추가하는 것이지 우리가 원하는 것은 아닙니다.마지막으로 연결하려면 스위치가 필요합니다.
네트워크에 연결된 모든 액셀러레이터와 헤드 노드그렇다면 Trainium2는 얼마나 강력할까요?
서버?Trainium2 서버는 20페타플롭스를 제공하는 가장 강력한 AWS AI 서버입니다.
뛰어난 컴퓨팅 용량.이는 트레이니엄1보다 7배 더 많고 25% 더 많은 수치입니다.
현재 가장 큰 AI 서버입니다.트레이니엄2 서버에도 1.5가 있습니다.
테라바이트의 고속 HBM 메모리.이는 2.5배 더 많은 양입니다.
현재 가장 큰 AI 서버보다 말이죠.이것이 바로 스케일업 서버입니다.하지만 가장 강력한 AI를 가지고 있다는 건
서버는 구할 수 있는 경우에만 중요합니다.
고객의 손에 빠르게 도달할 수 있습니다.몇 년 전, 새 칩이 나왔을 때
서버가 등장하면 채택 곡선이 보일 것입니다.
초기 몇 달 동안은 이렇게 보입니다.
일부 얼리 어답터는 새 서버의 수명이 다할 때 이를 채택하기도 합니다. 보통 규모가 가장 큰 데이터베이스죠.
그리고 가장 까다로운 워크로드도 마찬가지죠.그리고 그 얼리 어답터들은
초기 제조 과정에서 많은 부분이 새로운 워크로드를 하드웨어로 옮기고 있었습니다.
당면 과제를 해결할 수 있을 것입니다.하지만 상황은 그렇지 않습니다.
AI로 작업하세요.더 강력하다는 가치 때문이죠.
더 나은 모델을 구축하기 위한 서버, 고객은 액세스를 원합니다
고객은 첫 날부터 최고의 AI 인프라를 원하고 있습니다.전례 없는 도약을 예상하면서
여기서도 혁신을 이루었습니다.다시 한 번 살펴보죠.
조금 전에 살펴본 Trainium2 트레이.자, 여기서 흥미로운 것은
보이지 않는데 케이블이 엄청 많아요.그 이유는 팀 때문이죠.
케이블 수를 줄이기 위해 많은 노력을 기울였죠.케이블 대신 이 모든 것들이
구성품은 와이어 트레이스를 통해 상호 연결됩니다.
아래 마더보드에 있습니다.왜 그랬을까요?왜냐하면 모든 케이블이 연결되기 때문이죠.
제조상의 결함 및 제조가 발생할 가능성이 있습니다.
결함이 있으면 속도가 느려집니다.사실, 가장 멋진 것 중 하나는
Trainium2 서버의 특징은 특별히 설계되었다는 것입니다.
자동화된 제조 및 조립을 가능하게 하기 위해서죠.이러한 높은 수준의 자동화는
첫날부터 빠르게 확장할 수 있습니다.따라서 Trainium2는 우리의 가장 큰 기능일 뿐만 아니라
강력한 AI 서버이기도 하고 특별히 설계되었습니다.
다른 AI 서버보다 빠르게 확장할 수 있습니다.
지금껏 해본 적 있는 일이죠.하지만 그게 전부는 아니에요.강력한 AI 서버는 그 이상입니다.
작은 공간에 원시 컴퓨팅과 메모리가 담겨 있을 뿐입니다.전문 도구입니다.
AI 워크로드를 최적화하는 데 사용됩니다.이것이 바로 아키텍처입니다.
트레이니엄 2가 그 역할을 톡톡히 해냅니다.가장 먼저 이해해야 할 것은
Trainium2에 대해서는 완전히 다음을 사용한다는 것입니다.
기존의 CPU나 GPU와는 다른 아키텍처죠.
시스톨릭 어레이라고 하는 것이죠.그럼 간단하게 보여드릴게요.
어떻게 다른지.다음은 몇 가지 표준을 설명해 드렸습니다.
명령을 실행하는 CPU 코어.종류도 다양하지만
CPU는 모두 몇 가지 공통점을 가지고 있습니다.
특징.먼저, 각 CPU 코어는 완전합니다.
독립 프로세서.이것이 바로 실행할 수 있는 이유입니다.
최신 CPU에서 여러 프로세스를 동시에 실행할 수 있습니다.여기서 주목해야 할 또 다른 사항은
모든 CPU 코어는 메모리로 돌아가기 전에 소량의 작업을 수행한다는 것입니다.
데이터를 읽거나 쓰기 위해서죠.따라서 CPU의 용도가 매우 다양하지만 성능이 뛰어나다는 의미이기도 합니다.
궁극적으로 메모리 대역폭에 의해 제어됩니다.마지막으로 CPU의 코어 수는
최근 몇 년 동안 크게 증가했는데, 이는 오늘날 가장 큰 CPU입니다.
기껏해야 코어가 몇 백 개일 수도 있지만 GPU는 완전히
다른 동물이죠.최신 GPU에는 수백 개 이상의 GPU가 있습니다.
수천 개의 컴퓨팅 코어가 체계화되어 있습니다.
병렬 처리 장치로 말이죠.그리고 GPU는 더 많은 코어를 담을 수 있습니다.
여러 코어가 정확히 동일하게 실행되므로 동일한 공간에서 사용할 수 있습니다.
서로 다른 데이터에 대한 작업즉, 각 GPU 코어를 의미합니다.
완전히 독립적이지는 않습니다. 사실 다른 코어와 연결되어 있습니다. 하지만 이는 각 GPU 코어가
전체 트랜지스터보다 적은 수의 트랜지스터로 제작할 수 있습니다.
CPU의 독립 코어GPU 아키텍처는 방대합니다.
그래픽을 시작으로 수많은 워크로드를 가속화했습니다.
하지만 가장 눈에 띄는 것은 AI입니다.GPU는 의심할 여지 없이
혁신적인 하드웨어 아키텍처지만 저희는 다른 접근 방식을 선택했습니다.시스톨릭 어레이 아키텍처는
오랜 시간 동안 만들 수 있는 고유한 하드웨어 아키텍처입니다.
상호 연결된 컴퓨팅 파이프라인.CPU 또는 GPU를 사용하여 각 컴퓨팅을 수행합니다.
명령어는 메모리를 읽고, 작업을 수행해야 하며,
그런 다음 메모리를 다시 씁니다.수축기 배열을 사용하면
계산 단계 간에 메모리 접근을 피할 수 있습니다.
한 처리 장치의 결과를 직접 전달함으로써
다음 처리 장치로이렇게 하면 메모리 대역폭이 줄어듭니다.
압력이 가해지면 최적화가 가능합니다.
우리의 컴퓨팅 리소스.그리고 Trainium을 사용해서 실제로 설계를 합니다.
AI 워크로드를 위한 시스톨릭 어레이입니다.따라서 우리는 선형 체인을 가지고 있지 않습니다.
앞서 설명한 것과 같은 처리 단위로 이루어져 있지만, 한 가지가 있습니다.
좀 더 비슷해 보이네요.저희 레이아웃은 특별히 디자인되었습니다
일반적인 행렬 또는 텐서 연산을 수용하기 위해
이는 AI 코드의 기초가 됩니다.그리고 이 아키텍처는
Trainium은 기존 하드웨어에 비해 이점을 제공합니다.
메모리와 대역폭을 최적으로 사용하는 아키텍처
AI 서버에서 사용 가능하므로 최대한 활용할 수 있습니다.
저희가 열심히 작업한 컴퓨팅과 메모리
그 Trainium2 서버에 집어넣는 거였죠.저희가 내린 또 다른 결정
트레이니엄은 여러분께 드리는 것입니다.
하드웨어에 직접 액세스하여 최적화 가능
애플리케이션 성능.뉴런 커널 인터페이스 또는 NKI
여러분을 가능하게 하는 새로운 언어입니다.
최대한 활용하는 코드 개발 및 배포
기본 Trainium 하드웨어를 활용하여 실험할 수 있습니다.
보다 비용 효율적으로 구축할 수 있는 새로운 방법을 소개합니다.
AI 애플리케이션.그리고 많은 것을 허락하게 되어 정말 기쁩니다.
더 많은 사람들이 Trainium을 실험하고 있습니다.그래서 지난 달에 저희가 발표했는데요.
Build on Trainium 프로그램은 연구자들에게 Trainium 하드웨어에 대한 액세스를 제공합니다.
새로운 기술을 개발하기 위해서죠.대학 출신 연구자
UC 버클리, 카네기 멜론, UT 오스틴, 옥스퍼드 같은
Trainium과 새로운 하드웨어 기능을 사용하게 되어 기쁩니다.
AI에 대한 새로운 연구를 수행하기 위해서죠.함께 협력하게 되어 매우 기쁩니다.
하드웨어 혁신을 꾀하는 연구 기관들
이는 미래의 가장 까다로운 AI 워크로드를 지원할 것입니다.좋아요, 그래서 저희가 가장 많이 만들었죠
새로운 하드웨어 아키텍처를 갖춘 강력한 AI 서버
이는 AI 워크로드에 최적화되어 있으며, 이제 더 빠르게 확장할 준비가 되었습니다.
그 어느 때보다 말이죠.하지만 가장 중요한 건 어때요?
최신 프론티어 모델을 구동하는 까다로운 AI 워크로드가 필요하신가요?그들에게는 아무리 강력해도 절대 강력하지 않습니다.
이젠 그만, 그게 바로 NeuronLink입니다
이 이야기에 들어오죠.뉴런링크는 당사의 독점 기업입니다.
트레이니엄 인터커넥트 기술.NeuronLink를 사용하면 기술을 결합할 수 있습니다.
여러 Trainium2 서버를 두 대가 있는 하나의 논리적 서버로
이들 서버를 연결하는 초당 테라바이트의 대역폭, 그리고
지연 시간이 1마이크로초여야 합니다.기존 방식과는 다르게
NeuronLink 서버는 고속 네트워킹 프로토콜을 사용할 수 있습니다.
서로의 메모리에 직접 액세스하여 다음을 수행할 수 있습니다.
특별한 것, 우리가 울트라 서버라고 부르는 것 말이에요.자, 항상 가져오고 싶었어요.
하드웨어를 무대에 올리고 매년
그걸로 화제를 모았어요.화면을 차단할 거예요.그건 그렇고, 미안해요.
화면을 차단합니다.하지만 올해는 여러분께 보여드리려고 합니다.
울트라서버란 무엇일까요? 저희가 출시한 것은 울트라서버입니다.
무대에 올랐습니다.[응원] 이것은 하나의 울트라서버입니다.
64개의 트레이니엄2 칩이 함께 작동하여 다음을 제공합니다.
현재 EC2 AI 서버보다 5배 더 많은 컴퓨팅 파워
그리고 10배 더 많은 메모리.자, 이것이 바로 서버 유형입니다.
빌드할 때 필요한 것들이죠.
1조 파라미터 AI 모델.정말 멋지네요.제 생각엔 적어도 그럴 것 같아요.
이 청중 중에 건물을 짓는 것에 대해 생각하고 있는 사람이 한 명 있습니다.
1조 파라미터의 AI 모델이지만 나머지 분들을 위해 말씀드리자면
뭔가도 있을 거예요.한 가지 살펴보죠.
모두가 많이 하고 있는 일이죠. 그게 바로 AI 추론이죠.대규모 모델 추론
정말 흥미롭고 까다로운 워크로드입니다.
그 자체로, 실제로는 두 개의 워크로드입니다.첫 번째 워크로드는 입력 인코딩입니다. 여기서 프롬프트와 다른 모델은
입력은 토큰 생성 준비 과정에서 처리됩니다.이 프로세스를 참조하십시오.
프리필이라고 합니다.그리고 프리필에는 많은 양이 필요합니다
입력값을 전달되는 데이터 구조로 변환하기 위한 컴퓨팅 리소스
다음 프로세스로 넘어가죠.프리필이 완료되면
계산된 데이터 구조가 전달됩니다.
토큰 생성을 수행하는 두 번째 추론 워크로드로 이동합니다.흥미로운 점 중 하나는
토큰 생성의 경우 모델이 각 토큰을 생성한다는 것입니다.
한 번에 하나씩 순차적으로 토큰을 생성합니다.그리고 이것은 완전히 다른 세트를 만들어 줍니다.
AI 인프라에 대한 수요.토큰이 생성될 때마다 전체 모델을 읽어야 합니다.
메모리에서 가져온 것이지만 소량일 뿐입니다.
컴퓨팅이 많이 사용됩니다.이러한 이유로 토큰 생성에는 많은 수요가 발생합니다.
메모리 버스에서는 연산량이 적지만 거의 정반대입니다.
프리필 워크로드의 경우죠.그렇다면 이러한 워크로드는 어떤 역할을 할까요?
차이가 여러분과 AI 인프라에 의미하는 바는 무엇일까요?여러분부터 시작해 볼까요?
얼마 전까지만 해도 챗봇과 같은 많은 워크로드가 대부분 신경 쓰였습니다.
미리 채워진 성능에 대해서요.왜냐하면 프리필을 할 때
이런 일이 발생하면 사용자는 보통 기다리고 있습니다.
그리고 스크린이나 물레를 쳐다보기도 하죠.하지만 일단 토큰이 생기기 시작하면
생성되었으니 그냥 생성하기만 하면 됩니다.
사람이 읽을 수 있는 속도보다 빠르죠.그리 빠르지 않아요.하지만 점점 더 많은 모델들이
에이전트 워크플로우에서 사용되고 있습니다.그리고 여기에는 전체가 필요합니다.
다음 단계로 넘어가기 전에 응답이 생성되어야 합니다.
워크플로의 다음 단계로 넘어가세요.이제 고객들은 빠른 속도를 중요하게 생각합니다.
프리필과 매우 빠른 토큰 생성.이것이 우리에게 가져다 줄 수 있는 일입니다.
수요와 함께 벌어지고 있는 흥미로운 일에 대해
AI 추론 인프라를 위해서죠.정말 빠른 추론에 대한 욕구
즉, AI 추론 워크로드가 현재 가장 많은 것을 찾고 있다는 뜻입니다.
강력한 AI 서버도 마찬가지입니다.자, 좋은 점은 이 두 개입니다.
앞서 말씀드린 다양한 워크로드는 무료 프리필 요건입니다.
컴퓨팅 토큰을 더 많이 생성하려면 더 많은 메모리 대역폭이 필요합니다.따라서 동일한 강력한 장치에서 실행하려면
AI 서버는 우리의 목표를 달성하는 데 도움을 줄 수 있습니다.
뛰어난 성능과 효율성.그래서 우리는 어떻게 하면 좋을지 자문해 보았습니다.
AWS 고객이 Trainium2를 통해 얻을 수 있는 이점을 추론할 수 있을까요?발표하게 되어 정말 기쁩니다.
Amazon Bedrock을 위한 새로운 지연 시간 최적화 옵션으로, 이를 통해 액세스할 수 있습니다.
최신 AI 하드웨어 및 기타 소프트웨어 최적화
다양한 제품에 대해 최고의 추론 성능을 얻으려면
주요 모델.[박수와 환호] 지연 시간에 최적화된 추론
미리보기로 지금부터 사용할 수 있습니다.
일부 모델에만 해당됩니다.그리고 그 모델 중 하나
널리 알려진 라마입니다.그리고 지연 시간이 정말 기대됩니다.
최적화된 버전의 라마 405B와 소형 라마 70B 모델이 이제 최고의 성능을 제공합니다.
모든 공급자의 AWS에서 사용할 수 있습니다.[박수] 여기 있어요
가장 크고 가장 인기 있는 라마 405B의 성능
라마 모델.총 시간을 보고 있어요.
요청을 처리하고 응답을 생성하기 위해서죠.따라서 두 가지가 모두 포함됩니다.
프리필 워크플로와 토큰 생성 워크플로가 있습니다.여기서는 낮을수록 좋습니다.저기 암반이 보이시죠?
지연 시간에 최적화된 오퍼링은 다른 오퍼링보다 훨씬 낮습니다.하지만 다른 모델을 사용한다면 어떨까요?발표하게 되어 정말 기쁩니다.
Anthropic과의 파트너십을 통해 지연 시간에 최적화된 제품을 출시할 예정입니다.
매우 인기 있는 새로운 Claude 3.5 모델의 버전입니다.요청에 따라,
지연 시간에 최적화된 Haiku 3.5는 보다 60% 더 빠르게 실행됩니다.
스탠다드 하이쿠 3.5이며, 가장 빠른 추론을 제공합니다.
어디에서든 하이쿠 3.5에 적합합니다.[박수] 그리고 라마처럼 하이쿠 3.5도
이 성능을 달성하기 위해 Trainium2를 활용하고 있습니다.하지만 그냥 복용할 필요는 없습니다.
이에 대한 제 말씀입니다.무대에 초대하게 되어 정말 기쁩니다.
스케일링 법률 논문의 공동 저자 중 한 명입니다.
앞서 말씀드렸던 내용인데요.공동 설립자 겸 최고 컴퓨팅 책임자인 Tom Brown을 환영합니다
Anthropic에서 이들이 어떻게 혁신하고 있는지 공유해 주세요.
트레이니엄과 AWS와 함께요.[음악 재생] 고마워요 피터.Anthropic에서는 신뢰할 수 있는 AI를 구축합니다.매일 수백만 명의 사람들이
전 세계 사람들이 클로드 (Claude) 의 도움을 받고 있습니다.클로드님은 코드를 작성하시는데요,
문서를 편집하고 도구를 사용하여 작업을 완료합니다.솔직히 말씀드리자면
제가 말씀드리려는 이 기조연설의 절반을 클로드가 썼어요.자, 우리의 파트너십 덕분입니다.
AWS와 함께요.대기업과 중소기업은 보안 클라우드에서 Claude를 사용할 수 있습니다.
이미 신뢰하고 있는 기업이죠.시간을 좀 할애할게요
협업이 어떻게 이루어지는지 더 자세히 알아보겠습니다.먼저 클로드 3.5에 대해 이야기해 보겠습니다.
방금 피터가 말한 하이쿠.최신작 중 하나예요
그리고 가장 빠른 모델도 있고요.작은 크기에도 불구하고
때로는 성능에 필적하는 강력한 성능을 제공합니다.
당사의 가장 큰 모델인 Opus의 제품이면서 가격은 15배나 저렴합니다.Peter가 말했듯이, 우리는 함께 일합니다.
고객이 실행할 수 있는 이 지연 시간 최적화 모드를 구축하기 위해서입니다.
Trainium2에서는 하이쿠가 훨씬 더 빨라졌습니다.즉, 오늘부터 달릴 수 있다는 뜻이죠.
하이쿠는 60% 더 빨라졌고, 변경은 필요 없습니다.
API에서 스위치를 켜기만 하면 요청이 라우팅됩니다.
새 Trainium2 서버로간단합니다.[박수] 자, 이 속도는 정말 좋아요
루프 내 상호작용.그래서 저는 코더입니다. 자동 완성을 상상해 보세요.
탭을 눌러야 하는 곳에서 제안을 완료하세요.
키 입력 사이의 짧은 시간에 말이죠.속도를 60% 높이면
여기서 큰 차이가 납니다.여러분 사이의 차이일 수 있습니다.
완료가 표시되거나 전혀 표시되지 않습니다.그럼 어떻게 이렇게 빨리 만들 수 있었을까요?우선, 이걸 보세요.이건 짐승이에요.저 기계 좀 봐봐 그리고
그 안에 들어 있는 각 칩은 상당한 사양을 가지고 있습니다.
피터가 말했잖아요그 안에서 페타플롭이 넘는 컴퓨팅을 할 수 있습니다.
시스톨릭 어레이, 충분한 메모리 대역폭,
빠른 상호 연결, 훌륭한 사양을 갖추고 있습니다.하지만 모든 엔지니어가 알고 있듯이
사양만으로는 충분하지 않습니다.최고의 성능을 얻으려면 다음을 유지해야 합니다.
배고픈 수축기 어레이는 항상 먹이를 먹었죠.즉, 작업의 순서를 정해야 한다는 뜻이죠.
그래야 그들이 메모리에 입력되는 것을 기다리며 차단되는 일이 없죠.
인터커넥트를 통해 어디서든 말이죠.마치 테트리스 게임 같아요.
타이트하게 포장할수록 더 싸게 포장할 수 있습니다.
그리고 모델이 더 빨라집니다.그럼 이 테트리스 게임을 어떻게 풀어볼까요?음, 앤트로픽의 퍼포먼스
엔지니어링 팀은 아마존 및 안나푸르나와 긴밀하게 협력하고 있습니다.
1년 넘게 이 도전을 해왔습니다.컴파일러가 할 수 있다는 것을 알게 되었습니다.
많긴 하지만 완벽하진 않아요.그리고 저희 규모로 보면
완벽해지려고 노력해볼 가치가 있어요.단일 성능 최적화
Anthropic의 경우 충분한 컴퓨팅 성능을 확보할 수 있습니다.
백만 명의 신규 고객에게 서비스를 제공하기 위해서죠.즉, 한 번 내려올 가치가 있다는 뜻입니다.
NKI와 같은 낮은 수준으로 가서 커널을 비슷하게 작성하십시오.
원시 하드웨어와 마찬가지로 말이죠.마치 가장 중요한 부분을 파이썬에서 C로 옮기는 것과 같습니다.
프로그램의 한 부분이죠.그리고 우리는 트레이넘의 디자인을 발견했습니다.
이런 유형의 저수준 코딩에 적합합니다.그래서 사람들은 이 사실을 모를 수도 있습니다.
하지만 다른 AI 칩의 경우 실제로 어떤 명령어인지 알 방법이 없습니다.
커널에서 실행되고 있습니다.즉, 다음을 추측해야 한다는 뜻입니다.
눈가리개를 끼고 테트리스를 하는 것과 같아요.트라이늄은 첫 번째 칩입니다.
모든 명령의 타이밍을 기록할 수 있는 걸 봤어요
시스템의 어느 곳에서나 실행됩니다.보여드릴게요.예를 하나 들어보죠.
실제 저수준 Trainium 커널의
저희는 앤트로픽에서 개발했습니다.여기서 정확히 언제인지 알 수 있습니다.
차단되었을 때 수축기 배열이 실행 중이었는데, 그 결과를 보면
정확히 왜 차단됐는지, 무엇을 기다리고 있었는지눈가리개를 벗을 수 있어요.이렇게 하면 저수준 커널을 작성할 수 있습니다.
더 빠르고, 더 쉽게,
제 생각에는 훨씬 더 재미있습니다.좋아요, 재밌는 얘기가 나와서 말인데
발표할 게 있어요.아시다시피, 지금까지는 집중해 왔어요.
추론에 대해서요. 그렇다고 해서 트레니움이라고 부르지는 않죠.다음 기회에 발표하게 되어 정말 기쁩니다.
트레니엄과 함께하는 클로드 세대: 프로젝트 레이니어, 수백 개의 신규 아마존 클러스터
수천 개의 트레이니움2 칩.[박수와 환호] 그러니까, 수십만 개의 칩이
밀도가 높은 엑사플롭스 수백 개를 의미하는데, 이는 5배 이상 많은 양입니다.
지금까지 사용해 본 모든 클러스터.그렇다면 레이니어는 무엇을 의미할까요?
고객을 위해서요?글쎄요, 전 세계는 이미 우리가 무엇을 할 수 있었는지 잘 알고 있습니다.
마지막 클러스터에서 말이죠.올해 초,
앤트로픽은 세계에서 가장 똑똑한 모델인 클로드 3 오푸스를 출시했습니다.
4개월 후 우리는 클로드 3.5 소넷을 이전보다 훨씬 더 똑똑하게 출시했습니다.
오푸스 비용은 5분의 1 수준이었죠.그러다가 지난 달에
3.5 하이쿠와 업그레이드된 3.5 소넷을 모두 출시했습니다.
컴퓨터를 사람처럼 사용할 수 있죠.레이니어 프로젝트의 속도가 빨라질 것입니다.
우리의 발전은 두 연구 모두에 힘을 실어줄 것이며 더욱 발전할 것입니다.
그리고 우리의 차세대 스케일링.즉, 고객은 다음과 같은 혜택을 누릴 수 있습니다.
더 낮은 가격과 더 빠른 속도로 더 많은 인텔리전스, 더 큰 상담사와 함께 신뢰할 수 있는 더 스마트한 에이전트
그리고 더 중요한 프로젝트.트레이니엄2와 프로젝트 레이니어를 통해
우리는 단지 더 빠른 AI를 구축하는 것이 아니라 신뢰할 수 있는 AI를 구축하고 있습니다.
확장 가능한 AI.감사합니다.[박수와 환호] [음악 재생] 고마워요, 톰.인류학적인 이것과 함께 혁신하기
지난 한 해는 흥미진진한 여정이었으며 우리는 다음과 같은 에너지를 얻었습니다.
다가올 일의 가능성.좋아요, 앞서 말씀드렸듯이
최고의 AI 인프라를 구축하려면 구축해야 합니다.
가장 강력한 서버.이것이 바로 스케일 업 부분입니다.
문제의 핵심이죠.하지만 그건 이야기의 절반에 불과합니다.훈련을 하고 싶다면
가장 큰 모델인 만큼 가장 큰 모델도 만들어야 합니다.
프로젝트 레이니어 같은 클러스터.이제 두 번째 이야기로 넘어가죠.
이야기의 절반은 스케일아웃 이야기입니다.이것이 바로 AWS의 오랜 역사입니다.
고성능 스케일아웃을 통한 혁신
인프라는 정말 유용합니다.이에 대한 좋은 예가 있습니다.
스케일아웃 혁신이 시작되고 있습니다.
AI에 최적화된 탄력적인 네트워크.이제 훌륭한 AI 네트워크는 많은 것을 공유합니다.
모든 것이 그렇지만 훌륭한 클라우드 네트워크와 공통점이 있습니다.
엄청나게 늘어납니다.만약 이게 라스베가스 싸움이었다면
근접전도 아니겠죠.[복싱 벨 소리] 물론이죠. 클라우드 네트워크에는 많은 것이 필요합니다.
네트워크를 보장할 수 있는 충분한 용량
절대 고객을 방해하지 않습니다.사실 제임스 해밀턴이 말했죠.
첫날 저녁 기조 연설에서 이에 대해 이야기했습니다.하지만 AI 네트워크에는 방법이 필요합니다.
더 많은 용량.리콜
각 Trainium2 울트라 서버는 거의 13테라비트에 달한다는 것을 알 수 있습니다.
네트워크 대역폭.그리고 훈련 중에는 모든 서버가
다른 모든 서버와 정확히 동시에 통신해야 합니다.따라서 네트워크는 거대해야 합니다.
속도가 절대 느려지지 않도록 하기 위해서요
그 서버들.클라우드 네트워크는 빠르게 확장해야 합니다.
성장을 수용하기 위해서죠.수천 대의 서버를 추가하고 있습니다.
매일 전 세계 데이터 센터를 이용하고 있습니다.하지만 조금 앞서 논의한 바와 같이
AI는 그 어느 때보다 빠르게 확장되고 있습니다.수십억 달러를 지출하는 경우
AI 인프라를 구축하는 데 드는 비용을 즉시 설치해야 합니다.그리고 클라우드 네트워크
안정적이어야 합니다.그들은 납품했고, 제공하기도 했습니다.
대부분의 업체에서 달성할 수 있는 것보다 훨씬 더 나은 가용성
정교한 온프레미스 네트워크.당사의 글로벌 데이터센터 네트워크
99.999% 의 가용성을 제공합니다.하지만 여기에도 AI 워크로드가 있습니다.
더 까다롭습니다.AI 네트워크가 경험하는 경우
일시적인 장애가 발생하더라도 교육 과정이 지연될 수 있습니다.
전체 클러스터에 걸쳐 유휴 용량이 발생합니다.
그리고 훈련 시간도 길어졌죠.그럼, 어떻게 기반을 다질 수 있을까요?
훌륭한 AI 네트워크를 만들기 위한 클라우드 네트워크의 혁신은 무엇일까요?다음은 최신 사진입니다.
차세대 AI 네트워크 패브릭을 우리는 10p10u 네트워크라고 부릅니다.이 네트워크 패브릭은 전원을 공급하는 네트워크 패브릭입니다.
우리의 UltraServer 두 클러스터, 하지만 우리는 그 네트워크를 둘 다에 사용합니다.
트레이니엄 및 엔비디아 기반 클러스터.우리는 이를 10p10u라고 부릅니다.
수십 페타비트의 네트워크 용량을 제공할 수 있기 때문입니다.
수천 대의 서버에 미만
10마이크로초의 지연 시간.그리고 10p10u 네트워크는 방대합니다.
병렬적이고 조밀하게 상호 연결되어 있습니다.그리고 10p10u 네트워크는 탄력적입니다.규모를 조금만 줄일 수 있습니다.
랙 몇 개만 사용하거나 여러 개를 아우르는 클러스터로 확장할 수도 있습니다.
물리적 데이터센터 캠퍼스.그리고 여기서 보고 계신 것은
10p10u 랙 하나일 뿐이죠.자, 스위치를 눈치채셨을 겁니다.
아름다운 초록색이죠.녹색은 사실 제가 가장 좋아하는 색이에요.저는 브리티시 레이싱 그린이 더 좋아요.
하지만 멋진 색상이네요.그래서 녹색 스위치는 본 적이 없어요.
전에 저희 데이터 센터에서요.그래서 팀원들에게 물었죠.
왜 이런 초록색이죠?음, 이 초록색
그리너리라고 불리는데 2017 팬톤 컬러였어요.
올해의 상이며 분명히 우리 공급업체 중 한 곳인 것 같습니다.
페인트가 조금 남아서 아주 좋은 거래를 제안했습니다.그리고 제가 이 이야기를 좋아하는 이유는
우리의 디자인 철학을 담았습니다.중요한 일에 돈을 쓰세요
고객에게 제공하고 페인트를 좋아하지 않는 물건에 비용을 절약하세요.이제 다른 건, 아마도
여기 보신 게 엄청 많다는 거예요.
네트워킹 케이블을 이 랙에 꽂으세요.이 중 녹색이 아닌 부분은 네트워크 패치 케이블입니다.
또는 패치 패널.고밀도 네트워크 패브릭을 구축하려면
이와 같이 스위치를 상호 연결해야 합니다.
아주 정밀한 패턴으로 말이죠.그게 바로
이 패치 패널은 가능하죠.그리고 이 패치 패널들은
수년 동안 우리에게 좋은 서비스를 제공해 왔습니다.하지만 보시다시피
10p10u 네트워크에서는 케이블이 복잡하기 때문에 상황이 점점 복잡해지고 있습니다.
크게 성장했습니다.그리고 논의한 바와 같이
설치 속도가 훨씬 빨라졌습니다.그래서 이게 절호의 기회였어요.
팀이 혁신할 수 있도록 말이죠.그들의 혁신 중 하나
전용 트렁크 커넥터를 개발하고 있었습니다.이에 대해 생각해 볼 수 있습니다.
16개의 개별 광섬유 케이블을 결합한 슈퍼 케이블로
견고한 단일 커넥터로그리고 이 게임의 판도를 바꾸는 이유는
이 모든 복잡한 조립 작업이 공장에서 이루어진다는 것이죠.
데이터센터 바닥에서는 안 돼요.이렇게 하면 획기적으로 간소화됩니다.
설치 과정이 거의 필요하지 않습니다.
연결 오류 위험.조금 소박하게 들릴 수도 있겠지만
그 영향은 상당했습니다.트렁크 커넥터를 사용하면 속도가 빨라집니다.
AI 랙 설치 시간이 54% 나 단축된 것은 말할 것도 없습니다.
훨씬 더 깔끔해 보이네요. 초록색 스위치가 이제 정말 눈에 띄네요.하지만 팀은 멈추지 않았습니다.
여기서 혁신하고 있어요.여기 또 하나의 위대한 혁신이 있습니다.그들은 이것을 파이어플라이 옵틱 플러그라고 부릅니다.그리고 이 독창적인 저가형 장치는
소형 신호 리플렉터 역할을 하므로 종합적인 테스트가 가능합니다.
랙이 도착하기 전에 네트워크 연결을 확인할 수 있습니다.
데이터 센터 바닥에서즉, 낭비하지 않는다는 뜻이죠.
서버가 도착하면 언제든지 케이블을 디버깅할 수 있습니다.그게 중요하죠. 왜냐하면
AI 클러스터의 세계에서 시간은 말 그대로 돈입니다.하지만 여기서 그치지 않습니다.파이어플라이 플러그는 두 가지 역할을 합니다.
먼지 입자의 유입을 방지하는 보호 씰 역할을 합니다.
광학 연결부에 들어가기.사소하게 들릴 수도 있겠지만
하지만 아주 작은 먼지 입자라도 성능이 크게 저하될 수 있습니다.
무결성 및 네트워크 생성
성능 문제.그래서, 이 간단한 장치는 더 나아졌습니다.
네트워킹 성능도 마찬가지입니다.따라서 한 가지 설득력 있는 솔루션으로
우리는 두 가지 중요한 문제를 해결했습니다.두 마리의 새에게 먹이를 주는 예시입니다.
스콘 한 개로.이런 혁신이 있죠.
이것이 10p10u 네트워크를 만드는 데 도움이 되었습니다.
역사상 가장 빠른 스케일링 네트워크.그리고 링크의 개수를 볼 수 있습니다.
저희 다른 곳에 설치했습니다.
이 차트에 네트워크 패브릭이 나와 있습니다.그리고 10p10u의 경사로는
네트워크는 우리에게도 전례가 없습니다.3백만 개 이상의 링크를 설치했습니다.
지난 12개월 동안, 그리고 이는 시작하기도 전입니다.
트레이니엄2 램프를 보기 위해서요.그게 우리를 데려다 주죠.
우리의 마지막 과제는 더 높은 성과를 내는 것입니다.
네트워크 안정성.실패의 가장 큰 원인은
AI 네트워크는 옵티컬 링크입니다.옵티컬 링크는 미니어처입니다.
이 모든 케이블에서 광 신호를 보내고 받는 레이저 모듈
저희가 살펴봤는데요.이제 AWS는 자체적으로 설계하고 운영하고 있습니다.
사용자 지정 광학 장치는 수년 동안 사용되어 왔습니다.그 결과 우리의 운영은
엄격함과 엄청난 규모 덕분에 우리는 한 걸음 더 나아갈 수 있었습니다.
실패율은 일관되게 유지되고 있습니다.그리고 이것은 놀라운 진전입니다.
이는 규모에서 비롯된 것입니다.하지만 아무리 멀리 달려도
이러한 실패를 극복할 수는 없을 것입니다.
실패를 완전히 없애기 위해서요그래서 우리는 어떻게 할 수 있는지 살펴봐야 합니다.
실패의 영향을 줄이세요.그리고 모든 네트워크 스위치에는 데이터가 필요합니다.
패킷을 라우팅하는 방법을 알려주기 위해서죠.이것들은 기본적으로 맵입니다.
네트워크에 대해서요.AI 네트워크에서는 이 맵에 대해 고려해야 할 사항이 있을 수 있습니다.
수십만 개의 경로.그리고 옵티컬 링크에 장애가 발생할 때마다
지도를 업데이트해야 합니다.그럼 어떻게 하면 빨리 할 수 있을까요?
그리고 믿을 수 있게?간단한 접근 방식은
맵을 중앙에서 관리하는 거죠.네트워크를 최적화하는 원브레인
정말 매력적으로 들리지만 한 가지 문제가 있습니다.네트워크가 방대할 때는
중앙 제어는 병목 현상이 발생합니다.장애를 감지하는 것은 어렵습니다. 스위치를 업데이트하는 것은 어렵습니다.
매우 느릴 수 있으며 중앙 컨트롤러는
단일 장애 지점입니다.이것이 대규모 네트워크가 필요한 이유입니다.
일반적으로 탈중앙화되죠.BGP 및 OSPF와 같은 프로토콜을 사용하여 스위치는 상태를 공유합니다.
이웃과 함께 업데이트하고 이들이 협업하여 제작합니다.
이웃에게 적합한 네트워크 맵.그리고 이러한 접근 방식은 강력합니다.
하지만 완벽하진 않아요.대규모 네트워크에서는 링크에 장애가 발생하면 상당한 시간이 걸릴 수 있습니다.
네트워크는 협업을 통해 최적의 새 맵을 찾기 위해 전환됩니다.
네트워크용.그리고 AI 네트워크에서는
이제 일을 하지 않을 때죠.그래서, 둘을 마주했을 때
최선의 선택이 아닌 경우, 종종 새로운 길을 개척해야 합니다.그래서 우리는 10p10u 네트워크를 사용하여 전체를 구축하기로 결정했습니다.
새로운 네트워크 라우팅 프로토콜.우리는 이 프로토콜을 스케일러블이라고 부릅니다.
인텐트 기반 라우팅 또는 SIDR.네, 네트워킹 담당자에게도 적합합니다.
방에서 보면 말장난일 수도 있어요.SIDR이 최고입니다.
두 세계 모두에서 말이죠.SIDR에 대해 쉽게 생각해 볼 수 있는 방법
중앙 계획자가 증류 작업을 맡게 되나요?
네트워크를 아래로 밀어 내릴 수 있는 구조로 만들죠.
네트워크의 모든 스위치에 연결해서 스위치가 빠르게 작동할 수 있도록
실패를 발견했을 때 자율적으로 결정을 내립니다.따라서 SIDR은 중앙 계획을 제공합니다.
분산형 속도를 통한 제어 및 최적화
그리고 탄력성.결과적으로 SIDR은 이에 대응합니다.
최대 규모의 10p10u 네트워크에서도 1초 이내에 장애가 발생하는데, 이는 10배 더 빠른 속도입니다.
다른 네트워크 패브릭에서 사용하는 다른 접근 방식보다 말이죠.하지만 다른 네트워크들은 여전히 그럴 수도 있겠지만
경로를 다시 계산하는 중인데 10p10u 네트워크가 다시 작동합니다.좋아요, 얘기 많이 했어요
오늘 저녁에는 많은 얘기가 나왔어요.Dave는 핵심 혁신에 대해 이야기했습니다.
니트로, 그래비톤, 스토리지와 같은 우리의 투자 전반에 대해
우리가 가장 크고 강력한 AI 서버를 구축하는 방법에 대해
Trainium2를 통해 AI가 우리의 이점을 활용하는 방법
수년간의 스케일 아웃 클라우드 혁신.오늘 밤 이곳을 떠나시길 바랍니다.
우리가 어떻게 혁신하고 있는지 이해하면서
스택 전체에 걸쳐 진정으로 차별화된 제품을 만들어 보세요.
고객인 여러분을 위한 오퍼링.이걸로 안녕히 주무세요.감사합니다. re:Invent를 즐기세요.[박수와 환호] [음악 재생]