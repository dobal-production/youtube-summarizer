- 안녕하세요, 여러분,
세션에 오신 것을 환영합니다.제 이름은 페데리카 시우포입니다.저는 이탈리아인이지만 살고 있습니다.
스페인, 마드리드에서만나서 반가워요
오늘은 모두 함께 모였어요.그리고 오늘은 사이 벤남도 함께 해요. - 안녕하세요, 여러분.사이, 여기 있어요.저는 AWS의 컨테이너 전문가입니다.저는 텍사스 오스틴에 거주하고 있지만, 원래는 인도 출신으로 네트워킹 전략에 대해 이야기할 수 있어서 기쁩니다.
오늘날의 쿠버네티스를 위해 말이죠.이 강연은 400개 레벨로 구성되어 있습니다. 먼저 잠깐 설명해 드릴게요.
복잡성 수준은 작아지고, 저희가 쌓아나가면서 점점 더 발전해 나갑니다.
이제 세션이 끝날 무렵이지요.바로 시작해 보죠. - 네, 사실 우리
모든 상호 작용을 통해 아젠다를 구축했습니다.
2024년에도 고객과 함께한 내용은 현재와 같습니다.
둘 다 컨테이너 전문가이기 때문에 Kubernetes 네트워킹에 대해 많은 대화를 나누고 있습니다.그래서 우리는 한 해 동안 가장 흥미로웠던 고객 상호작용과 더불어, 아시다시피,
가장 많이 묻는 질문.뭐, 이 세션을 좀 더 인터랙티브하게 만들기 위해서죠.번역해 드렸습니다
이러한 고객 질문 및 주제를 요구 사항으로
애플리케이션.이게 렌탈 스토어 애플리케이션이 될 거예요. 오늘은
Sai와 제가 맡아서 역할극을 좀 해봐요. 그럼 저는 클라우드 아키텍트가 되어 다음과 같은 작업을 담당할 것입니다.
클라우드와 쿠버네티스 클러스터를 설계합니다.
이 애플리케이션을 실행하려면 사이- - 네, 제가 할게요
클러스터 오퍼레이터 맞죠?제가 오늘 세션에서 이야기를 나눈 사람들 대부분에 대해 말씀드릴 수 있을 것 같은데요, 제 생각에는
오늘 청중에 계신 여러분은 회사에서 쿠버네티스 클러스터를 운영하는 플랫폼 팀에 속해 있습니다. 제가 바라는 것은
지금 바로 그 역할을 모방해 보세요.그러니까 페데리카가 제게 요구 사항을 알려줄 거예요그녀는 정말 대단한 입장에서 태어날 거예요
정통한 클라우드 아키텍트인데 제가 충족시켜야 할 요구 사항을 제시할 거예요
플랫폼 팀으로서 말이죠.이게 뒷전이고
앞으로는 해볼게요. - 네, 그럼 모자를 쓸게요. - 좋아요. - 그래서 우리, 사이, 우린
신청에 필요한 요구 사항이 다릅니다.제가 가장 먼저 하고 싶은 일은 삶을 단순화하고 더 쉽게 만드는 것입니다.
클러스터 작업을 단순화해 보겠습니다.
가능한 한 많이, 저희 애플리케이션도 마찬가지고요.
외부 애플리케이션이므로 고객이 실제로 외부에서 액세스할 수 있습니다.그럼 함께 그 방법을 알아보도록 하겠습니다.그리고 우리한테도 좀 필요해요.
전반적으로 레질리언스를 개선하고 싶다고 가정해 봅시다.
특히 네트워크의 경우, 하지만 네트워크를 기반으로 하기도 합니다.
우리가 발견한 결과, 우리는 또한 할 수 있기를 원합니다.
이 아키텍처와 이 애플리케이션을 살펴보세요.
매번, 좀 더, 전혀 그렇지 않은 방식으로
제 애플리케이션 팀에 부담을 주는데, 그들은 뭐, 많은 비용을 지출하고 있죠.
관찰하는 데 많은 시간을 할애했지만 실제로는
많은 마이크로서비스에서 이 작업을 수행하는 방법에 대한 명확한 방법또한 몇 가지 요구 사항도 있습니다.
보안팀에서 보냈기 때문에 이를 적용해야 합니다.그리고 우리는 할 수 있기를 바랍니다.
이러한 문제를 해결하기 위해 다른 접근 방식을 취하세요.
예를 들어 새 업데이트를 할 때 클러스터 내에서 장애가 발생합니다.예를 들어 3개월에 한 번씩 클러스터를 업데이트해야 하고 이런 식으로요.그래서 이 모든 작업들은
이로 인해 운영 중단이 발생할 수 있습니다. 현재로서는 전체 업그레이드 등을 통해 작업을 진행하고 있지만
조금은 문제가 될 수 있는 것에 대해 좀 더 자세히 살펴보겠습니다.
좀 덜 파괴적이죠. 그런 의미에서는 청록색처럼 말이죠.하지만 더 깊이 파고들기 전에, 사이, 이미
신청서를 보내드렸으니 검토해 볼 수 있다면. - 네, 여기서 신청서를 정말 빠르게 살펴보도록 하겠습니다.그럼 이걸 바꿔볼게요
여기 제 컴퓨터로 가볼게요. 미리 말씀드리자면, 잘못된 화면이 공유되고 있어요.그러니 잠시만 기다려주세요.
여기서 무슨 일이 벌어지고 있는지 봅시다. - 네, 그럼 그 동안 그런 의미에서 우리가 하고자 하는 것을 복습해 보죠.하지만 제가 복습을 해볼게요.
Sai가 검토하는 동안 우리가 실제로 살고 있는 곳에 애플리케이션을 배포하는 방법
그는 응용 프로그램을 가지고 있어요.그런 의미에서 우리 조직은
서로 다른 사업부, 그리고 각 사업부
전용 계정이 있습니다.또한, 몇 개 있습니다.
고려해야 할 온프레미스 데이터 센터.사실 모든 것이 그렇습니다.
트랜짓 게이트웨이와 연결되어 있습니다.또한 환경을 위한 몇 가지 직접 연결 등도 있습니다.그럼 응용 프로그램을 찾은 것 같아요, 그렇죠?- 네, 알겠어요.완벽한 타이밍, 좋아요, 좋아요.그럼 이걸 좀 더 크게 만들어 볼게요.그래서 저희가 말씀드린 게
우리는 애플리케이션의 로컬 버전을 설치해서 실행하고 있었습니다.그래서 페데리카 팀은
기본적으로 로컬 머신에 컨테이너를 구축했고, 이를 위해 로컬에서 실행 없이 실행되는 리테일 스토어 샘플 애플리케이션 버전을 만들었습니다.
클라우드에서 실행.그럼 여기서 간단한 명령을 실행해서 어떻게 생겼는지 봅시다.
애플리케이션을 시작하기 위해서요.좋아요, 이제 설정해 볼게요
MySQL 암호를 전달한 다음 도커 컴포지션을 실행하세요.그리고 로컬에서 컨테이너를 사용할 수 있는 좋은 방법이라고 생각합니다.컨테이너 이미지를 다운로드해서 어떤 작업을 수행했는지 알 수 있습니다. 이제 로컬에서 몇 초 만에 애플리케이션을 시작합니다.
이제 완전히 시작되었습니다.그리고 실제로 가보죠.
여기 있는 로컬 호스트에게 가서 애플리케이션에 액세스하세요.붐, 이제 끝났어요.이곳이 바로 우리의 아름다운 소매점입니다.
로컬에서 실행되는 샘플 애플리케이션을 저장하세요.하지만 이 방법은 개발용으로는 좋지만 반복적인 작업도 가능하게 합니다.
로컬 머신에 있는 컨테이너를 사용하여 매우 빠르게 개발하기 위해서는 실행 방법이 필요합니다.
이거 클라우드에서 하는 거 맞죠?자, 이제 다음 단계로 넘어가죠. - 네, 맞아요, 그리고
실제로 필요한 것은 환경의 모든 VPC에 소매 계정 전용으로 이 애플리케이션의 복제본을 두는 것입니다.Sai가 방금 보여준 애플리케이션은 서로 다른 애플리케이션으로 구성되어 있습니다.
컴포넌트를 분리했는데, 몇 개 있어요.
인프라 의존성거기서 MySQL을 본 적이 있습니다.그럼 바로 시작해 보죠.우리가 가장 먼저 원하는 것은
삶을 단순하게 만드는 겁니다. 실제로 생각해보면
쿠버네티스 아키텍처에는 구성해야 할 네트워킹 구성 요소가 많이 있습니다.
그리고 컨트롤 플레인과 다양한 구성 요소뿐만 아니라
서로 소통하는 것뿐만 아니라 컨트롤 플레인과 데이터 플레인을 어떻게 통합할 수 있을지도 모릅니다.데이터 플레인 내에서도 우리가 고려해야 할 몇 가지 핵심 네트워킹 구성 요소들이 있는데, 클러스터는
해당 구성 요소를 사용할 수 있도록 구성해야 합니다.예를 들어, 우리는
kube-proxy, 코어DNS, CNI 등 많은 것들,
우리는 이것을 단순화하고자 하는데, 실제로 이것은
Amazon EKS가 도움이 될 수 있는 부분이죠.그럼, 사이, 원하세요?
이거 가져가고 싶은데... 네, 물론이죠.그럼 얘기 좀 해볼까요?
아마존 EKS에 대해 조금 알아보겠습니다.아마 궁금하실 겁니다. “사이, 이건 네트워킹 토크예요.왜 우리가 EKS에 대해 얘기하는 거죠?”제 말을 믿으세요. 이제 해낼 수 있을 거예요.그러니까 아마존 EKS는 정말
방금 관리형 쿠버네티스.저희 회사만의 특별한 것은 아닙니다.
쿠버네티스 버전.오픈 소스이고 업스트림이고
적합한 쿠버네티스를 관리하도록 도와드리겠습니다.우리가 처음 출시했을 때
아마존 EKS는, 알다시피, 약 6년 전,
컨트롤 플레인을 관리하여 고객을 돕는 데 중점을 두었습니다.보셨을 텐데요.
아주 깔끔한 애니메이션과 함께, 그 기능들은
컨트롤 플레인으로 여러분을 대신해서 관리하고 있습니다.하지만 우리는 여기서 한 걸음 더 나아가고 있습니다. 여러분도 제가 여기서 무슨 이야기를 하려고 하는지 아실 거라 생각합니다. 하지만 이건 발표였어요.
이번 주 초에 공개한 내용이죠.이제 Amazon EKS는 고객이 데이터 플레인의 일부를 관리할 수 있도록 지원하고 있습니다.그렇다면 기본적으로 Auto는 무엇일까요?
Mode를 통해 고객은 프로덕션 사용 사례에 바로 사용할 수 있는 EKS 클러스터를 즉시 사용할 수 있습니다.이 모든 구성 요소
플랫폼 팀인 여러분과 플랫폼 운영자로서의 저
제가 직접 관리해야 했던 일을 이제 여러분을 대신해서 관리해 드립니다.그리고 범위와 권한도
아시다시피 오토 모드의 비율은 계속 증가하고 있습니다.로드맵을 확인할 수 있습니다.대부분은 GitHub에 공개되어 있습니다.그리고 매우 중요한 것은
자동 모드가 네트워킹과 잘 어울리는 이유는 많은 주요 네트워킹 구성 요소가 자동 모드에서 자동으로 관리된다는 것입니다.이 부분들을 정말 빠르게 살펴보도록 하겠습니다.우선 VPC CNI는
이제 관리해 드릴게요.그러니까 이게, 알다시피
기본적으로 모든 EKS 클러스터에 설정되지만 더 이상 관리되지 않는 클러스터입니다.
데이터 플레인 안에 있는 당신.저희가 대신 처리해 드립니다.즉, 다음과 같은 경우
컨트롤 플레인을 업그레이드하세요. 해당 애드온은
여러분을 위해 업그레이드도 되었습니다.즉, 다양한 관리 작업에 따른 인지 과부하가 줄어든다는 뜻입니다.
데이터 플레인 구성 요소.또한 CoreDNS는 작동하지 않습니다.
kube-proxy도 그렇고, 박스도 그렇고, 이 모든 게 다 될 거예요
일종의 당신을 위해 관리해 주는 거죠.사실, 실제로
여기서 한 가지 더 관리할 것이 있습니다. 바로 애플리케이션 로드입니다.
밸런서 컨트롤러도 마찬가지인데, 이 컨트롤러는 모든 EKS 자동 모드 클러스터와 함께 기본으로 제공됩니다.이 모든 것을 종합하면 기본적으로
Amazon EKS가 컨트롤 플레인 및 데이터 플레인에서 더 많은 기능을 대신 관리할 수 있습니다.하지만 페데리카는 이미 살펴보셨을 겁니다.
CNI에 대해 조금 알아봤습니다.요구 사항을 설명해 주시겠습니까?
그리고 다른 CNI에 비해 이 CNI를 사용하고 싶은 이유는 무엇일까요?— 네, 정확히 말씀드리자면, Amazon VPC CNI의 경우 AWS 내에서 쿠버네티스를 사용하는 방법을 조금 단순화하기 때문에 실제로 사용해보겠습니다.사실상 아마존 VPC는
CNI, 기본 시스템과 긴밀하게 통합되어 있습니다.
네트워크는 Amazon VPC이므로 IP를 할당합니다.
아마존 VPC에서 포드까지그리고 이런 용도로는 아주 좋습니다.
왜냐하면 우리가 모든 것을 활용할 수 있게 해주기 때문이죠.
Amazon VPC의 좋은 점.예를 들어 보안을 할 수 있습니다.옵저버빌리티도 할 수 있죠.
VPC 플로우 로그를 사용합니다.또한 CNI는 고도로 사용자 지정할 수 있습니다.즉, CNI에 정말 적합하고 모든 사양을 필요에 맞게 변경할 수 있습니다.그리고 이것은 우리에게 아주 좋은 일입니다.또한, 고려해야 할 사항이 있습니다.
다음과 호환되는 다른 대체 CNI도 있습니다.
EKS는 지원되지만 지원되지 않습니다.그게 무슨 뜻인가요?선택한 CNI 공급업체의 지원을 받는 것이 좋습니다.하지만 저희는 이 CNI를 고수할 것입니다. 사실 저는 Amazon EKS, 그리고 무엇보다도 자동 모드가 여러분의 삶에 도움이 된다는 점이 마음에 듭니다.
팀을 정말 능률적으로 만들고 그 부담을 덜어야 합니다.
팀에서 물러나서 AWS에 맡기세요. - 네, 당신이 해줘서 기뻐요
VPC CNI를 사용해도 괜찮아요. 그래야 제 삶이 더 편해지기 때문이죠.AWS에 통합되어 있습니다.
플랫폼 팀으로서의 에코시스템, 제가 할 수 있는 일은 더 적어요
관리에 대해 걱정하세요. - 그리고 실제로 말씀하셨잖아요
이전에 로드 밸런서, 로드 밸런서 컨트롤러에 대해 말씀드렸는데요.그러니까 이건 사실 동떨어진 거죠.
우리의 다음 요구사항, 그리고 우리의 다음 요구사항에
고객이 내 애플리케이션에 액세스할 수 있기를 바랍니다.자, Sai가 방금 보여준 것은 훌륭합니다. 그가 로컬에서 실행하고 있다는 사실이죠.
하지만 이건 우리에게 필요한 게 아니에요.그래서 뭔가 더 필요해요.그리고 우리가 생각해볼 때
클러스터 외부에서 애플리케이션에 액세스하는 방법
백엔드 포드에는 항상 일부 Kubernetes 객체, 즉 인그레스 및 서비스 리소스, 인그레스 리소스가 필요합니다.
계층 7, 애플리케이션 계층에서 작동하고
네트워크 전송 계층에서 작동하는 서비스 리소스하지만 뭔가 더 필요하죠.인프라가 좀 필요해요.
트래픽을 유도하는 데 도움이 되는 요소라고 해봅시다.
교실 밖에서, 교실 안에서요.그리고 그 곡은 보통
프록시, 로드 밸런서.따라서 AWS에는 AWS 로드 밸런서 컨트롤러를 사용하여 이를 수행할 수 있는 기본 방법이 있습니다.정말 기대가 됩니다.
AWS 로드 밸런서 컨트롤러의 기능에 대해 말씀드리자면, 다시 말씀드리지만
AWS에서 Kubernetes를 사용하여 운영하면서 우리 팀의 작업을 간소화할 수 있습니다.AWS 로드 밸런서
컨트롤러는 애플리케이션 로드 밸런서를 자동으로 배포합니다.
인그레스 리소스와 서비스, 서비스 리소스를 사용하여 자동으로 배포합니다.
네트워크 로드 밸런서, 즉 네이티브 AWS 로드
실제로 모든 기능과 안정성을 갖춘 밸런서,
확장성 등등, 특히
앞서 말씀드렸듯이 자동 모드에서의 지원은
하지만 특히 더 깊이 파고들고 싶어요.
Layer 7에서 이 기술이 우리에게 어떤 도움을 줄 수 있는지 알아봅시다. 생각해보면 실제로 우리가 사용하고 있는 것은
애플리케이션 로드 밸런서.애플리케이션 로드 밸런서 자체는 계층 7 로드 밸런서입니다.그렇다면 이것이 의미하는 바는 무엇일까요?그러니까 모든 능력,
모든 계층 7 처리는 로드 밸런서 계층에서 이루어집니다. 즉, 다음과 같은 구성에서 오프로드할 수 있습니다.
귀사의 애플리케이션 팀과 제 애플리케이션 팀이 필요로 하는 것은
로드 밸런서에 해야 할 일예를 들어, 인증서,
로드 밸런서로 오프로드할 수 있으며
그런 다음 AWS 인증서 관리를 통해 관리할 수도 있습니다.
따라서 인증서 관리자는 실제로 AWS 로드 밸런서 컨트롤러 자체와 긴밀하게 통합됩니다.그리고 이점을 활용할 수 있습니다.
AWS 로드 밸런서와 보안 간의 이러한 모든 통합, 그리고
AWS 내 자연스러운 제품군.그리고 이것은 우리에게 아주 좋은 일입니다.
우리 삶을 단순화시켜주기 때문이죠.또한, 다음과 같은 것들이 있습니다.
또 다른 방법으로 배포하거나
인그레스 트래픽을 처리하세요. 즉, 서드파티를 사용하세요.
인그레스 컨트롤러.이제 처리, 처리 계층, 기능 계층이 책임에서 바뀌는 것을 볼 수 있습니다.
로드 밸런서의 책임이 되는 것으로
컨트롤러 자체에 대해서요.이게 핵심인데, 예를 들어 예전에 어디서 오프로드를 할 수 있었을까요?
이제 SSR 인증서 관리를 로드 밸런서에 맡길 수 있습니다.
이를 인그레스 컨트롤러에 제공해야 합니다.그리고 이것은 근본적으로 매우 다릅니다.또 한 가지 다른 점은 관리 능력을 좀 더 높일 수 있다는 것입니다.
인그레스 리소스만.따라서 처리가 필요한 경우
서비스 리소스에는 추가 컨트롤러, 즉 서비스 컨트롤러가 필요합니다.예전에는 EKS에서 이 기능을 사용할 수 있었습니다.
인트리 로드 밸런서 컨트롤러 또는 서비스 컨트롤러는 매우 투명하게 처리해야 하지만
아직 사라지지 않았습니다.아직 남아있긴 하지만, 저희는 업데이트를 푸시하는 중일 뿐입니다.꼭 필요한 것이 있습니다.
보안 업데이트.따라서 서비스를 처리하기 위해 실제로 다시 한 번 권장되는 사항은 다음과 같습니다.
로드 밸런서의 배포는 다시 말하지만, AWS Load입니다.
밸런서 컨트롤러.재미있네요.
인그레스 컨트롤러를 사용하는 경우에도 여전히 AWS가 필요합니다.
수신 앞에 있는 로드 밸런서를 배포하기 위한 로드 밸런서 컨트롤러
원하는 컨트롤러.사이, 그래, 우린 떠났어
차이점과 이를 통해 우리가 할 수 있는 일은 무엇인지 살펴보겠습니다.
AWS 로드 밸런서 컨트롤러, 타사 컨트롤러, 하지만 다음에서 볼 수 있습니까?
내 애플리케이션에서 작동합니까?정말 멋질 것 같아요. - 해봅시다.그럼 시작해 볼게요
Docker가 만든 첫 번째 종류의 실제 데모는
실제 데모는 아니지만, 이제 시작해볼게요.
응용 프로그램을 실제로 노출하는 방법을 알아봅시다.
레이어 7 기반 로드 밸런싱인 애플리케이션 로드 밸런서입니다.간단히 말씀드리자면 이 다이어그램이 정말 마음에 들어요. 인그레스 리소스를 만들면 분명히 더 많은 것을 얻을 수 있다는 것을 알 수 있기 때문입니다.
레이어 7 수준에서 작동하는 고급 경로 기반 라우팅.다음과 같이 생성할 수 있습니다.
사용자 지정 인그레스 컨트롤러 또는 AWS 로드 밸런서 컨트롤러.그리고 레이어 4 수준에서, 만약
각 개별 서비스에 대한 로드 밸런싱을 원한다면 다음과 같이 할 수 있습니다.
일종의 네트워크 로드 밸런서는 AWS 로드 밸런서 컨트롤러로 만들 수 있는 것이기도 합니다.좋아요, 그럼 시작해 볼까요?
어서 이 얘기 시작하세요.여기 제 EKS 클러스터에서는
우리는 기본적으로 모든 것을 배포했습니다. 아, 인터넷 연결은 이미 어느 정도 되었어요.
클러스터의 모든 포드를 가져올 거예요. 하지만 이 클러스터에는 리테일 샘플용 컨테이너가 이미 배포되어 있습니다.
현재 사용하고 있는 애플리케이션이죠.그리고 중요한 것은, 여기서도 우리가 배포했다는 것을 알 수 있습니다.
AWS 로드 밸런서 컨트롤러.그건 그렇고, 만약
자동 모드 클러스터에서 이 명령을 실행하려면
로드 밸런서 컨트롤러가 자동으로 관리되기 때문에 해당 포드는 보이지 않을 것입니다.하지만 제가 다른 곳에서 실행 중이기 때문에
자동 모드가 아니라 표준 클러스터입니다.
직접 설치해야 했어요.그리고 분명히 언제
클러스터를 업그레이드하고 로드 밸런서 컨트롤러 자체의 업그레이드도 처리해야 합니다.좋아, 일단 컨트롤러가 설치되면 기본적으로 쿠버네티스는
이제 인그레스 리소스가 생성되거나 로드 밸런서 유형의 서비스가 생성되면 컨트롤러가 작동할 수 있습니다.“아, 이제 뭘 해야 할지 알겠어.” 라고 나오는데, 백엔드에서는
AWS에서 우리를 위해 리소스를 생성하기 시작할 거예요.
긴밀하게 통합되었죠?많은 일들이 벌어지고 있어요.
특히 커스텀 도메인을 만들고 있다면
인증서도 있고 그런 것도 있잖아요.세상에는 많은 일들이 벌어지고 있습니다.
Route 53과 ACM, 아시다시피 인증서가 있는 백엔드
기관, 그리고 그 모든 것, 로드 밸런서
컨트롤러가 대신 처리해 드립니다.그래서 인그레스 리소스를 만들었으니 get을 실행해 보겠습니다.
모든 네임스페이스에 인그레스를 적용하면 됩니다.여기서는 인그레스가 있다는 것을 아주 간단하게 알 수 있습니다.
주소가 있습니다.복사해서 액세스하겠습니다.
그거, 하지만 그 전에 빨리 보여드릴게요
인그레스 yaml에 뭐가 들어 있어요.그리고 이건 정말
여기서 인그레스 지정이 어떻게 작동하는지 이해하는 것이 중요합니다. 왜냐하면 다음과 같이 할 수 있기 때문입니다.
여기에서 몇 가지 내용을 확인하세요.특히 주석이 있는데, 주석은 애플리케이션에 이를 알려줍니다.
이번 인그레스를 위해 만들고 있는 로드 밸런서 컨트롤러 ALB는 인터넷이라는 것입니다.
내부를 향하는 것이 아니라 내부를 향하고 있습니다.그래서 우리는 대중을 원해요
이를 위해 인터넷에 접속할 수 있습니다.대상 유형은 IP 모드이고 다른 옵션은 인스턴스 모드입니다.여기서는 다루지 않겠습니다.
지금은 너무 깊지만 몇 가지 자료를 공유하겠습니다.
우리가 왜 그런지 더 깊이 이해할 수 있는 방법을 알려드리죠
두 옵션을 모두 제공하세요.또한 건강 검진도 제공됩니다.
대상 그룹이 자신의 건강 여부를 알 수 있는 경로.그리고 여기서 또 다른 중요한 부분은 바로 서비스입니다.
실제로 라우팅 대상이 되는 거죠?그러니까 제가 급하게 해보면
svc를 UI 네임스페이스에 넣으면 UI가 보입니다.
여기 서비스, 포트 80, 이게 바로 핵심입니다.
해당 인그레스로 라우팅하려는 대상.좋아요, 마지막으로 여기서 말씀드리고 싶은 건, 제가 이걸 받았으니까요.
이번 주에 질문을 많이 받았는데, 자동 모드에서는 로드 밸런서 컨트롤러의 AWS 관리 버전과 일반 버전을 사용하기 위해 특별히 해야 하는 작업이 있나요?
자동 모드가 아닌 클러스터가 있는 클러스터에서 실행 중입니까?그나저나, 그 이후로는
기존 모델에 자동 모드를 추가할 수 있습니다.
클러스터, 이는 AWS 관리형 시스템으로 마이그레이션하는 방법에 매우 중요합니다.
컨트롤러 버전.기본적으로 여기에 인그레스 클래스 이름이 있다는 것을 알 수 있을 것입니다.따라서 사용하고 싶을 때
컨트롤러의 자동 모드 관리 버전,
기본적으로 수행할 작업은 다음을 지정하는 새 수신 클래스를 만드는 것입니다.
대신 해당 컨트롤러에서 인그레스 리소스를 처리하기를 원합니다.이렇게 하면 정말 매끄럽게 작동합니다.
클러스터를 자동 모드로 마이그레이션하기 위해서는
새 인그레스 클래스를 설치한 다음 하기만 하면 됩니다.
보유한 인그레스의 종류를 새 인그레스 클래스로 전환하세요.그런 다음 로드 밸런서를 제거할 수 있습니다.
클러스터의 컨트롤러.더 이상 관리할 필요가 없습니다.좋아, 이제 다 봤으니 기도할게
데모용 인터넷의 신들한테는 거의 다 됐어요. 사실 완벽하게 로딩이 됐어요
빨리요, 고마워요.(웃음) 보시다시피 쿠버네티스의 클라우드에서 실행되는 애플리케이션의 앞에 인그레스 리소스가 있어 애플리케이션 로드 밸런싱이 이루어집니다.좋아, 얘들아, 약속할게
우린 이제 좀 더 낮은 수준의 복잡성에서 시작하고 있어요.
프레젠테이션을 진행하면서 좀 더 자세히 설명해 보겠습니다.그래서 이 데모를 통해 저는
다시 전달해 주세요, 페데리카 씨. 그럼 좀 더 재미있는 이야기를 해봅시다. - 파워포인트, 네,
정말 감사합니다. 이것이 우리의 첫 번째 요구 사항이니까요.다시 말씀드리지만, 우리는
쿠버네티스를 채택하고 있는 저희 팀을 위해 간단하게 시작하세요.
Amazon EKS를 사용하는 클러스터에는 많은 것들이 있습니다.
인증서를 추가하는 방법으로도 할 수 있습니다.
이 도메인 등에 말이죠.고마워요, 사이,
우리가 어떻게 할 수 있는지, 어떻게 할 수 있는지 보여줬지만
다른 요구 사항도 있습니다.자, 이것 좀 봅시다.그래서 우리 팀원들은
네트워크 레질리언스와 관련해서는 많은 문제가 있습니다. 왜냐하면 우리가
이미 모든 모범 사례를 따르고 있으며, 토폴로지 분산 제약이 있는 가용 영역 전체에 포드를 분산하고 있습니다.
또한 애플리케이션 내에 안정성 내장 메커니즘을 많이 배포하고 있습니다.하지만 저희 입장에서는 재해 복구 시나리오를 테스트하기가 정말 어렵습니다.그렇게 하는 데 도움이 될 수 있는 한 가지는 사실 새로운 것입니다.
아마존 EKS와 아마존 복구 컨트롤러 ARC의 통합.상태 점검을 기다릴 필요가 없기 때문에 복구 시나리오를 쉽게 테스트하고 복구할 수 있습니다.
서비스에 장애가 발생할 수 있습니다.하지만 실제로 컨트롤러는 AZ가 다운되었다는 신호를 보내고, 따라서 대상, 엔드포인트도 다운되었다는 신호를 보냅니다.
영향을 받는 구역에는 자동으로
서비스에서 등록이 취소되었습니다.그리고 이것은 우리에게 아주 좋은 일입니다.
- 페데리카, 물어봐야 할 게 있는데, 안 할게
ARC가 뭔지는 아직 모르니까, 왜 ARC가 필요한지 말해줘야겠네요. 이유가 뭔지
우리가 Kubernetes를 사용하는 이유는 포드가 비정상 상태일 때 자동으로 중지되기 때문입니다.
트래픽이 해당 사용자에게 라우팅되고 있나요?그렇다면 ARC를 사용하는 이유는 무엇일까요?- 문제는
시간이 좀 걸려서 기다려야 돼요
이러한 상태 확인이 실패하면 대상의 등록이 취소됩니다.그건 많은 문제가 될 거예요.따라서 ARC는 그 시간을 단축시킵니다. AWS API에서 자동으로 신호를 보내면 바로 신호를 보내니까요.
AZ (예: 실패) 가 발생하면 이 작업은 자동으로 수행됩니다.제 팀의 책임도 그렇게 하는 것만은 사실입니다.
애플리케이션 레질리언트. - 좋아, 그러니까 기본적으로
쿠버네티스는 포드가 비정상임을 감지할 수 있습니다.
그리고 트래픽 라우팅을 중단하세요. 시간이 좀 걸립니다. 왜냐하면
기본적으로 상태 점검이 실패하고 준비 상태 프로브와 상태 프로브가 실패해야 합니다. 그러면 고객에게 영향을 미칠 수 있습니다.하지만 여기서, 아시다시피, 근본적으로
AZ 문제가 발생하는 경우 조금 더 빠르게 진행하여 가용성을 개선하고 있습니다. 여기서는 영역 이동만 하겠습니다.
그 트래픽 맞죠?- 맞아요.
- 멋지네요. - 그리고 우리한테도 정말 흥미로워요. 우리가 할 수 있다는 건
실제 AZ 장애가 발생하지 않았더라도 이러한 시나리오를 테스트해 보세요.이러한 시나리오를 테스트하는 것에 대해 저희 팀에서 말씀드린 바 있습니다.
사실 안정성을 보장하기 위해 애플리케이션을 많이 구축했습니다.그리고 병목 현상 또는 병목 지점을 먼저 관찰해야 하기 때문에 오랜 시간이 걸렸습니다.
잠재적 실패는 다음과 같습니다.그런 다음 구현해야 합니다.
애플리케이션 내에서.다음은 애플리케이션입니다.
애플리케이션 코딩을 사용하는 보조 도구
언어, 프로그래밍 언어, 다른 프로그래밍 언어가 있는 언어그러니까 우리한테는 좀 엉망인 거죠.그리고 저는 거기서 찾고 있었어요.
건축학적 관점에서 보면 이러한 작업을 통합하고 부담을 덜어줄 수 있는 방법을 찾고 있었습니다.
제 애플리케이션 팀으로부터 말이죠.어쩌면 생태계에서 가장 많이 사용되는 방법일지도 모릅니다.
서비스 메쉬를 채택하고 있습니다.그리고 간단히 말씀드리면, 서비스 메쉬란 무엇일까요?그래서 가장 일반적인 것은
서비스 메시 아키텍처에서는 프록시를 가져와 애플리케이션 컨테이너 옆에 배치합니다.클러스터 내 각 애플리케이션 컨테이너에 대해 이 작업을 수행하고
기본적으로 새 계층을 생성하여 새로 만듭니다.
모든 프록시를 끄고 해당 레이어로 푸시합니다.
고급 네트워크 보안 및 네트워크 옵저버빌리티 책임.따라서 애플리케이션 비즈니스 로직에서 이를 제거하게 되는 것인데, 이는 여전히 존재할 것입니다.
개발자가 처리합니다.그 외 다른 것들도 마찬가지고요.
지금은 단 하나의 프로그래밍 언어로만 통합되었는데, 왜냐하면 여러분은
모든 응용 프로그램에 실제로 프록시를 사용하는 거죠.덕분에 제 삶이 더 쉬워지고, 애플리케이션 생활이 더 쉬워지고, 매우 강력합니다.기능과 서비스 메쉬가 우리에게 가져다주는 이점을 살펴보면, 우리가 가진 모든 것들은
실제로 하고 싶은 것이 바로 거기에 있습니다.우리는 할 수 있기를 원해요
예를 들어 추적 요청을 관찰하고 이해하세요.
병목 현상이 무엇인지, 그리고 이러한 안정성 기능을 구현할 수 있기를 원합니다.
애플리케이션 내에서가 아니라 서비스 메시 내에서 말이죠.또한 보안 기능도 있습니다.
보안 팀으로부터 상호 TLS 및 보안과 같은 요청을 많이 받는 경우
워크로드 등서비스 메쉬도 마찬가지이긴 하지만 이는 정말 큰 과제입니다.
몇 가지 어려움이 따르죠. - 맞아요, 페데리카, 당신이 모든 장점을 다루었다는 사실은 마음에 들지만, 당신은 제 역할을 생략하고 있는 것 같아요.
운영자는 모든 문제를 해결해야 합니다.
서비스 메시 실행.아시다시피, 전통적으로
우리가 말하는 서비스 메쉬의 종류는
여기, 이스티오 같은 것들은 사이드카 모델에서 작동하죠, 그렇죠?그래서 도전 과제는, 뭐, 자원 같은 것들도 있겠죠.
효율성 문제, 그렇죠?그러니까 사이드카가 안 될 때는
효율성을 극대화하기 위해 활용한다는 사실, 아시다시피
사이드카는 확장에 따라 모든 포드와 함께 확장해야 합니다.
확대하는 것은 어려울 수 있습니다.게다가 사이드카를 클러스터에 설치하는 것만으로는 그리 쉬운 일이 아닙니다.사이드카를 추가할 때마다 포드가 이동해야 하기 때문에 포드를 다시 시작해야 합니다.
재시작 주기를 거쳐야 합니다.그것도 좋지 않아요.게다가 추가적인 장애 지점, 보안 경계, 이 모든 것들이 플랫폼 팀으로서 제가 가진 것들입니다.
생각해 볼 필요가 있어요.물론 저는 조직적으로 최고의 성과를 내고 싶습니다.
동시에, 프랙티스는 플랫폼으로서
팀, 저는 모든 서비스 대 서비스 이야기를 들어봤어요
통신은 암호화되어야 하고, 상호 TLS를 거쳐야 하고,
그래서 해결책이 필요하죠.그래서 저는 서비스 메쉬를 사용한다는 아이디어가 마음에 들어요. 왜냐하면 알다시피, 페데리카의
팀에서 각 애플리케이션을 하나하나 계측할 필요는 없습니다.
옵저버빌리티 보안에 필요한 모든 것을 갖추고 있죠.이를 맨 위에 레이어로 추가할 수 있어 팀의 복잡성을 없앨 수 있습니다.제 생각에는 조금 더 도움이 되긴 하지만, 접근 방식이 있는 것 같아요.
여기에는 Istio 앰비언트 메시가 있습니다.즉, Istio 앰비언트 메시는 기존 사이드카 모델에서 Istio와 동일한 이점을 얻을 수 있게 해주지만 사이드카 없이도 말이죠.
이를 수행하는 방법은 기본적으로 서비스 간 트래픽을 터널 프록시로 암호화하는 것입니다.이 프로토콜이 사용하는 특정 프로토콜은 HTTP 기반 오버레이 네트워크 환경인 HBONE이라는 ISTIO 관련 용어입니다.그래서 이걸 구분해 보면
그렇게 복잡하지 않아요.환경은
네트워크 상단에 오버레이되며 HTTP를 기반으로 합니다.여기서 흥미로운 점은 기본적으로 서비스 사이를 오가는 모든 트래픽이 제대로 전달되도록 한다는 것입니다.
이제 이 터널을 통과합니다.그게 우리가 할 수 있는 건
상호 TLS를 바로 사용할 수 있습니다.포드를 다시 시작할 필요가 없습니다.트래픽은 에서 출발합니다.
네트워크 계층에서 일하고, 네트워크에서 작업하고, 터널을 통과하는 거죠?그래서 그런 일이 일어납니다.
뒤집히는 스위치인데 그걸 보여드리자면
실제로 데모로 넘어가기 위해서요.참고로, 웨이포인트 프록시에 대해서도 조금 보신 것으로 알고 있습니다.이에 대해서는 잠시 후에 설명하겠습니다.레이어 7 기능 때문이죠.레이어 4에 초점을 맞출 것입니다.이것이 바로 IP 주소입니다.
레이어 4 인증.정규화된 도메인 이름, PAT, 도메인 등보다는 IP와 포트를 생각해 보세요.자, 그럼 한 번 살펴보죠.
제 클러스터 환경을 보세요.저는 K9를 사용할 거예요. 그리고
이걸 안 쓰신다면 강력히 추천합니다.스텝을 밟을 수 있는 좋은 방법이에요
클러스터를 통해 무엇이 실행되고 있는지 확인해 보세요.그리고 이 클러스터에서는
오, 네, 여긴 인터넷 속도가 좀 느리긴 하지만 괜찮아요.제가 봤다는 걸 알 수 있어요.
이미 Istio를 설치했어요.자, 이것은 무중단 운영입니다.
그나저나 활동.헬름 차트 같아요.클러스터에 설치하기만 하면 됩니다.이제 이 포드가 시작되었고, 일부 포드가 함께 제공되는 것을 확인할 수 있습니다.
그라파나, 프로메테우스, 키알리, 예거, 이스티오의 컨트롤 플레인 같은 옵저버빌리티 툴과 트래픽 라우팅 방식을 위한 인그레스 게이트웨이
대신 Istio를 통해서요.좋아요, 그리고 보시다시피, 네, 이 포드들이 실제로 지난 26일 동안 다시 시작되지 않았어요.아주 빨리, 한 번 살펴보죠.유용한 명령어가 하나 있습니다.
istioctl이 우리에게 노출시키는 것은 ztunnel-config 워크로드라고 불립니다.이게 전부입니다.
우리 클러스터의 워크로드는 정확히 알 수 있습니다.
자, 이 프로토콜은 TCP입니다. 즉, HBONE 프로토콜을 거치지 않는다는 뜻이죠.우리에겐 그런 상호작용이 없어요
TLS는 아직 활성화되지 않았습니다.이를 가능하게 하려면 기본 네임스페이스에 레이블을 붙이기만 하면 됩니다. 제 생각에는 정말 멋지다고 생각해요.
이 주석을 쓰면, 그냥 이 레이블을 쓰면 되죠.데이터 플레인 모드를 설정했습니다.
앰비언트로 설정하면 끝입니다.이제 트래픽이 HBONE 프록시를 통과하기 시작할 것입니다.이제 istioctl 명령을 다시 실행해 보겠습니다.이제 이 모든 워크로드가
이전에는 TCP였던 것이 이제는 HBONE 프로토콜을 다루고 있습니다.이런 것들은 무시해도 됩니다.관리자가 몇 명 있습니다.
컨트롤 플레인 타입 서비스.이러한 사항은 변경할 필요가 없습니다.하지만 실제 애플리케이션 워크로드의 경우 HBONE을 넘어갑니다. 간단히 말씀드리자면
서비스가 정말 빠르기 때문에 액세스할 수 있습니다.하나 사야겠어
Istio 인그레스 게이트웨이.죄송합니다. 읽기가 조금 어려워요. 하지만 Istio 곡만 읽을게요.그리고 기억하세요, 우리의
애플리케이션이 다시 시작되지 않았어요.몇 가지 작업을 수행해야 합니다.
애플리케이션을 실행하기 위해 캐시 목록이 여기에 다시 로드됩니다.
여기, 이제 끝났어.애플리케이션에 접속합니다.포드 간 통신은
상호 TLS에서 발생합니다.다운타임이나 포드 재시작이 필요 없습니다.앰비언트 메시가 있습니다.
클러스터에서 활성화되었습니다.하지만 Istio를 생각해보면 상호 TLS에만 Istio를 사용하는 것은 아닙니다.그건 좀 과한 것 같네요.다른 장점들도 많이 있습니다.
Istio도 마찬가지죠?따라서 옵저버빌리티가 그 중 하나입니다.
중요한 것 중 하나죠.그래서 옵저버빌리티를 활성화하는 방법을 보여드리고자 합니다.
기능도 마찬가지죠.아주 빨리, 그냥 점프만 하면 돼요.
슬라이드로 돌아가서 ztunnel을 예로 들어보죠.
상호 TLS를 바로 사용할 수 있습니다.Layer 4 권한 부여 정책도 구현할 수 있습니다.Istio는 다음과 같은 경우에 적합합니다.
레이어 7 기능, 맞아요. 고급 트래픽
라우팅과 그런 것들이죠.그래서 웨이포인트의 경우 기본적으로 우리가 하는 일은 트래픽이 별도의 웨이포인트를 통과하게 되는 것입니다.
클러스터에서 실행되면 다음과 같이 됩니다.
Istio에 레이어 7 기능을 수행할 수 있는 기능을 제공하십시오.
그리고 관찰력이 정말 풍부하죠.사실, 잠시 후에 카오스 엔지니어링에 대한 데모도 보여드릴 예정입니다.레이어 7 기능에 왜 이런 웨이포인트가 필요한지에 대한 또 다른 인기 있는 사용 사례
카나리아 배포입니다.새 것이 있다고 가정해 봅시다.
일부 사용자에게 배포하고 싶은 기능
Firefox를 사용하는 사용자일 수도 있고 휴대폰을 사용하는 사용자일 수도 있습니다.이 모든 것이 네트워크 계층에서 전환할 수 있는 단순한 플립이 됩니다.앱 팀은 그럴 필요가 없습니다.
모든 코드를 반드시 변경해야 합니다.네트워크에서 할 수 있어요.
레이어, 그 오버레이 레이어.정말 강력한 기능이죠.어떻게 생겼는지 한 번 살펴보죠.이제 제 컴퓨터로 다시 돌아가서 웨이포인트를 활성화시켜 보겠습니다.
여러분 모두가 더 쉽게 볼 수 있겠죠.좋아, 웨이포인트를 적용해 보자면
기본적으로 제가 할 일은 웨이포인트를 적용하는 istioctl 헬퍼 명령을 실행하는 것입니다.
기본 네임스페이스에서, 그게 전부입니다.다시 말씀드리지만, 이는 새 포드를 시작하기만 하기 때문에 포드가 다시 시작되지 않습니다. 클러스터에 배포가 이루어질 것이고, 7초 전에 이 새로운 웨이포인트를 시작했다는 것을 알 수 있습니다. 이제
애플리케이션 내 옵저버빌리티.로그와 메트릭의 흐름이 어떤지 확인하기 위해 몇 번 새로고침하겠습니다.
애플리케이션과 그런 것들을 통해서요.주머니를 하나 추가할지도 몰라요
카드를 보시고 결제 버튼을 누르세요.좋아요, 멋지네요.그 정도면 충분할 것 같아요.이제 다시 돌아갈게요
커맨드 라인으로 가서 편리한 istioctl 대시보드 kiali를 실행해 보세요.Kiali는 오픈 소스입니다.
정확히 볼 수 있게 도와주는 일종의 옵저버빌리티 툴입니다.
우리 애플리케이션이 어떻게 보이는지 말이에요.우리가 제대로 작동하는지 확인해 봅시다
지난번처럼 3시간 분량의 데이터를 보세요.좋아요, 읽기가 정말 어려워요.저한테는 별로 흥미롭지 않아요.그럼 좀 정리해 볼게요.그럼 난 모르는 사람을 숨길 거야
노드.앱 그래프를 원해요.여기로 갈게요.오,
이미 좋아보여요여기로 가볼게요. 여기서 몇 가지 기능을 활성화해 볼게요.서비스 노드를 없애겠습니다.교통을 처리할게요
애니메이션, 웨이포인트 프록시.이제 끝났습니다. 여기에서 볼 수 있는 더 많은 것을 이미 보실 수 있습니다.TCP 트래픽을 비활성화해 봅시다. 다음과 같은 건 보고 싶지 않으니까요.
프로메테우스 관련 일들이 벌어지고 있어요.그리고 붐, 이제 끝났어요.이제 애플리케이션 아키텍처의 시각적 레이아웃을 볼 수 있습니다.체크아웃을 완료하지 않았어요. 그래서 이 줄이 검은색으로 표시됩니다. 왜냐하면 결제를 완료하지 않았으니까요.
이 포드에 대한 상호 TLS. 사실 제가 하지 않았거든요
체크아웃 절차를 진행하세요.하지만 바로 여기에서 볼 수 있습니다.
제가 이리저리 클릭했을 때 활성화된 다른 포드의 트래픽을 보여주고 있다는 거죠.
그 샘플 애플리케이션에서 말이죠.다음 중 하나를 클릭하고
아시다시피 UI에서 카트로 이동하는 트래픽을 볼 수 있습니다.
상호 TLS가 활성화되어 있습니다.제 생각에는 정말 멋진 것들이죠.사실 저는 점프도 할 수 있어요.
카트 같은 것들에 들어가서 정확히 뭐가 뭔지 확인해 보세요
애플리케이션이 무엇과 통신하고 있는 건데, 여기서 알 수 있겠네요.
이봐, 내 서비스 중 하나가 통신해서는 안 되는 서비스와 통신하고 있는데 Istio를 사용하여
권한 부여 또는 네트워크 정책을 구현하여 이를 방지하세요.
서비스 간 액세스는 허용되지 않을 수도 있습니다.
서로 대화하는 거죠. 폭발 반경을 제한하고 더 나은 보안 관행을 구현하죠.자, 그럼 여기서 뭘 봤죠?우리는 Istio Ambient Mesh를 사용해서 어떤 포드나 애플리케이션도 재시작하지 않아도 되는 것을 보았습니다.
레이어 4 기능이 있고, 상호 TLS가 활성화되었습니다.
그리고 우리는 뛰어난 옵저버빌리티를 얻을 수 있었습니다.
이것 때문이기도 하죠.하고 싶다고 말했잖아요
카오스 엔지니어링 데모를 보여드릴게요그럼 간단히 얘기해 보죠.그래서 제가 사용하는 관문에서는
이 클러스터에 배포하는 건 정말 간단합니다.
저는 기본적으로 앞서 보여드린 인그레스 리소스와 비슷합니다.그냥 Istio의 방식이에요.UI 서비스를 공개했는데, 해당 UI 서비스에 대해서는
오류를 삽입해 보겠습니다.약 75% 의 확률은 실패할 겁니다.아직 바르지 않았어요. 그러니 꼭 적용해 보죠
아직 응용 프로그램을 실행 중이에요.네, 다 괜찮아요.하지만 지금은
새 게이트웨이를 적용해 보겠습니다.구성된 것으로 표시되어야 합니다.
가상 서비스로.이제 구성이 완료되었습니다.그리고 지금은 75% 의 확률로
이건 실패할 거예요붐.좋아, 우린 이미 잘못을 저질렀어.이건 정말 혼란스러운 일이에요.
최고의 엔지니어링.애플리케이션이 어떻게 작동하는지 보는 거죠.
실패에 반응할 것입니다.따라서 다음과 같은 작업을 수행할 수도 있습니다.
실패 시 정책을 재시도하고 애플리케이션이 제대로 작동하는지 확인해 보세요
올바르게 응답합니다.이걸 몇 번 반복해 보죠. 25% 의 경우는 효과가 있을 테니까요.와, 말도 안 돼요.식스, 나
오늘은 도박을 하지 말아야겠네요.좋아요, 그건 일곱 번이에요.
실제로 작동하기 위해서요그리고 우리는 이미 볼 수 있습니다.
좋아요 캐시에 몇 가지 문제가 있다는 거
무효화가 진행 중이에요.그러니까 이미 우리 같은 기분이야
버그를 발견했죠?그래서 결함이 생겼을 때 우리가 해결해야 할 수도 있습니다.
캐시가 조금 더 좋아져서 사용자들이 결국 보지 못하도록 말이죠.
이런 페이지, 정말- [페데리카] 뭔가
우리 팀원들이 생각해봐야겠네요. - [사이] 맞아요, 맞아요.그러니까
어떻게 생각해요, 페데리카?이런, 그건 필요 없어요.슬라이드로 넘어가죠. - 네.
- 네. - 이게 맞는 것 같아요
사실 우리가 찾고 있는 건, 사이, 고마워요
그걸 보여줘서 고마워요클러스터에서 뮤턴트 TLS를 정말 쉽게 사용할 수 있다는 사실이 마음에 듭니다.정말 대단한 질문이네요.
보안팀 등등.따라서 관찰 가능성과 새로운 구현 측면에서 우리가 할 수 있는 모든 일들도 확실히 마음에 듭니다.
우리의 신뢰성을 향상시킬 수 있는 것들이죠.
Istio 앰비언트를 사용한 애플리케이션.하지만 저도 넣고 싶어요
바로 여기 계신 거군요.그럼 우리가 알아야 할 한계점이 있나요?
이스티오 앰비언트에 대해서요?- 그래서 여기에는 한계가 있습니다.처음 시작했을 때
이 샘플, 이 애플리케이션으로 앰비언트 메시를 구현했는데, 우리가 본 것은 서비스 중 하나가 앰비언트와 잘 맞지 않는다는 것이었습니다.
모드, 말장난을 의도한 건 아니었죠.기본적으로 우리가 봤던 것처럼요.
포드 중 하나가 MySQL 프로토콜을 사용하여
퍼시스턴스 레이어에 접근했는데 그 프로토콜은 접근하지 못했습니다.
터널과 잘 어울립니다.마치, 음, 여기서 뭘 하는 거지?글쎄요, 정말
우리가 할 수 있는 대단한 일은, 일종의
앰비언트 메시의 유연성.기본적으로 우리가 했던 일, 그리고
터미널 UI인 K9를 다시 가져와서 자세히 살펴보겠습니다.
그 카탈로그 배포.제가 여기서 약간 속임수를 썼는데, 이 포드에서 두 개의 컨테이너가 실행되고 있다는 것을 알 수 있을 겁니다.무엇을 보여드리기 위해서인지 보여드리기 위해서입니다.
두 번째 컨테이너는 Envoy 프록시입니다.자, 이제 됐어요.
근본적으로 이 카탈로그를 위해 우리가 한 일은
서비스는 사이드카를 활성화하는 것입니다.네, 이거에 대해서요.
포드, 다시 시작해야 했어요.그리고 제가 ztunnel 구성을 실행했을 때 눈치채셨을 겁니다.
워크로드 명령을 먼저 말씀드리자면, 이미 HBONE 프로토콜에 있는 서비스가 하나 있었습니다.그건 제 작은 속임수였어요.그래서 그 전에, 저는
이미 사이드카와 함께 포드를 설정했으니 앰비언트 메시가 얼마나 유연한지 제대로 알 수 있습니다.
해당 HBONE에서 작동하지 않는 특정 워크로드에 사용할 수 있습니다.
프로토콜, 그 터널 프록시.기본적으로 여러분이 하는 일은 다음과 같습니다.
단 하나의 카탈로그 서비스, 맞아요, 그 카탈로그 서비스에 대한 배포 구성, 이 레이블을 추가하죠.
사이드카 삽입은 사실입니다.그래서 그 포드 하나에는 사이드카가 있는데 실제로 키알리에서도 그 한 포드에 대해 사이드카가 있다는 것을 보여줬습니다.
사이드카가 활성화되어 있었죠.아시다시피, 여기서도 아주 빠르게 보여드릴 수 있을 것 같아요. 여기로 가보면요.좋아요, 재설정해 보겠습니다.
이전 상태로 돌아가 봅시다.좋아요, 이제 가볼게요.
카탈로그를 보면 바로 옆에 있는 작은 아이콘을 보면 그 안에 사이드카가 있다는 것을 알 수 있습니다.좋아요, 멋지네요.어떻게 하는지 봤어요, 알다시피
제대로 작동하지 않을 수 있는 특정 워크로드의 경우
이 ztunnel 프록시를 사용하면 사이드카를 설치할 수 있습니다.
어서 시작하세요. - 대단하네요, 고마워요.그리고 이건
우리가 찾고 있는 것이 바로 그것입니다.그리고 그 이유도 마음에 들어요.
여러분을 포함한 우리 팀은 서비스가 없는 메시 상태에서 보안 상태로 전환할 수 있습니다.
레이어 서비스 메시 상태를 본격적인 상태로
전체 레이어 7 기능을 즉시 채택할 필요가 없습니다.이 또한 놀랍습니다.그리고 동그라미를 치고 싶기도 했는데
조금 뒤로 돌아가 보세요.이전에 인그레스에 대해 많이 이야기했는데, 사실 인그레스는 훌륭하지만 제한적입니다.인그레스는 제한적입니다.고급 네트워크 스태프 인그레스를 활용하려면 많은 주석과 고객 리소스 정의가 필요합니다.따라서 실제로 쿠버네티스 에코시스템은 인그레스에 새로운 기능을 추가하지 않습니다.그래서 이게 될 겁니다.
앞으로도요.하지만 인그레스의 진화, 즉 쿠버네티스 게이트웨이 API는 이러한 모든 기능을 갖추고 있으며, 모든 새로운 기능이 쿠버네티스 게이트웨이 API에 추가되었습니다.게이트웨이 API는 다음과 같은 모든 문제를 해결하려고 합니다.
인그레스를 통해 배웠고 모든 강의를 수강했습니다.
서비스 메쉬에서 배웠죠.재미있게도, 이건
게이트웨이 API는 우리가 사용하고 있는 API입니다.
레이어 7, 아이스티오 앰비언트그러니까 생태계 전반은
쿠버네티스 게이트웨이 API로 빠르게 채택될 예정입니다.드디어 API가 하나 생겼습니다.
모두가 사용할 수 있고, 우리에겐 없죠.
예를 들어 서비스 메시에서 다른 것으로 이동하거나 인그레스 사양에서 다른 사양으로 이동하려는 경우, 예를 들어 인그레스 컨트롤러의 경우
다양한 어노테이션.한 인그레스 컨트롤러에서 다른 인그레스 컨트롤러로의 마이그레이션은 매우 어려웠습니다.이제 게이트웨이 API를 사용하면
사양이 동일하기 때문에 더 쉬울 것입니다.그럼 그 외 다른 것들
게이트웨이 API로 할 수 있는 일은, 우선
당연히 인그레스 API로 할 수 있는 모든 것을 할 수 있습니다.따라서 인그레스를 처리할 수 있습니다.
트래픽은 물론 처리할 수도 있고, 당연히 더 많은 일을 할 수 있습니다.
주석으로 하면 이제 API에 다시 임베드됩니다.그러면 서비스 간 서비스를 할 수 있습니다.
Gamma 프로젝트를 사용해보세요.그리고 이제 마지막 KubeCon에서는
쿠버네티스 게이트웨이의 애플리케이션도 살펴본 적이 있습니다.
이그레스 트래픽을 위한 API.정말 놀랍습니다. 모든 사용 사례와 시나리오를 처리하고 Kubernetes를 통합할 수 있는 단일 API가 있기 때문입니다.
네트워킹, 정말 그렇습니다.또 다른 한 가지는, 여러분도 다룰 수 있는 구체적인 주제입니다.
제가 쿠버네티스 게이트웨이 API에 대해 자세히 알아보고 싶었던 API는 사실 청록색입니다.
클러스터 전반의 시나리오예를 들어, 앞서 설명했듯이 우리 팀은 비용을 지출하고 있습니다.
예를 들어 클러스터 업그레이드를 하는 데 많은 시간을 할애했고, 우리는
현재 업그레이드가 진행 중이지만 좀 더 자세히 알아보고 싶었습니다.
예를 들어 블루-그린을 적용하면 어떤 모습일까요?
신뢰성을 높이기 위해서죠.필요한 경우 롤백할 수 있기를 원합니다.카나리아를 만들고 싶어요.
새 버전으로의 배포, 그러니까 이 모든 것들,
생태계를 살펴보면서 우리는 이렇게 말했습니다. “좋아요, 필요해요.
그럼 멀티클러스터를 해야겠네요.어떤 옵션이 우리에게 적합할까요?”Istio Ambient를 채택했지만 멀티클러스터는 아직 채택하지 않았습니다.
Istio 앰비언트에서 지원됩니다.그리고 일반적으로 Istio 또는 서비스 메시 전반을 사용하여 멀티클러스터에 접근하는 방식을 생각해 보면 아키텍트로서 고려해야 할 사항이 여러 가지가 있습니다.예를 들어 컨트롤 플레인을 어떻게 설정할지 생각해 봐야 합니다.클러스터를 관리하기 위해 컨트롤 플레인을 외부화할 건가요?안에 설치해 볼까요?
고가용성 모드?우리가 고려해야 할 또 다른 사항은 클러스터 전체에서 API 권한을 공유해야 한다는 것입니다.그 다음은 암호화입니다.
그리고 테넌시 경계.다시 말씀드리지만, 메시 간의 신뢰도 관리해야 합니다.그래서 만약 그게 어려웠다면
그 전에는 서비스 메쉬부터 시작했죠.
메시에 클러스터를 여러 개 추가하면 매우 큰 효과를 얻을 수 있습니다.
거기에는 복잡성이 더해집니다.그래서 쿠버네티스 게이트웨이 API로도 이 작업을 수행할 수 있다고 말씀드렸습니다.그래서 다른 접근 방식을 사용하고 있습니다.
쿠버네티스 게이트웨이 API, 그리고 그 커플링을 하면
일반적으로 API에 대한 또 다른 API 세트, 즉 멀티클러스터 서비스 API, 서비스 입력, 서비스 익스포트와 같은 API와 함께 사용할 수 있습니다.
이를 통해 이 작업을 수행할 수 있습니다. 예를 들어, 멀티클러스터를 사용하면
하지만 더 쉬운 방법으로 쿠버네티스 고유의 방식이 필요합니다.그리고 AWS 내에서 구현합니다.
쿠버네티스 게이트웨이 API와 Amazon VPC Lattice를 인프라로 사용하는 멀티클러스터 서비스 API.예를 들어, 우리는
인그레스 이전에 인그레스 컨트롤러를 사용하는 것을 본 적이 있습니다.
로드 밸런서를 구현했으니 이제 쿠버네티스를 볼 수 있습니다.
Amazon을 구현하는 컨트롤러가 있는 게이트웨이 API
VPC 래티스 리소스.그리고 정말 빠르죠?
아마존 VPC 래티스는 우선 아마존 VPC입니다.
래티스는 트랜짓 게이트웨이와 같은 네트워크 서비스입니다.
VPC 피어링과 비슷하지만 트랜짓 게이트웨이와 달리 OSI 모델의 레이어 7인 다른 레이어에서 작동합니다.
VPC 피어링과는 다릅니다.그리고 이를 통해 우리는 연결할 수 있었습니다.
VPC와 계정 전반의 애플리케이션 없이
Amazon VPC Lattice를 사용하는 것만으로도 이러한 서비스를 이용할 수 있습니다.또한 AWS를 구현합니다.
보안에 대한 기본 접근 방식.또 다른 좋은 점은
쿠버네티스 게이트웨이 API와 Amazon VPC Lattice를 사용하여 여러 클러스터에 걸쳐 트래픽을 확보할 수 있을 뿐만 아니라
또한 Amazon VPC Lattice를 사용하면 단일 URL로 다음과 같은 정보의 일부를 전송할 수 있습니다.
Amazon EC2 내의 서비스와 다음과 같은 서비스를 대상으로 하는 트래픽을 예로 들 수 있습니다.
쿠버네티스 또는 예를 들어 ECS나 Lambda에서 말이죠.이 점이 우리에게 매우 매력적인데, 우리에게도 몇 가지가 있기 때문이죠.
글쎄요, 레거시 워크로드는 여전히 해당 기관에서 실행되고 있습니다.
현대화하고 싶습니다.실제로 많은 문제가 있지만 네트워크도 그 중 하나입니다.그래서 이런 것들이 우리에게 많은 것을 단순화시켜주죠. - 네, 물론이죠. 게이트웨이 API가 정말 기대되네요.정말 이런 것이죠.
전체 커뮤니티와 클라우드 제공업체는
일종의 중심이죠.물론, 게이트웨이는
API는 오픈 소스 업스트림 쿠버네티스 기술입니다. 인그레스의 진화처럼 말이죠.그래서 클라우드 제공업체들은
특히 AWS와 마찬가지로 다음과 같은 컨트롤러를 만들고 있습니다.
Federica가 지난 슬라이드에서 몇 가지를 구현할 수 있도록 다루었던 게이트웨이 API 컨트롤러는
AWS에 있는 이러한 리소스 중 VPC Lattice는 정말 유용합니다.
게이트웨이 API 컨트롤러와 함께라면 정말 잘 적응할 수 있었죠.따라서 인그레스와 일종의 인그레스 API 및 서비스를 만드는 대신 일종의 새로운 접근 방식입니다.
게이트웨이 및 HTTP 라우트 포함.그리고 제 생각에 우리는 정말
커뮤니티와 고객들의 모습을 보게 될 거예요.
이 새로운 접근 방식을 채택한 이유는 그 수가 많기 때문입니다.
이것이 제공하는 장점들, 제가 말씀드릴 수 있는 것은
알다시피, 목표물로 라우팅할 수 있다는 거죠.
클러스터 외부에서, 다른 클러스터이든, Lambda이든 상관 없습니다.
ECS, 당신이 가지고 있는 모든 것, 그리고 추가적으로
Federica가 여기서 다룬 모든 기능 중 이제 사용할 수 있게 되었습니다.오늘은 우리가 이야기한 내용을 간단히 요약해 볼게요. 그렇죠?그래서 단순화부터 시작했죠.
클러스터 오퍼레이션.컨테이너 기반 애플리케이션을 실행하기 위해 Amazon EKS를 선택한 것에 대해 이야기를 나눴습니다.포드 간 네트워킹에 VPC CNI를 사용하는 방법에 대해 이야기했습니다.
플랫폼에 통합된 것 같고
특히 자동 모드에서 말이죠.알다시피, 심지어 아주 많은 사람들에게도
제가 오늘 보여드린 데모는 좀 더 이상 다음과 같은 구성 요소를 관리할 필요가 없기 때문에 간소화되었을 것입니다.
로드 밸런서 컨트롤러, VPC CNI, CoreDNS는 제가 직접 관리합니다.그리고 클러스터를 업그레이드하면 클러스터도 업그레이드됩니다.물론 그 뜻은
아시다시피, 자동 모드에는 다른 구성 요소도 있습니다.
카펜터 같은 것도 관리됩니다.걱정하지 않으셔도 됩니다.
이를 실행하기 위한 전용 컴퓨팅, 이러한 리소스도 마찬가지입니다.
카펜터용 전용 노드, 전용 노드 없음
네트워킹 구성 요소.여기로 넘어가자면
애플리케이션 노출에 대해 조금 이야기를 나눴습니다.
외부적으로는, 맞아요. 로드 밸런서 컨트롤러를 사용하는 거죠.ALB 생성에 대해 이야기했는데요,
Layer 7에서 다음을 사용하는 애플리케이션 로드 밸런서
로드 밸런서 컨트롤러.그리고 레이어 4 레벨에서는
다음을 생성하여 개별 NLB를 만드는 방법에 대해 이야기했습니다.
로드 밸런서 유형의 서비스.여기서 좀 더 아래로 내려가서 얘기해봤는데
Istio Ambient Mesh를 사용하여 레이어 4 및 레이어 7 권한 부여 정책, 레이어 7 고급 라우팅을 적용할 수 있게 되었습니다.
애플리케이션을 방해하지 않고 바로 사용할 수 있는 상호 TLS뿐만 아니라 특정 워크로드에 필요할 때 사이드카를 사용할 수 있어 상호 운용성이 뛰어납니다.마지막으로 이야기를 나눴습니다.
VPC 래티스와 새로운 게이트웨이 API에 대해 조금 말씀드리자면
쿠버네티스 게이트웨이 API, 이를 통해 고객이 이 새로운 API로 이동하고 발전할 수 있는 방법
네트워킹 버전과 아마존에서 VPC Lattice가 VPC 기능으로 사용되는 방식이 이를 뒷받침하는 데 도움이 됩니다.좋아요, 많은 분들이 어떻게 하면 계속할 수 있을지 궁금하실 텐데요.
이런 것들을 집에서 배우시나요?음, 참고로 제가 처음 해본 데모와 제가 만든 인그레스 데모는 사실 EKS Workshop을 기반으로 했습니다.클라우드의 VS Code에서 보여드린 것과 동일한 환경을 직접 만들어 볼 수 있습니다.따라서 강력히 추천합니다.
EKS 워크숍을 통해 자신의 속도에 맞게 학습하세요.사실 저는 아주 잘 할 수 있어요.
eksworkshop.com에서 간단하게 한 가지만 보여주세요.기초 섹션에서 알아차릴 수 있는 몇 가지 사항은 애플리케이션 노출로 이동하면 다음과 같습니다.
인그레스를 통해 보여드렸듯이, 실제로 다음과 같은 설정을 할 수 있습니다.
자신을 위한 환경을 만들고 직접 살펴보세요.우리는 다음과 같은 것들에 대해 이야기합니다.
다중 인그레스 패턴, 생성하면 어떻게 되나요?
인그레스 리소스가 여러 개지만 앞에 단일 ALB가 있어야 합니다.IP에 대해서도 이야기합니다.
로드 밸런서의 모드 대 인스턴스 모드도 마찬가지입니다.EKS 워크숍은 자기 주도형으로 EKS에 관한 모든 것을 배울 수 있는 좋은 방법입니다.정말, 진심으로 그렇게 생각해요. 왜냐하면 꽤 많은 것들이 있기 때문이죠.
여기에 약간의 콘텐츠가 있고 계속 업데이트하고 있습니다.한 가지 말씀드리고 싶은 것은
자신의 계정으로 만들고 싶지 않다면
AWS 계정 관리자에게 문의할 수도 있습니다.
EKS 워크숍을 요청하려면그리고 그 QR 코드에는
작성할 수 있는 양식도 있을 거예요.
설정을 도와드리기 위해 연락드리겠습니다.
EKS 워크숍과 함께 말이죠.또한 EKS의 모범 사례 가이드가 이제 AWS Docs에 통합되어 있어 자세히 알아보기에 좋은 곳입니다.
네트워킹 모범 사례.저는 페데리카와 그녀를 잘 압니다.
팀은 많은 시간을 들여 업데이트를 진행했습니다.
항상 최신의 최적화된 설정을 사용할 수 있도록 하는 모범 사례 가이드
권장하는 네트워킹.그리고 조금만 통과하면 배지도 받을 수 있습니다.
저희 코스 중 하나죠.좋아요, 그게 다예요
오늘은 여러분을 위해 준비했습니다.정말 고마워요
우리 세션에 참석해 주세요. - 고마워요.
(관중들의 박수 갈채)